<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 8 Os métodos Ensemble | Fundamentos de Machine Learning</title>
  <meta name="description" content="Entenda Machine Learning desde sua história até seus principais conceitos." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 8 Os métodos Ensemble | Fundamentos de Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Entenda Machine Learning desde sua história até seus principais conceitos." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 8 Os métodos Ensemble | Fundamentos de Machine Learning" />
  
  <meta name="twitter:description" content="Entenda Machine Learning desde sua história até seus principais conceitos." />
  

<meta name="author" content="Elton Massahiro Saito Loures" />


<meta name="date" content="2021-04-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ptII.html"/>
<link rel="next" href="deeplearning.html"/>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefácio</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#por-que-ler-esse-livro"><i class="fa fa-check"></i><b>0.1</b> Por que ler esse livro?</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#estrutura"><i class="fa fa-check"></i><b>0.2</b> Estrutura</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#informações-a-respeito-do-conteúdo"><i class="fa fa-check"></i><b>0.3</b> Informações a respeito do conteúdo</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#agradecimentos"><i class="fa fa-check"></i><b>0.4</b> Agradecimentos</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="i-a.html"><a href="i-a.html"><i class="fa fa-check"></i><b>1</b> Inteligência Artificial (IA)</a><ul>
<li class="chapter" data-level="1.1" data-path="i-a.html"><a href="i-a.html#o-que-é-ia-de-onde-veio-esse-conceito"><i class="fa fa-check"></i><b>1.1</b> O que é IA? De onde veio esse conceito?</a></li>
<li class="chapter" data-level="1.2" data-path="i-a.html"><a href="i-a.html#a-arte-de-uma-ia"><i class="fa fa-check"></i><b>1.2</b> A arte de uma IA</a></li>
<li class="chapter" data-level="1.3" data-path="i-a.html"><a href="i-a.html#vertentes-de-uma-ia-e-fundamentação-filosófica"><i class="fa fa-check"></i><b>1.3</b> Vertentes de uma IA e fundamentação filosófica</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="machinelearning.html"><a href="machinelearning.html"><i class="fa fa-check"></i><b>2</b> O Aprendizado de Máquina</a><ul>
<li class="chapter" data-level="2.1" data-path="machinelearning.html"><a href="machinelearning.html#como-a-máquina-aprende"><i class="fa fa-check"></i><b>2.1</b> Como a máquina aprende?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="dicio.html"><a href="dicio.html"><i class="fa fa-check"></i><b>3</b> Uma breve revisão</a><ul>
<li class="chapter" data-level="3.1" data-path="dicio.html"><a href="dicio.html#um-pouco-de-álgebra-linear"><i class="fa fa-check"></i><b>3.1</b> Um pouco de Álgebra Linear</a></li>
<li class="chapter" data-level="3.2" data-path="dicio.html"><a href="dicio.html#um-pouco-de-estatística"><i class="fa fa-check"></i><b>3.2</b> Um pouco de Estatística</a></li>
<li class="chapter" data-level="3.3" data-path="dicio.html"><a href="dicio.html#medidasimport"><i class="fa fa-check"></i><b>3.3</b> Medidas de Importância</a><ul>
<li class="chapter" data-level="3.3.1" data-path="dicio.html"><a href="dicio.html#medidasdep"><i class="fa fa-check"></i><b>3.3.1</b> Medidas de Dependência</a></li>
<li class="chapter" data-level="3.3.2" data-path="dicio.html"><a href="dicio.html#medinfo"><i class="fa fa-check"></i><b>3.3.2</b> Medidas de Informação</a></li>
<li class="chapter" data-level="3.3.3" data-path="dicio.html"><a href="dicio.html#meddist"><i class="fa fa-check"></i><b>3.3.3</b> Medidas de Similaridade e Dissimilaridade</a></li>
<li class="chapter" data-level="3.3.4" data-path="dicio.html"><a href="dicio.html#medidas-de-precisão"><i class="fa fa-check"></i><b>3.3.4</b> Medidas de Precisão</a></li>
<li class="chapter" data-level="3.3.5" data-path="dicio.html"><a href="dicio.html#medidas-de-consistência"><i class="fa fa-check"></i><b>3.3.5</b> Medidas de consistência</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="preprocesso.html"><a href="preprocesso.html"><i class="fa fa-check"></i><b>4</b> Pré-processamento</a><ul>
<li class="chapter" data-level="4.1" data-path="preprocesso.html"><a href="preprocesso.html#dados-faltantes-e-a-limpeza-de-dados"><i class="fa fa-check"></i><b>4.1</b> Dados faltantes e a Limpeza de dados</a><ul>
<li class="chapter" data-level="4.1.1" data-path="preprocesso.html"><a href="preprocesso.html#tratamento-de-dados-faltantes"><i class="fa fa-check"></i><b>4.1.1</b> Tratamento de dados faltantes</a></li>
<li class="chapter" data-level="4.1.2" data-path="preprocesso.html"><a href="preprocesso.html#outlier"><i class="fa fa-check"></i><b>4.1.2</b> <em>Outlier</em></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="preprocesso.html"><a href="preprocesso.html#transformação-de-dados"><i class="fa fa-check"></i><b>4.2</b> Transformação de dados</a><ul>
<li class="chapter" data-level="4.2.1" data-path="preprocesso.html"><a href="preprocesso.html#tipos-de-datasets"><i class="fa fa-check"></i><b>4.2.1</b> Tipos de <em>datasets</em></a></li>
<li class="chapter" data-level="4.2.2" data-path="preprocesso.html"><a href="preprocesso.html#normpadro"><i class="fa fa-check"></i><b>4.2.2</b> Normalização e padronização</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="preprocesso.html"><a href="preprocesso.html#features-selection---seleção-de-atributos-sa"><i class="fa fa-check"></i><b>4.3</b> Features Selection - Seleção de atributos (SA)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="valid.html"><a href="valid.html"><i class="fa fa-check"></i><b>5</b> Validação de um modelo</a><ul>
<li class="chapter" data-level="5.1" data-path="valid.html"><a href="valid.html#fitt"><i class="fa fa-check"></i><b>5.1</b> <em>Overfitting, Underfitting</em></a><ul>
<li class="chapter" data-level="5.1.1" data-path="valid.html"><a href="valid.html#overfitting"><i class="fa fa-check"></i><b>5.1.1</b> <strong>Overfitting</strong></a></li>
<li class="chapter" data-level="5.1.2" data-path="valid.html"><a href="valid.html#underfitting"><i class="fa fa-check"></i><b>5.1.2</b> <strong>Underfitting</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="valid.html"><a href="valid.html#holdout"><i class="fa fa-check"></i><b>5.2</b> Validação cruzada Hold-out</a></li>
<li class="chapter" data-level="5.3" data-path="valid.html"><a href="valid.html#kfold"><i class="fa fa-check"></i><b>5.3</b> Validação Cruzada <em>K-fold</em></a></li>
<li class="chapter" data-level="5.4" data-path="valid.html"><a href="valid.html#aocroc"><i class="fa fa-check"></i><b>5.4</b> ROC e AUC</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html"><i class="fa fa-check"></i><b>6</b> Modelos de Aprendizagem I</a><ul>
<li class="chapter" data-level="6.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#naive-bayes"><i class="fa fa-check"></i><b>6.1</b> Naive Bayes</a><ul>
<li class="chapter" data-level="6.1.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exbayes"><i class="fa fa-check"></i><b>6.1.1</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#reg"><i class="fa fa-check"></i><b>6.2</b> Regressão</a><ul>
<li class="chapter" data-level="6.2.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#reglin"><i class="fa fa-check"></i><b>6.2.1</b> Análise de Regressão Linear Simples</a></li>
<li class="chapter" data-level="6.2.2" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#regmult"><i class="fa fa-check"></i><b>6.2.2</b> Regressão Linear Múltipla</a></li>
<li class="chapter" data-level="6.2.3" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#mpl"><i class="fa fa-check"></i><b>6.2.3</b> Modelo de Probabilidade Linear (MPL)</a></li>
<li class="chapter" data-level="6.2.4" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exemplo1reg"><i class="fa fa-check"></i><b>6.2.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#GD"><i class="fa fa-check"></i><b>6.3</b> Gradiente Descendente</a><ul>
<li class="chapter" data-level="6.3.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exemplos"><i class="fa fa-check"></i><b>6.3.1</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#regularizacao"><i class="fa fa-check"></i><b>6.4</b> Regularização</a><ul>
<li class="chapter" data-level="6.4.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#penalizacoes"><i class="fa fa-check"></i><b>6.4.1</b> Penalizações - Regressão <em>Lasso</em> e a Regressão <em>Ridge</em></a></li>
<li class="chapter" data-level="6.4.2" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#elasticnet"><i class="fa fa-check"></i><b>6.4.2</b> Elastic Net - <span class="math inline">\(L_1+L_2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#k-vizinhos-mais-próximos-k-nearest-neighbors"><i class="fa fa-check"></i><b>6.5</b> K-Vizinhos Mais Próximos (<em>K-Nearest Neighbors</em>)</a><ul>
<li class="chapter" data-level="6.5.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exknn"><i class="fa fa-check"></i><b>6.5.1</b> Exemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ptII.html"><a href="ptII.html"><i class="fa fa-check"></i><b>7</b> Modelos de Aprendizagem II</a><ul>
<li class="chapter" data-level="7.1" data-path="ptII.html"><a href="ptII.html#svm"><i class="fa fa-check"></i><b>7.1</b> Máquina de Vetores Suporte - <em>Support Vectors Machine</em></a><ul>
<li class="chapter" data-level="7.1.1" data-path="ptII.html"><a href="ptII.html#classificação-de-padrões-linearmente-separáveis"><i class="fa fa-check"></i><b>7.1.1</b> Classificação de Padrões Linearmente Separáveis</a></li>
<li class="chapter" data-level="7.1.2" data-path="ptII.html"><a href="ptII.html#margmax"><i class="fa fa-check"></i><b>7.1.2</b> Hiperplano de Separação Ótima / Margem Máxima</a></li>
<li class="chapter" data-level="7.1.3" data-path="ptII.html"><a href="ptII.html#classificação-de-padrões-não-linearmente-separáveis"><i class="fa fa-check"></i><b>7.1.3</b> Classificação de Padrões Não-Linearmente Separáveis</a></li>
<li class="chapter" data-level="7.1.4" data-path="ptII.html"><a href="ptII.html#exemplosvm"><i class="fa fa-check"></i><b>7.1.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ptII.html"><a href="ptII.html#decisiontree"><i class="fa fa-check"></i><b>7.2</b> Árvore de Decisão (<em>Decision Tree</em>)</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ptII.html"><a href="ptII.html#extree"><i class="fa fa-check"></i><b>7.2.1</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ptII.html"><a href="ptII.html#AC"><i class="fa fa-check"></i><b>7.3</b> Análise de Componentes Principais</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ptII.html"><a href="ptII.html#autovalores-e-autovetores"><i class="fa fa-check"></i><b>7.3.1</b> Autovalores e Autovetores</a></li>
<li class="chapter" data-level="7.3.2" data-path="ptII.html"><a href="ptII.html#estatísticas"><i class="fa fa-check"></i><b>7.3.2</b> Estatísticas</a></li>
<li class="chapter" data-level="7.3.3" data-path="ptII.html"><a href="ptII.html#a-acp"><i class="fa fa-check"></i><b>7.3.3</b> A ACP</a></li>
<li class="chapter" data-level="7.3.4" data-path="ptII.html"><a href="ptII.html#exemplocp"><i class="fa fa-check"></i><b>7.3.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ptII.html"><a href="ptII.html#análise-de-agrupamentos---clusters"><i class="fa fa-check"></i><b>7.4</b> Análise de Agrupamentos - <em>Clusters</em></a><ul>
<li class="chapter" data-level="7.4.1" data-path="ptII.html"><a href="ptII.html#técnicas-hierárquicas-aglomerativas"><i class="fa fa-check"></i><b>7.4.1</b> Técnicas Hierárquicas Aglomerativas</a></li>
<li class="chapter" data-level="7.4.2" data-path="ptII.html"><a href="ptII.html#número-final-de-grupos"><i class="fa fa-check"></i><b>7.4.2</b> Número final de grupos</a></li>
<li class="chapter" data-level="7.4.3" data-path="ptII.html"><a href="ptII.html#técnicas-não-hierárquicas"><i class="fa fa-check"></i><b>7.4.3</b> Técnicas Não Hierárquicas</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ptII.html"><a href="ptII.html#redesneurais"><i class="fa fa-check"></i><b>7.5</b> Redes Neurais Artificiais</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptIII.html"><a href="ptIII.html"><i class="fa fa-check"></i><b>8</b> Os métodos <em>Ensemble</em></a><ul>
<li class="chapter" data-level="8.1" data-path="ptIII.html"><a href="ptIII.html#bagging"><i class="fa fa-check"></i><b>8.1</b> <em>Bagging</em></a></li>
<li class="chapter" data-level="8.2" data-path="ptIII.html"><a href="ptIII.html#boost"><i class="fa fa-check"></i><b>8.2</b> <em>Boosting</em></a><ul>
<li class="chapter" data-level="8.2.1" data-path="ptIII.html"><a href="ptIII.html#adaboost"><i class="fa fa-check"></i><b>8.2.1</b> <em>AdaBoost</em></a></li>
<li class="chapter" data-level="8.2.2" data-path="ptIII.html"><a href="ptIII.html#gradientboost"><i class="fa fa-check"></i><b>8.2.2</b> <em>Gradient Boosting</em></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ptIII.html"><a href="ptIII.html#bagboost"><i class="fa fa-check"></i><b>8.3</b> <em>Bagging x Boosting</em></a></li>
<li class="chapter" data-level="8.4" data-path="ptIII.html"><a href="ptIII.html#stacking"><i class="fa fa-check"></i><b>8.4</b> <em>Stacking</em></a></li>
<li class="chapter" data-level="8.5" data-path="ptIII.html"><a href="ptIII.html#rf"><i class="fa fa-check"></i><b>8.5</b> Floresta Aleatória - <em>Random Forest</em></a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="deeplearning.html"><a href="deeplearning.html"><i class="fa fa-check"></i><b>9</b> <em>Deep Learning</em></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado com bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de <em>Machine Learning</em></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ptIII" class="section level1">
<h1><span class="header-section-number">Capítulo 8</span> Os métodos <em>Ensemble</em></h1>
<p>Os métodos <strong><em>ensemble</em> (conjunto)</strong> são algoritmos de aprendizado que constroem um conjunto de classificadores e combinam os resultados de cada modelo para classificar um novo modelo de exemplo <span class="citation">(Dietterich <a href="#ref-dietterich2000ensemble">2000</a>)</span>, obtendo um valor final único a fim de melhorar a precisão e estabilidade do modelo. Os mais conhecidos são as técnicas de <strong><em>boosting</em></strong> <span class="citation">(Freund, Schapire, and others <a href="#ref-freund1996experiments">1996</a>)</span>, <strong><em>bagging</em></strong> <span class="citation">(Breiman <a href="#ref-breiman1996bagging">1996</a>)</span>, <strong><em>Random Forest</em></strong> <span class="citation">(Breiman <a href="#ref-breiman2001random">2001</a>; Liaw, Wiener, and others <a href="#ref-liaw2002classification">2002</a>)</span>, <strong><em>Extra Trees</em></strong>, <strong><em>GradientBoosting</em></strong>.</p>
<p>Como é uma resposta agregada de outros modelos preditivos, tratamos de algoritmos mais complexos que necessitam de um custo computacional maior, mais tempo e com mais processos para que se tenha um desempenho melhor.</p>
<div id="bagging" class="section level2">
<h2><span class="header-section-number">8.1</span> <em>Bagging</em></h2>
<p>O método <em>bagging</em> <span class="citation">(Breiman <a href="#ref-breiman1996bagging">1996</a>)</span> é um dos métodos de algoritmos de aprendizado de máquina mais antigos. Este método utiliza amostras <em>bootstrap</em> - amostragem com reposição no qual por meio do conjunto de treinamento inicial, seleciona-se aleatoriamente exemplos para um novo subconjunto de treinamento <span class="citation">(Oshiro <a href="#ref-oshiro2013abordagem">2013</a>)</span>.</p>
<p>Na técnica <em>bagging</em>, portanto, diferentes subconjuntos <span class="math inline">\(T_k\)</span> são aleatóriamente elaborados, com reposição, a partir do original e tem como idéia básica criar classificadores a partir de um conjunto de dados de treinamento com distribuição uniforme de probabilidades. Cada amostra possui o mesmo tamanho da base de dados originais e por ser <em>bootstrap</em> alguns elementos podem aparecer repetidamente, ao passo que alguns podem ser que não estejam presentes no conjunto de treinamento. Cada subconjunto <span class="math inline">\(T_k\)</span> é utilizado para treinar um classificador diferente <span class="math inline">\(\{h_k(x)\}\)</span> e a classificação é definida pelo voto majoritário sobre todos os classificadores.</p>
<p>Conforme <span class="citation">(Oshiro <a href="#ref-oshiro2013abordagem">2013</a>)</span>, este método consiste então em combinar <span class="math inline">\(T\)</span> classificadores de <span class="math inline">\(N\)</span> amostras geradas a partir do conjunto de treinamento <span class="math inline">\(M\)</span> com <span class="math inline">\(R\)</span> elementos. Cada classificador possui <span class="math inline">\(m\)</span> elementos do conjunto de treinamento original de <span class="math inline">\(M\)</span>. Em vez de utilizar todas as observações do conjunto original do treinamento, escolhe elementos uniformemente com repetição e gerando <span class="math inline">\(k\)</span> exemplos, que representam aspectos originais da base de dados. Em cada exemplo o classificador é gerado independentemente e a classificação de um novo elemento será executada sobre cada um dos <span class="math inline">\(T\)</span> classificadores.</p>
<p>A cada tentativa <span class="math inline">\(t=1,2,...,T\)</span>, um conjunto de treinamento de tamanho <span class="math inline">\(N\)</span> é amostrado do conjunto de treinamento original com o mesmo tamanho. Também a cada tentativa, um classificador <span class="math inline">\(C_i\)</span> será gerado e no final um classificador <span class="math inline">\(C^*\)</span> será formado através da geração de <span class="math inline">\(T\)</span> classificadores obtidos em cada tentativa. Para uma amostra desconhecida, cada classificador <span class="math inline">\(C_i\)</span> retorna seu voto e por fim o classificador <span class="math inline">\(C^*\)</span> retornará a classe com o maior número de votos.</p>
<p>Vamos pensar numa aplicação deste método em árvores de decisão: primeiramente, o <em>bagging</em> faz um sorteio de todas as amostras - escolhe uma, sorteia e escolhe outra sucessivamente - com reposição com, por exemplo, 70% do total. Por isso podem vir elementos repetidos ou até mesmo omitir alguns (<em>bootstrap</em>). Temos agora um <em>dataset</em> para construirmos uma árvore de decisão. Da mesma forma, faz este processo com uma segunda árvore, uma terceira e assim por diante com um novo <em>dataset</em> aleatório com <em>bootstrap</em>. Note que temos então uma estimação para cada árvore diferente com dados diferentes sorteados. Um mesmo modelo de Aprendizado de Máquina com conjuntos diferentes. Com o voto majoritário (situação de classificação) ou uma média (como um caso de regressão) de todas as estimações dos classificadores <span class="math inline">\(C_i\)</span>, obtemos um classificador <span class="math inline">\(C^*\)</span> final. O método <em>bagging</em> é muito útil para evitar <em>overfitting</em> (ver <a href="valid.html#fitt">5.1</a>) com essa repetição do mesmo modelo de Aprendizado de Máquina. Importante notar que ele é um método para ser aplicado em algum modelo de Aprendizado de Máquina, por exemplo, pode-se optar pelo algoritmo de Regressão Linear, KNN, árvore de decisão ou em alguma técnica de mineração de dados.</p>
<p>O método <em>bagging</em> é muito útil para evitar <em>overfitting</em> (ver <a href="valid.html#fitt">5.1</a>) pois repetimos o modelo várias vezes com vários conjuntos aleatórios e situações com novos esimadores de treino. Ao entrar novos dados para o teste, ele terá um desempenho semelhante. Importante notar que ele é um método para ser aplicado em algum modelo de Aprendizado de Máquina, por exemplo, pode-se optar pelo algoritmo de Regressão Linear, KNN, árvore de decisão ou em alguma técnica de mineração de dados.</p>

</div>
<div id="boost" class="section level2">
<h2><span class="header-section-number">8.2</span> <em>Boosting</em></h2>
<p>O método <strong><em>boosting</em></strong> <span class="citation">(Freund, Schapire, and others <a href="#ref-freund1996experiments">1996</a>)</span> é um método de combinação de classificadores com o propósito de fornecer uma classificação muito mais eficiente, considerado uma das ideias mais poderosas de aprendizagem nos últimos vinte anos <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-hastie2009elements">2009</a>)</span>. É um processo iterativo utilizado para ser alterado adaptativamente a distribuição de exemplos de treinamento, assim os classificadores de base tem como foco exemplos difíceis de classificar. Originalmente foi elaborado para problemas de classificação, mas pode ser muito bem aplicado para regressão.</p>
<p>Válido ressaltar de que a seguir estão apresentados duas, e muito utilizadas, de muitas outras técnicas de <em>boosting</em>. A ideia deste método é a combinação de classificadores para reforçar seu algoritmo base, portanto, pode variar de acordo com a fundamentação teórica proposta pelo pesquisador e as que estão sendo mais utilizadas no mercado.</p>
<div id="adaboost" class="section level3">
<h3><span class="header-section-number">8.2.1</span> <em>AdaBoost</em></h3>
<p>Um dos mais conhecidos proposto por <span class="citation">Freund, Schapire, and others (<a href="#ref-freund1996experiments">1996</a>)</span>, é o <strong><em>AdaBoost</em> (Adaptative Boosting)</strong>. Conforme <span class="citation">(Freund and Schapire <a href="#ref-freund1997decision">1997</a>)</span>, o <em>AdaBoost</em> apresenta algumas propriedades específicas que pode-se destacar como o baixo valor computacional por corresponder a um programa linear e ao caso de análises de grandes espaços dimensionais, como na casa de milhões, os valores de margem entre classes podem se apresentar muitas vezes bastante diferentes e mais precisos que outros métodos como SVM <span class="citation">(Freund, Schapire, and Abe <a href="#ref-freund1999short">1999</a>; Chaves <a href="#ref-chaves2012estudo">2012</a>)</span>. Apesar de sua simplicidade e flexibilidade de implementação, deve-se atentar aos possíveis ruídos devido do algoritmo enfatizar dados mais difíceis de serem classificados.</p>
<p>Primeiramente, o conjunto de dados de treinamento é separado em <span class="math inline">\(m\)</span> conjuntos exemplos definidos. Em seguida, utiliza-se o algoritmo base (modelo de regressão, árvores de decisão, <em>naive bayes</em>, etc) escolhido de forma repetitiva aos exemplos, de modo que o <em>AdaBoost</em> fornece ao algoritmo uma distribuição de pesos referentes a cada um dos dados de treinamento <span class="citation">(Chaves <a href="#ref-chaves2012estudo">2012</a>)</span>.</p>
<p>A cada ciclo de aprendizagem, o algoritmo gera uma hipótese <span class="math inline">\(h_f\)</span>. Portanto o algoritmo base tem com finalidade gerar uma hipótese com o menor erro de treinamento. Considerando, <strong>por exemplo</strong>, <span class="math inline">\(\omega_i^{t}\)</span> o peso atribuído a (<span class="math inline">\(x_i,y_i\)</span>) na iteração <span class="math inline">\(t\)</span>, temos:</p>
<p><span class="math display" id="eq:pesoadaboost">\[\begin{equation}
    \omega_i^{t+1}=\frac{w_i^{t}}{Z_t}.k 
    \tag{8.1}
\end{equation}\]</span>
<span class="math display">\[k=exp^{-\alpha_i} \ \mbox{se} \ h_t(x_i)=y_i\]</span>
<span class="math display">\[k=exp^{\alpha_i}\ \mbox{se} \ h_t(x_i)\neq y_i\]</span></p>
<p>em que <span class="math inline">\(\alpha_t=\frac{1}{2}ln(\frac{1-\varepsilon_t}{\varepsilon_t})\)</span> é a importância associada do classificador, calculada a partir da taxa de erro da hipótese do classificador fraco (<span class="math inline">\(h_f\)</span>) <span class="math inline">\(\varepsilon_t=Pr(h_f(x_i)\neq y_i)\)</span> e <span class="math inline">\(Z_t\)</span> é o fator de normalização utilizado para que a soma de todos pesos seja igual a 1. Portanto o peso diminui para registros classificados corretamente e aumenta para classificados erroneamente <span class="citation">(Merjildo, Alonso, and others <a href="#ref-merjildo2013algoritmo">2013</a>; Chaves <a href="#ref-chaves2012estudo">2012</a>)</span>.</p>
<p>O resultado final do <em>AdaBoost</em> é calculado com base no resultado dos classificadores e seus respectivos pesos:</p>
<p><span class="math display" id="eq:adaboost">\[\begin{equation}
   H_f(x)=sign(\sum_t \alpha_t h_t(x)) 
    \tag{8.2}
\end{equation}\]</span></p>
<p>Segue a Figura <a href="ptIII.html#fig:adaboost">8.1</a> em que, da esquerda para a direita, temos a sequência do primeiro classificador treinando seus dados não ponderados, em seguida treina-o com ponderação e assim sucessivamente até chegar em seu resultado final combinado pelas hipóteses.</p>
<div class="figure" style="text-align: center"><span id="fig:adaboost"></span>
<img src="Figuras/adaboost.png" alt="Exemplo de AdaBoost. Atributos circulados referem-se aos classificados erroneamente (Marsh 2016)." width="100%" />
<p class="caption">
Figura 8.1: Exemplo de <em>AdaBoost</em>. Atributos circulados referem-se aos classificados erroneamente <span class="citation">(Marsh <a href="#ref-marsh2016multivariate">2016</a>)</span>.
</p>
</div>

</div>
<div id="gradientboost" class="section level3">
<h3><span class="header-section-number">8.2.2</span> <em>Gradient Boosting</em></h3>
<p>O algoritmo <em>Gradient Boosting</em> <span class="citation">(Friedman and Fisher <a href="#ref-friedman1999bump">1999</a>)</span> consiste em um processo iterativo aditivo iniciado com uma previsão constante, cujo valor corresponde à média da variável de resposta na amostra de treinamento <span class="math inline">\((f_0(x)=\overline{y})\)</span>. A cada iteração, um novo termo é adicionado ao modelo corrente, com o objetivo de reduzir gradualmente o erro de previsão <span class="citation">(Mayrink <a href="#ref-mayrink2015avaliaccao">2015</a>)</span>. Alguma semelhança com Gradiente Descendente? Sim! Este modelo utiliza-se do algoritmo Gradiente Descendente para que se obtenha um modelo com os erros minimizados. As atualizações são calculadas seguindo o sentido inverso do gradiente da função objetivo em relação às aproximações correntes. Este processo irá se repetir até que seja atingida sua condição, como número máximo de iterações e erro minimizado. Sua diferença em relação ao <em>AdaBoost</em> é que ao invés das deficiências dos modelos anteriores serem identificadas por peso, são através do gradiente para que se chegue a um modelo “ótimo”.</p>
<p>Este algoritmo <em>ensemble</em> é <strong>tipicamente</strong> baseado em árvore de decisão, como por exemplo, <span class="citation">Yamagishi, Kawai, and Kobayashi (<a href="#ref-yamagishi2008phone">2008</a>)</span> utilizam-no para prever a duração de chamada telefônica em sistemas de síntese texto-discurso e <span class="citation">Zhang and Haghani (<a href="#ref-zhang2015gradient">2015</a>)</span> aplicam o <em>Gradient Boosting</em> para previsão de tempo de viagem.</p>
<p>No caso típico, as funções parametrizáveis <span class="math inline">\(F_m(x|\theta_m)\)</span> são árvores de decisão. Os parâmetros <span class="math inline">\(\theta_m\)</span> definem os particionamentos e as constantes de aproximação. A cada iteração, uma nova árvore de decisão <span class="math inline">\(F_m(x|\theta_m)\)</span> é treinada para ajustar os gradientes da função objetivo em relação às previsões do modelo corrente, levando em conta cada observação da amostra de treinamento <span class="citation">(Beserra <a href="#ref-freitas2020">2020</a>)</span>.</p>
<p><span class="math display" id="eq:gdboostarvore">\[\begin{equation}
   \theta_{yi}=F_M(x_i)=\displaystyle \sum^M_{m=1}h_m(x_i)
    \tag{8.3}
\end{equation}\]</span></p>
<p>em que <span class="math inline">\(h_m\)</span> são os estimadores alunos fracos e <span class="math inline">\(M\)</span> corresponde ao número de árvores de regressão <span class="citation">(Ke et al. <a href="#ref-ke2017lightgbm">2017</a>)</span>.
E <span class="math inline">\(F_M\)</span> é definida como:</p>
<p><span class="math display" id="eq:gdboostarvore2">\[\begin{equation}
   F_m(x)=F_{m-1}(x)+h_m(x)
    \tag{8.4}
\end{equation}\]</span></p>
<p>onde a árvore recém-adicionada <span class="math inline">\(h_m\)</span> é alocada com a finalidade de minimizar a soma de perdas <span class="math inline">\(L_m\)</span>, dado o conjunto anterior <span class="math inline">\(F_{m-1}\)</span>. Portanto, a cada iteração uma nova árvore de decisão é treinada para ajustar os erros
obtidos pelo estado corrente do comit</p>
<p><span class="math display" id="eq:gdboosttree">\[\begin{equation}
   h_m=arg \underset{h}{min} L_m = arg \underset{h}{min} \displaystyle \sum^n_{i=1}l(y_i,F_{m-1}(x)+h(x_i))
    \tag{8.5}
\end{equation}\]</span></p>
<p>sendo <span class="math inline">\(l(y_i,F(x_i))\)</span> uma função de perda.</p>
<p>Para problemas de regressão, no geral, a função objetivo utilizada é o erro quadrático médio (MSE) e os gradientes da função correspondem aos resíduos de previsão da aproximação corrente.</p>

</div>
</div>
<div id="bagboost" class="section level2">
<h2><span class="header-section-number">8.3</span> <em>Bagging x Boosting</em></h2>
<p>Tomando como base em <span class="citation">Zhou (<a href="#ref-zhou2012ensemble">2012</a>)</span> e <span class="citation">Mayrink (<a href="#ref-mayrink2015avaliaccao">2015</a>)</span>, existem dois paradigmas entre os procedimentos de construção dos modelos: os métodos de combinação paralela, onde cada modelo é treinado de forma totalmente independente; e os métodos de combinação sequencial, em que o treinamento de um novo modelo depende do resultado obtido pelo modelo anterior.</p>
<p>O método de <em>Boosting</em> segue o paradigma sequencial, utilizando uma estratégia que busca atuar sobre os erros obtidos na etapa anterior, tem como finalidade reduzir gradativamente os resíduos de previsão. Dessa maneira, o processo de treinamento de cada novo modelo que irá compor o modelo final precisa ser alimentado com informações sobre os erros obtidos na etapa anterior. Funciona em modelos estáveis (como modelos lineares) melhor do que o <em>Bagging</em>.</p>
<p>Para o <em>Bagging</em> - como validação cruzada, é um exemplo de combinação paralela. A cada rodada, o algoritmo sorteia aleatoriamente um subconjunto dos dados de treinamento e utiliza essa subamostra para que se treine um novo modelo. Geralmente é utilizado reposição no sorteio, tornando possível a ocorrência de observações replicadas nesses subconjuntos de treinamento de cada modelo. É muito utilizado para resolver problemas de <em>overfitting</em> e diferentemente do <em>Boosting</em> que possui ponderação em suas saídas, as saídas do <em>Bagging</em> são igualmente importantes.</p>
<div class="figure" style="text-align: center"><span id="fig:boostbag"></span>
<img src="Figuras/boostbag.PNG" alt="Bagging x Boosting (Mayrink 2015). Os porcentuais são valores parametrizáveis que indicam a proporção da subamostragem de dados em cada subconjunto da amostra total de treinamento." width="100%" />
<p class="caption">
Figura 8.2: <em>Bagging x Boosting</em> <span class="citation">(Mayrink <a href="#ref-mayrink2015avaliaccao">2015</a>)</span>. Os porcentuais são valores parametrizáveis que indicam a proporção da subamostragem de dados em cada subconjunto da amostra total de treinamento.
</p>
</div>

</div>
<div id="stacking" class="section level2">
<h2><span class="header-section-number">8.4</span> <em>Stacking</em></h2>
<p>É um método <em>ensemble</em> pouco utilizado em relação aos anteriores. Este método busca combinar diferentes hipóteses induzidas por diferentes algoritmos de aprendizado de máquina, tem como finalidade encontrar uma boa combinação desse conjunto de hipóteses denominada <span class="math inline">\(h^*\)</span> <span class="citation">(Bernardini <a href="#ref-bernardini2002combinaccao">2002</a>)</span>.</p>
<p><span class="citation">Wolpert (<a href="#ref-wolpert1992stacked">1992</a>)</span> propôs o um esquema para aprender <span class="math inline">\(h^*\)</span> com a estratégia <strong>“<em>leave-one-out cross validation</em>” (“validação cruzada deixe um de fora”)</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>Considere <span class="math inline">\(h_i^{(-i)})\)</span> como sendo a hipótese construída pelo algoritmo de aprendizado <span class="math inline">\(A_l\)</span> utilizando como conjunto de treinamento todos os <span class="math inline">\(N\)</span> exemplos do base de dados de treinamento, com exceção do <span class="math inline">\(i\)</span>-ésimo exemplo de <span class="math inline">\(x\)</span>. Ou seja, cada algoritmo é aplicado ao conjunto de treinamento <span class="math inline">\(N\)</span> vezes, deixando de fora um exemplo de treinamento por vez.</p></li>
<li><p>Aplique cada classificador <span class="math inline">\(h_i^{(-i)}\)</span> ao exemplo <span class="math inline">\(x_i\)</span> para obter a classe predita <span class="math inline">\(y_i^l\)</span>. Com todas as classes preditas por cada um dos <span class="math inline">\(L\)</span> classificadores, haverá um novo conjunto de dados contendo exemplos de “nível 2” para que se possa analisar.</p></li>
<li><p>Por fim, basta aplicar algum algoritmo de aprendizado a este novo conjunto “nível 2” de treinamento para aprender <span class="math inline">\(h^*\)</span>.</p></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:stack"></span>
<img src="Figuras/stack.PNG" alt="Funcionamento do Algoritmo Stacking (Bernardini 2002)." width="100%" />
<p class="caption">
Figura 8.3: Funcionamento do Algoritmo <em>Stacking</em> <span class="citation">(Bernardini <a href="#ref-bernardini2002combinaccao">2002</a>)</span>.
</p>
</div>


</div>
<div id="rf" class="section level2">
<h2><span class="header-section-number">8.5</span> Floresta Aleatória - <em>Random Forest</em></h2>
<p>A <strong>Floresta Aleatória</strong>, do inglês <strong><em>Random Forest</em></strong> <span class="citation">(Breiman <a href="#ref-breiman2001random">2001</a>; Liaw, Wiener, and others <a href="#ref-liaw2002classification">2002</a>)</span>, é um classificador composto de classificadores projetados especialmente para árvores de decisão <span class="math inline">\(\{h_k(X),k=1,2,...,L.\}\)</span> onde <span class="math inline">\(T_k\)</span> são amostras aleatórias independentes e identicamente distribuídas e que cada árvore decide a classe mais popular para a entrada de <span class="math inline">\(X\)</span> (baixa correlação entre as árvores) . Vetores aleatórios são gerados a partir de uma distribuição e probabilidade fixa sobre o vetor de entrada inicial. A precisão da Floresta Aleatória é medida probabilísticamente em termos de margem do classificador, dado um conjunto de classificadores <span class="math inline">\(h_1(x), h_2(x),...,h_k(x)\)</span>, e um conjunto de treinamento aleatório a partir do vetor <span class="math inline">\(Y\)</span>, <span class="math inline">\(X\)</span> <span class="citation">(Gómez and others <a href="#ref-gomez2012random">2012</a>)</span>.</p>
<p>Como mencionado em <a href="ptII.html#decisiontree">7.2</a>, as Árvores de Decisão tendem a serem sensíveis à amostra de treinamento (ruídos). As Florestas Aleatórias buscam sanar este tipo de problema. A Floresta Aleatória é uma variação de <em>Bagging</em>, onde na construção da árvore, apenas um subconjunto aleatório das características participa da subdivisão de um nó. Pode-se melhorar a acurácia do modelo por meio da parametrização, que traz uma maior variação entre as árvores (mais estável que <em>bagging</em>).</p>
<p>Durante as construções das árvores, utiliza-se para medirmos o erro, o <strong><em>out of bag</em> (OOB)</strong>. Diferentemente dos erros tradicionais estimados (como validação cruzada, por exemplo), cada árvore de decisão dessa floresta construída a partir de um subconjunto (aleatório) de treinamento, pode ser testada com os exemplos que sobram (de fora) da classificação (exemplos <em>out of bag</em>). O próprio treinamento da Floresta Aleatória fornece uma estimativa de erro que denomina-se <strong>erro <em>out of bag</em> </strong>.</p>
<p>Um ótimo exemplo, elaborado e apresentado pela Ariane Machado Lima em uma de suas aulas online na Universidade de São Paulo (USP) sobre Florestas Aleatórias e o <em>out of bag</em> foi: imagine uma amostra de treinamento com duas classes e <span class="math inline">\(n=18\)</span> observações, como um dos parâmetros a serem definidos a quantidade de árvores de de decisões <span class="math inline">\(n\_estim=4\)</span> e amostras <em>bootstrap</em> (reposição) com <span class="math inline">\(obs=10\)</span> observações aleatórias em cada árvore que podem ou não serem repetidas.</p>
<p>Nesta amostra de treinamento será verificado quais elementos que situam-se fora de cada árvore composta por 10 observações (<em>OOB</em>) e quantas vezes fora para selecionar as árvores. Por exemplo, nesta mesma situação vamos supor que das três árvores de decisão, a observação 1 encontra-se dentro de uma árvore e <em>OOB</em> nas três restantes. Como a maioria das árvores não encontra-se esta observação específica, elas vão ditar a classificação desta observação (votação por maioria que pode acertar ou errar). Ao caso contrário da observação 2, por exemplo, encontra-se apenas em uma <em>OOB</em> e em três árvores de decisão. Portanto a <em>OOB</em> irá decidir a classificação desta observação. Assim sucessivamente até finalizar a contagem. Para as observações que não se encontram em nenhuma amostra, não serão contabilizadas no erro.</p>
<div class="figure" style="text-align: center"><span id="fig:outofbag"></span>
<img src="Figuras/outofbag.png" alt="Exemplificação de out of bag (MACHADO-LIMA 2020)." width="90%" />
<p class="caption">
Figura 8.4: Exemplificação de <em>out of bag</em> <span class="citation">(MACHADO-LIMA <a href="#ref-machadousprf">2020</a>)</span>.
</p>
</div>

<p>Para cada momento que temos 0 e 1 para classificar (ou até por regressão) cada elemento que estavam <em>OOB</em>, calcula-se a média das previsões como estimação de erro <em>out of bag</em>. Lembrando que permanece a medida de impureza na elaboração das árvores, como o índice de gini por exemplo.</p>
<p>Podemos dizer então que o erro <em>OOB</em> é o erro médio de predição em cada amostra de treinamento <span class="math inline">\(X_i\)</span>, no qual na construção de uma amostra-árvore haverá um conjunto de amostra de <em>bootstrap</em> (<em>in the bag</em>) e outro com dados não escolhidos no processo da amostragem (<em>out of bag</em>). Na construção da floresta (<span class="math inline">\(n\)</span> amostra-árvores) muitos exemplos de <em>bootstrap</em> e <em>OOB</em> elaborados. Estes conjuntos <em>OOB</em> podem ser agrupados em um conjunto de dados. Ao considerar <span class="math inline">\(Y\)</span> como a classe com a maioria dos votos, todas as vezes em que a observação foi considerada <em>OOB</em>, a proporção de vezes que <span class="math inline">\(Y\)</span> não for igual à verdadeira classe da observação, será a estimativa de erro <em>OOB</em>. Para o caso de problema de regressão, utiliza-se o método erro quadrado médio (MSE).</p>
<p>O procedimento <em>bootstrap</em> traz um melhor desempenho do modelo pois diminui a variância sem aumentar o viés, ou seja, embora as previsões de uma única árvore seja altamente sensível ao ruído em seu treinamento, a média de muitas árvores não será - desde que não sejam correlacionadas. Para estimarmos a incerteza das previsões de todas as árvores de regressão em <span class="math inline">\(x&#39;\)</span>, seu desvio padrão, podemos por meio da equação:</p>
<p><span class="math display" id="eq:desviorf">\[\begin{equation}
\sigma = \sqrt{\frac{\sum^B_{b=1}(f_b(x&#39;)-\hat{f})^2}{B-1}}
\tag{8.6}
\end{equation}\]</span></p>
<p>onde o <span class="math inline">\(B\)</span> é o número de árvores, um parâmetro livre que pode variar dependendo do conjunto de treinamento e a decisão do pesquisador.</p>
<p>Para calcularmos a importância de um atributo (<em>score</em>), para cada elemento <span class="math inline">\(e\)</span> e para cada árvore <span class="math inline">\(t\)</span>, permuta-se os valores de <span class="math inline">\(e\)</span> nos exemplos OOB de <span class="math inline">\(t\)</span>, ou seja: após permutarmos cada árvore terá uma nova votação em relação a cada elemento <span class="math inline">\(e\)</span> <em>OOB</em>, com novas classificações e novos erros <span class="math inline">\(OOB_p\)</span>. Podendo agora calcular a importância da variável <span class="math inline">\(e\)</span> e analizá-la como uma taxa de acréscimo sobre o erro.</p>
<p><span class="math display" id="eq:impc">\[\begin{equation}
\mbox{Importância de} \ e = \frac{(OOB_p-OOB)}{OOB}
\tag{8.7}
\end{equation}\]</span></p>
<p>O erro tradicional, geralmente utiliza-se todas as árvores como vantagem, porém é preciso dividir a amostra inicial em treinamento e teste. O <em>out of bag</em> utiliza toda a amostra, mas muitas vezes superestima o erro. Com a monitoração adequada dos parâmetros, como profundidade de cada árvore, número de atributos sorteados para cada divisão (com reposição), número de árvores, de nós por exemplo, pode ser melhorada esta superstimação e trazendo um bom modelo para o pesquisador.</p>
<p>Para aumentar a aleatoriedade no modelo. É possível utilizar o <em>bagging</em> em conjunto, onde cada novo conjunto de treinamento é criado por substituição a partir do novo vetor de entrada inicial. Uma nova árvore é induzida a partir de um novo conjunto de treinmaneto usando a seleção aleatória de atributos <span class="citation">(Gómez and others <a href="#ref-gomez2012random">2012</a>)</span>. Conforme <span class="citation">(Breiman <a href="#ref-breiman2001random">2001</a>)</span>, o uso do <em>bagging</em> melhora o desempenho quando características aleatórias são utilizadas; este método também pode ser usado para fornecer estimativas contínuas do erro generalizado do conjunto combinado de árvores, bem como estimativas para força e correlação com o estimador <em>OOB</em>. A força pode ser interpretada como medida de desempenho para cada árvore, uma árvore com uma baixa taxa de erro é um classificador forte. Aumentando a força das árvores individuais, reduz-se a taxa de erro de uma floresta, assim como a baixa correlação tende a diminuir <span class="citation">(Oshiro <a href="#ref-oshiro2013abordagem">2013</a>)</span>.</p>
<p>Um algoritmo que se tornou bem conhecido e bastante similar à Floresta Aleatória, é o <strong><em>Extra-Trees</em></strong> <span class="citation">(Geurts, Ernst, and Wehenkel <a href="#ref-geurts2006extremely">2006</a>)</span>. Neste caso, é adicionado mais uma camada de aleatoriedade para montar as árvores. O algoritmo utiliza como estratégia aleatória, na montagem dos nós ao invés de utilizar métricas como ganho de informação. Este acréscimo de aleatoriedade faz com que tenha uma diminuição no viés com menor custo computacional e dispêndio de tempo <span class="citation">(Machado and others <a href="#ref-machado2020avaliaccao">2020</a>)</span>.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-bernardini2002combinaccao">
<p>Bernardini, Flávia Cristina. 2002. “Combinação de Classificadores Simbólicos Para Melhorar O Poder Preditivo E Descritivo de Ensembles.” PhD thesis, Universidade de São Paulo.</p>
</div>
<div id="ref-freitas2020">
<p>Beserra, Gustavo Freitas. 2020. “Aplicação de Técnicas de Machine Learning Para Predição Em Uma Campanha de Marketing.”</p>
</div>
<div id="ref-breiman1996bagging">
<p>Breiman, Leo. 1996. “Bagging Predictors.” <em>Machine Learning</em> 24 (2): 123–40.</p>
</div>
<div id="ref-breiman2001random">
<p>Breiman, Leo. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1): 5–32.</p>
</div>
<div id="ref-chaves2012estudo">
<p>Chaves, Bruno Butilhão. 2012. “Estudo Do Algoritmo Adaboost de Aprendizagem de Máquina Aplicado a Sensores E Sistemas Embarcados.” PhD thesis, Universidade de São Paulo.</p>
</div>
<div id="ref-dietterich2000ensemble">
<p>Dietterich, Thomas G. 2000. “Ensemble Methods in Machine Learning.” In <em>International Workshop on Multiple Classifier Systems</em>, 1–15. Springer.</p>
</div>
<div id="ref-freund1999short">
<p>Freund, Yoav, Robert Schapire, and Naoki Abe. 1999. “A Short Introduction to Boosting.” <em>Journal-Japanese Society for Artificial Intelligence</em> 14 (771-780): 1612.</p>
</div>
<div id="ref-freund1997decision">
<p>Freund, Yoav, and Robert E Schapire. 1997. “A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting.” <em>Journal of Computer and System Sciences</em> 55 (1): 119–39.</p>
</div>
<div id="ref-freund1996experiments">
<p>Freund, Yoav, Robert E Schapire, and others. 1996. “Experiments with a New Boosting Algorithm.” In <em>Icml</em>, 96:148–56. Citeseer.</p>
</div>
<div id="ref-friedman1999bump">
<p>Friedman, Jerome H, and Nicholas I Fisher. 1999. “Bump Hunting in High-Dimensional Data.” <em>Statistics and Computing</em> 9 (2): 123–43.</p>
</div>
<div id="ref-geurts2006extremely">
<p>Geurts, Pierre, Damien Ernst, and Louis Wehenkel. 2006. “Extremely Randomized Trees.” <em>Machine Learning</em> 63 (1): 3–42.</p>
</div>
<div id="ref-gomez2012random">
<p>Gómez, Silvio Normey, and others. 2012. “Random Forests Estocástico.”</p>
</div>
<div id="ref-hastie2009elements">
<p>Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-ke2017lightgbm">
<p>Ke, Guolin, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. “Lightgbm: A Highly Efficient Gradient Boosting Decision Tree.” <em>Advances in Neural Information Processing Systems</em> 30: 3146–54.</p>
</div>
<div id="ref-liaw2002classification">
<p>Liaw, Andy, Matthew Wiener, and others. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22.</p>
</div>
<div id="ref-machado2020avaliaccao">
<p>Machado, Wylken dos Santos, and others. 2020. “Avaliação de Modelos de Classificação Automática de Atividades Diárias Para Dispositivos de Baixo Custo.”</p>
</div>
<div id="ref-machadousprf">
<p>MACHADO-LIMA, Ariane. 2020. “Reconhecimento de Padrões - Vídeo 4 Do Tema 9: Random Forests.” In. Universidade de São Paulo - Portal de vídeoaulas. <a href="http://eaulas.usp.br/portal/video.action?idItem=13856">http://eaulas.usp.br/portal/video.action?idItem=13856</a>.</p>
</div>
<div id="ref-marsh2016multivariate">
<p>Marsh, B. 2016. “Multivariate Analysis of the Vector Boson Fusion Higgs Boson.” <em>University of Missouri</em> 8.</p>
</div>
<div id="ref-mayrink2015avaliaccao">
<p>Mayrink, VTDM. 2015. “Avaliação Do Algoritmo Gradient Boosting Em Aplicações de Previsão de Carga Elétrica a Curto Prazo.” <em>Technical Report</em>.</p>
</div>
<div id="ref-merjildo2013algoritmo">
<p>Merjildo, Fernandez, Diego Alonso, and others. 2013. “Algoritmo Adaboost Robusto Ao Ruı́do: Aplicação à Detecção de Faces Em Imagens de Baixa Resolução.”</p>
</div>
<div id="ref-oshiro2013abordagem">
<p>Oshiro, Thais Mayumi. 2013. “Uma Abordagem Para a Construção de Uma única árvore a Partir de Uma Random Forest Para Classificação de Bases de Expressão Gênica.” PhD thesis, Universidade de São Paulo.</p>
</div>
<div id="ref-wolpert1992stacked">
<p>Wolpert, David H. 1992. “Stacked Generalization.” <em>Neural Networks</em> 5 (2): 241–59.</p>
</div>
<div id="ref-yamagishi2008phone">
<p>Yamagishi, Junichi, Hisashi Kawai, and Takao Kobayashi. 2008. “Phone Duration Modeling Using Gradient Tree Boosting.” <em>Speech Communication</em> 50 (5): 405–15.</p>
</div>
<div id="ref-zhang2015gradient">
<p>Zhang, Yanru, and Ali Haghani. 2015. “A Gradient Boosting Method to Improve Travel Time Prediction.” <em>Transportation Research Part C: Emerging Technologies</em> 58: 308–24.</p>
</div>
<div id="ref-zhou2012ensemble">
<p>Zhou, Zhi-Hua. 2012. <em>Ensemble Methods: Foundations and Algorithms</em>. CRC press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ptII.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="deeplearning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "github", "instagram"]
},
"fontsettings": ["white", "sepia", "night"],
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/09.1-bagging.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
