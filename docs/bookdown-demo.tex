\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Fundamentos de Machine Learning},
  pdfauthor={Elton Massahiro Saito Loures},
  pdfborder={0 0 0},
  breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{longtable,booktabs}
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage[utf8]{inputenc}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Fundamentos de Machine Learning}
\author{Elton Massahiro Saito Loures}
\date{2021-01-29}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{prefuxe1cio}{%
\chapter*{Prefácio}\label{prefuxe1cio}}
\addcontentsline{toc}{chapter}{Prefácio}

\hypertarget{por-que-ler-esse-livro}{%
\section{Por que ler esse livro?}\label{por-que-ler-esse-livro}}

\hypertarget{estrutura}{%
\section{Estrutura}\label{estrutura}}

\hypertarget{informauxe7uxf5es-a-respeito-do-conteuxfado}{%
\section{Informações a respeito do conteúdo}\label{informauxe7uxf5es-a-respeito-do-conteuxfado}}

\hypertarget{agradecimentos}{%
\section{Agradecimentos}\label{agradecimentos}}

\hypertarget{intro}{%
\chapter{Introdução}\label{intro}}

Caro leitor, se você veio até esse livro é bem provável que passou e/ou ainda passa pelas mesmas dificuldades que todo estudante interessado nessa área.

Ao elevado número de pesquisas que fiz para aprender o que era a Inteligência Artificial, o que era o \emph{Machine Learning} (Aprendizado de Máquina) e todos os outros temas similares, é nítido que ainda não está totalmente definido o conceito de cada um. É um ramo novo na área acadêmica, na indústria e em todo o mercado, com diversos temas, diversos modelos matemáticos, diversos modelos computacionais, diversos \emph{softwares}, diversas aplicações e em diversas áreas. Diversos ``diversos''\ldots{} E o mais assustador é que esse campo une todos esses ``diversos'', tornando o universo \textbf{caótico} ainda maior. Quando destaco o termo ``caótico'', refiro exatamente pela ironia deste mote, todo esse universo confuso é aplicado em nosso cotidiano para organizar, analisar, diagnosticar e facilitar as coisas.

Poucos instruem como devemos enxergar todo esse cosmos que ao longo da história está passando por diversas construções para estruturar seu conceito. Com uma tentativa de trazer isso com base em artigos, livros, vídeos, podcasts e cursos, disponho este simples livro com o propósito de organizar a imagem que você, leitor, tem de Aprendizado de Máquina e entender os principais modelos utilizados tanto no meio acadêmico, quanto no mercado de trabalho.

\hypertarget{dicas-de-estudo}{%
\section{Dicas de estudo}\label{dicas-de-estudo}}

Não cabe a mim dizer como estudar, mas o que posso lhe aconselhar como principal ponto é a \textbf{paciência}. Temas como esse podem abranger qualquer campo, desde a filosofia até a área da saúde e portanto, do mesmo modo que se aplica a qualquer conteúdo, o mais importante é a base. Leia, releia, pesquise, veja vídeos, ouça um podcast, converse e discuta com colegas e professores a respeito. Não se cobre de que precisa aprender o mais rápido possível, mas preze a qualidade do estudo.

Com intuito de explicar sobre Aprendizado de Máquina. Na seção \textbf{AQUI VOU COLOCAR A REFERENCIA DA SESSAO}, para faciliar o leitor dependendo de sua demanda de conteúdo, busquei separar em subseções a lógica computacional e a matemática. Tornando mais prático para o público que não tem interesse no modelo matemático e que busca o conhecimento de determinado assunto quanto ao público que demanda esse conteúdo.

\hypertarget{i-a}{%
\chapter{Inteligência Artificial (IA)}\label{i-a}}

\hypertarget{o-que-uxe9-ia-de-onde-veio-esse-conceito}{%
\section{O que é IA? De onde veio esse conceito?}\label{o-que-uxe9-ia-de-onde-veio-esse-conceito}}

Humano (taxonomicamente Homo sapiens), termo que derivado do latim ``homem sábio''. Pensamos, analisamos, aprendemos , prevemos e manipulamos. Somos seres \textbf{inteligentes}. Já pesquisou o significado de ``inteligência'' no dicionário?

É importante entender o conceito de inteligência, pois nem tudo que o ser humano faz pode ser classificado como inteligente. Aprender somar para calcular a soma de \(2+2\) é uma ação inteligente, mas copiar o resultado e colocar em sua folha de resultados que é 4 pode não ser tanto assim. Da mesma forma uma calculadora que executa um código passado por um humano, contendo dentro todos os passos a serem executados (algoritmos) para resolver esse cálculo, não é considerada.

Quando tratamos da inteligência artificial não é fácil definir o que ela é. O seu próprio conceito vem sendo discutido e moldado ao longo do tempo. A idéia de construir uma máquina pensante ou um ser artificial que se assemelhasse aos humanos é muito antigo. O mito do Golem, por exemplo, um dos primeiros seres artificiais criados pelo homem. Dizia a lenda que o mito do Golem surgiu no século XIII quando uma matéria informe tornou-se num homúnculo a partir da invocação mágica de Elijah de Chelm que escreveu em sua fronta \emph{``Shemhamforash''} - nome secreto de Deus \citep{moser2006golem}. Na literatura foi publicado o famoso romance \emph{Frankensteins} \citep{shelley1818frankenstein} que relata a história de um estudante que constrói um monstro em seu laboratório. Mas como ela realmente surgiu?

O primeiro trabalho a ser reconhecido como IA foi elaborado por \citet{mcculloch1943logical} que tinha como propósito estudar como os neurônios podiam funcionar, modelando uma rede neural simples com circuitos elétricos. Os mesmos autores sugeriram que as redes neurais definidas em conformidade poderiam ser capazes de aprender. Por seguinte, \citet{hebb1949organization} escreveu \emph{The Organization of Behavior} que fortalecia as teorias de que o condicionamento psicológico estava presente em qualquer parte dos animais. Teve como a premissa de que dois neurônios participantes de uma sinapse, têm ativação simultânea, então a força da conexão entre eles deve ser seletivamente aumentada, ou seja, os caminhos neurais são fortalecidos cada vez que são utilizados.

Em 1950, o matemático Claude E. Shannon publicou um artigo sobre como ``ensinar'' seu computador a jogar xadrez \citep{shannon1950xxii}; no mesmo ano Alan Turing, em ``\emph{Computing Machinery and Intelligence}'' \citep{turing1950computing},
sugeriu que, ao invés de perguntarmos se as máquinas podem pensar, devemos perguntar se as máquinas podem passar por um teste de inteligência comportamental, o teste de Turing. Uma forma de avaliar se uma máquina consegue se passar por um humano em uma conversa por escrito com um avaliador passando no teste caso o avaliador não conseguisse identificar se estava conversado com um computador ou com outro ser humano. No ano seguinte, os estudantes Marvin Minsky e Dean Edmonds construíram o SNARC, o primeiro computador de rede neural que simulava uma rede de 40 neurônios.

Em 1956 houve a conferência de verão em Dartmouth College (Hanover, New Hamphire), foi oficializada o nascimento da IA. John McCarthy, Minsky, Claude Shannon e Nathaniel Rochester elaboram uma proposta a fim de reunir pesquisadores dos Estados Unidos interessados em teoria de redes neurais, autômatos e estudo da inteligência:

\begin{quote}
Propusemos que um estudo de dois meses e dez homens sobre inteligência artificial fosse realizado durante o verão de 1956 no Dartmouth College, em Hanover, New Hampshire. O estudo foi para prosseguir com a conjectura básica de que cada aspecto de aprendizado ou qualquer outra característica da inteligência pode, em princípio, ser descrita com tanta precisão a ponto de
que uma máquina pode ser feita para simulá-la. Será realizada uma tentativa para descobrir como fazer com que as máquinas usem a linguagem, a partir de abstrações e conceitos, resolvam os tipos
de problemas hoje reservados aos seres humanos e se aperfeiçoarem. Achamos que poderá haver avanço significativo em um ou mais desses problemas se um grupo cuidadosamente selecionado de cientistas trabalhar em conjunto durante o verão.

--- ``A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence'' , \citet{mccarthy2006proposal} , Agosto de 1955.
\end{quote}

Entre diversas ideias e apresentações, Allen Newell e Herbert Simon apresentaram o programa logic theorist, capaz de provar diversos teoremas e segundo Simon, capaz de pensar não numericamente. Apesar de muitos editores não se agradarem, esta importante proposta trouxe nos próximos anos, uma dominação nesse campo \citep{russel2004inteligencia}:

\begin{itemize}
\item
  \emph{General Problem Solver} (GPS), projetado por \citet{newell1959variety}, é um sistema que buscava imitar o homem na forma de resolver problemas. Concluíram de que a forma em como dividia um objetivo em sub objetivos e possíveis ações era similar à forma em como o homem fazia. Esta pesquisa ajudou a estabelecer os fundamentos teóricos dos sistemas de símbolos e forneceram à área da IA uma série de técnicas de programação voltadas à manipulação simbólica, por exemplo, as técnicas de busca heurística;
\item
  a IBM produz alguns dos primeiros programas de IA, entre os quais, em 1959 o
  Geometry Theorem Prover;
\item
  Arthur Samuel desenvolveu um programa capaz de jogar damas ao nível de um
  jogador de torneio. O programa jogava melhor do que o seu autor;
\item
  John McCarthy no MIT, em 1958, define a linguagem de programação Lisp (List Processing) que se transformou na linguagem dominante
  da IA e publicou um artigo intitulado ``Programs with common sense'' \citep{mccarthy1968programs},
  onde descrevia um programa hipotético designado por ``Advice taker'', o qual pode
  ser visto como o primeiro sistema completo da IA;
\item
  \citet{slagle1963heuristic}, com o programa SAINT, foi capaz de resolver problemas de cálcuo integral;
\item
  \citet{evans1964program} e \citet{bobrow1967problems}, com os respectivos programas ANALOGY e STUDENT, resolviam problemas de análises geométricas semelhantes aos testes de QI e problemas clássicos de álgebra.
\item
  Em base de \citet{huffman1971impossible}, \citet{waltz1975understanding}, \citet{winograd1972understanding}, \citet{winston1970learning} e \citet{fahlman1974planning}, foi elaborado o mundo de blocos, que consiste em um conjunto de blocos sólidos colocados sobre uma mesa de modo que a mão de um robô reorganize-os.
\end{itemize}

Claro que os primeiros sistema houveram dificuldades com problemas mais difíceis. Desde traduções que exigiam conhecimento profundo para solucionar ambiguidades, por exemplo, como situações de necessidade de hardwares melhores e limitações fundamentais nas estruturas simples. Com ressalva, em \emph{Perceptrons} \citep{minsky1969perceptrons} demonstra que embora suas redes neurais simples (\emph{perceptrons}) pudessem aprender, eram capazes de representar muito pouco. Mas com exigência da formalização acadêmica na década de 70, permitiu o desenvolvimento de sistemas com grande desempenho intelectual com perspectivas industriais e comerciais, surgindo novos sistemas dispostos a resolver problemas mais complexos do que antes:

\begin{itemize}
\item
  DENDRAL \citep{buchanan1969heuristic}, analisa compostos orgânicos a fim de determinar sua estrutura molecular;
\item
  MYCIN \citep{buchanan1984rule}, Sistema pericial (expert system) foi capaz de diagnosticar infecções no sangue.
\end{itemize}

E sucessivamente foi crescendo este enorme e maravilhoso campo. O japão lança o projeto ``\emph{Fifth Generation}'' para construir em dez anos computadores inteligentes com capacidade de fazer milhões de inferências por segundo em 1981; uso de IA na guerra do Golfo em 1991; sistemas de perícia para casos médicos no mesmo ano; sistemas para condução de veículos automotores e detectores de colisões nas ruas (1993); reserva de viagens (1994); brinquedos inteligentes (2000); computador que se comunica ao nível de uma criança com 15 meses (2001). Ao longo dos anos da história da ciência da computação, a ênfase em \emph{algoritmos} e tratamento de dados vem aumentando.

\hypertarget{a-arte-de-uma-ia}{%
\section{A arte de uma IA}\label{a-arte-de-uma-ia}}

Atualmente, existem muitas atividades, pesquisas e aplicações em diversos temas que muitas vezes nem perbemos:

\begin{itemize}
\item
  Recomendações de mídia: com base em seu perfil de uso, o algoritmo compara filmes, músicas, clips, etc com base em vários usuários que possuem os gostos similares ao nosso. Recomedando aquilo que provavelmente irá nos agradar. Por exemplo \emph{Spotify}, \emph{YouTube} e \emph{Netflix}.
\item
  Reconhecimento de fala e assistentes virtuais: já refletiu sobre como funciona sua Google Assistente? Com ondas sonoras emitidas pela voz, o algoritmo reconhece palavras, frases e até mesmo o timbre, fornecendo respostas de acordo com o que recebe.
\item
  Jogos: a inteligência artificial desenvolvida pela \emph{OpenAi} conseguiu derrotar uma das melhores equipes do \emph{Dota 2} do mundo.
\item
  Logística: a crise de 1991, por exemplo, no Golfo Pérsico. Foi utilizada a DART \citep{cross1994dart}, uma ferramenta que envolveu até 50.000 veículos, transporte de carga aérea e pessoa simultâneamente com o objetivo de realizar um planejamento logístico automatizado levando em conta rotas, pontos de partida e resolução de conflitos.
\item
  Reconhecimento de imagens: identificação de objetos, pessoas, animais e qualquer figura com base em exemplos prévios, como por exemplo identificador de pessoas em uma foto do Facebook.
\item
  Verificação de compras: detecção de comportamentos suspeitos a partir do histórico e perfil do usuário, como a \emph{e-commerce}.
\item
  Automóveis autônomos: por meio do algoritmo, visualiza a estrada, as placas, condição climática, outros veículos e diversos outros obstáculos para tomar decisões de seu trajeto sem a necessidade de uma pessoa.
\end{itemize}

Poderíamos falar desde exemplos de inteligência artificial aplicados em casos jurídicos, diagnósticos na área da saúde, identificadores de \emph{fake news} (notíficas falsas) até a robótica. É uma extensa lista de exemplos na área que até hoje estão em desenvolvimento em busca de cada vez mais melhorar. A AGI (\emph{Artificial General Intelligence}), ou Inteligência Artificial Geral, trabalha na criação de uma inteligência artificial generalista, similar a humana, capaz de ser especialista em uma área, mas também aprender com facilidade outras. Uma área que se tornou uma das principais linhas de pesquisa e nos dias de hoje gera discussões sobre até onde a IA pode alcançar.

\hypertarget{vertentes-de-uma-ia-e-fundamentauxe7uxe3o-filosuxf3fica}{%
\section{Vertentes de uma IA e fundamentação filosófica}\label{vertentes-de-uma-ia-e-fundamentauxe7uxe3o-filosuxf3fica}}

\begin{quote}
Os filósofos têm estado por aí há muito mais tempo que os computadores e vêm tentando resolver algumas questões que se relacionam à IA: como a mente funciona? É possível que as máquinas ajam com inteligência, de modo semelhante às pessoas, e, se isso acontecer, elas realmente terão mentes conscientes? Quais são as implicações éticas de máquinas inteligentes?

``Inteligência Artificial'', \citet{russel2013inteligencia}.
\end{quote}

Com todo o desenvolvimento da IA, os algoritmos podem funcionar em níveis
humanos em tarefas que aparentemente envolvem julgamento humano ou, como Turing acrescentou,
``aprender a partir da experiência'' e a capacidade de ``distinguir o certo do errado''\citep{russel2013inteligencia}. Paul Meehl \citep{meehl1954clinical} analisou os processos de tomada de decisão de especialistas treinados em tarefas subjetivas como prever o sucesso de um aluno em um programa de
treinamento ou a reincidência de um criminoso e descobriu que algoritmos simples de aprendizado estatístico fizeram previsões melhores que os especialistas.

A reflexão sobre ``máquinas inteligentes e pensantes'' é recente em nossa história e passa por longas discussões sobre o alcance dessa inteligência. Desde a classificação elaborada pelo filósofo John Searle em 1980, tomou-se na doutrina em geral a divisão do uso da inteligência
artificial em \textbf{``fraca''} e \textbf{``forte''} \citep{searle1980minds}.

A inteligência artificial \textbf{fraca} ``nos permite formular e testar hipóteses de forma mais rigorosa e precisa'', no entanto, ela é dependente da inserção do conhecimento fornecido pelo ser humano que a programa. A máquina não é capaz de produzir raciocínios próprios, autônomos \citep{searle1980minds, guimaraes2019inteligencia}. Seartle também explica que a máquina adequadamente preparada é realmente uma
mente, no sentido de que os computadores que recebem os programas certos poderiam estar, literalmente, preparados para compreender eter outros estados cognitivos \citep{searle1980minds}.

\citet{searle1980minds} em seu \emph{naturalismo biológico}, critica a inteligência artificial forte pois, segundo ele, as máquinas não possuem a complexidade de sistema nervoso, neurônios com axonios e dendritos e tudo mais. Para corroborar sua crítica, Searle descreve uma situação hipótetica simulando um programa que passa pelo teste de turing e que ``não entende nada de suas entradas e saídas'', não havendo os requisitos para ser considerada uma mente.

O sistema foi nomeado como \textbf{``quarto chinês''}. Ele se usa como exemplo com a situação de que não tem conhecimento da língua chinesa, estaria trancada e isolado num quarto recebendo uma folha de papel com ideogramas em chinês escritos. Por não conhecer a língua, não possui ideia alguma do que se trata. Em seguida, ele recebe uma seguda folha com ideiogramas chineses acompanhados de um conjunto de regras em inglês (língua nativa) que permitem a correlação da segunda folha com a primeira. Por fim, recebe uma terceira folha com ideogramas chineses, com regras em inglês que orientam a dar em respostas específicos ideogramas chineses associados a outros ideogramas da terceira folha, correlacionando os elementos da atual com as duas anteriores. As pessoas externas do quarto denominam a terceira folha como o ``script'', a segunda folha de ``história'' e a primeira folha de ``questões''. Essas pessoas consideram que os símbolos que Searle entregou em resposta à terceira folha são as ``respostas às questões'' e todo o conjunto de regras que lhe foi entrega são o ``programa'' \citep{guimaraes2019inteligencia}.

Com o tempo Searle se torna melhor em dar respostas de acordo com as regras que permitem manipular os ideogramas chieses e de maneira similar ocorre com os programadores externos do quarto, que ficam bos em escrever os programas do ponto de vista externo. Qualquer pessoa que observa as resposta de Searle não contestaria de que Searle não fala chinês. Da mesma forma se o mesmo experimento fosse feito com textos em inglês, sua língua nativa, ele daria respostas em patamares semelhantes \citep{guimaraes2019inteligencia}.

Searle conclui que no caso em chinês ele opera como um computador, respondendo corretamente mas sem a menor ideia do que está respondendo. Ao caso em inglês, ele irá responder como um ser humano e com consciência de suas respostas. O quarto se refere ao computador, o ser humano ao \emph{software} de IA. Com isso ele assume que só seria possível produzir artificialmente uma máquina com sistema suficientemente semelhante a nós se poder duplicar exatamente as causas e seus efeitos, assim de fato seria possível produzir consciência, intencionalidade (fenômeno biológico dependente da
bioquímica específica de suas origens) e tudo o mais usando princípios químicos diferentes dos usados por seres humanos \citep{searle1980minds} .

Em contestamento a Searle, Daniel Dennett defende o projeto de Turing porque agir inteligente consiste na capacidade de processamento de informação \citep{dennett2009part}. Segundo Dennett, o problema da mente deve ser abordado com base na teoria evolutiva darwiniana pois o que entendemos por mental está relacionado ao tipo de resposta que nosso organismo dá para as demandas que estão para além daquelas que dizem respeito à manutenção da vida \citep{da2013searle}. Para ele, como ele denomina de \emph{intencionalidade intrínseca}, Seartle errou em atribuir aos humanos a intencionalidade produzida exclusivamente pela interação das partes que constituem uma totalidade complexa, não necessitando de influências ou interferências externas. Para Dennet nossa intencionalidade não é original \citep{dennett2009part}.

Para Dennet o principal argumento criticando o argumento do quarto chinês, é a forma como investigamos os fenômenos mentais. É uma região que possibilita infinitas especulações, sendo o método das ciências empíricas o mais apropriado ao estudo da mente \citep{da2013searle}.

A diferença entre ambos é de natureza filosófica com ontologias e epistemologias divergentes. É notável a importância das discussões filosóficas. O antagonismo dicotômico dos dois filósofos possuem fundamentações que auxiliam na compreensão da mente. Quando teremos estas respostas? As máquinas serão capazes de raciocinar algum dia? Até onde uma IA pode chegar?

\hypertarget{machinelearning}{%
\chapter{O Aprendizado de Máquina}\label{machinelearning}}

Agora que entendemos o conceito e a origem de uma IA, podemos entrar no tão esperado \textbf{Machine Learning (ML)}. Alguns pensam erroneamente ser algo distinto de uma IA, mas é importante entender que ela é um campo específico da inteligência artificial que tem como base a ideia de que sistemas podem aprender com dados e iterações, identificar padrões para que aprimorem seu desempenho diante de problemas específicos e possam tomar decisões com a menor intervenção humana possível. Como modelos estatísticos, busca entender a estrutura dos dados modelos que atendam a certos pressupostos - muitas vezes não temos conhecimento de como essa estrutura se parece.

\citet{samuel1959some}, engenheiro do MIT popularizou o termo \emph{``Machine Learning''} (Aprendizado de Máquina), descrevendo o conceito com ``um campo de estudo que dá aos computadores a habilidade de aprender sem terem sidos programados para tal'' \citep{simon2013too}. Com a expansão da internet e seu abundante armazenamento de dados na web, o \emph{Big data}, foi necessário - ainda é - aprimorar sistemas de organização, classificação, análise de dados e identificação de padrões para tratá-los. Isso fez com que o Aprendizado de Máquina entrasse em destaque e passasse a ser uma das áreas mais importantes. Na seção \ref{i-a} foi apresentado alguns exemplos de aplicações de IA, o mesmo se aplicam para o ML.

Um aprendizado de máquina \textbf{não} é o mesmo que uma lista de instruções. Imagine uma criança aprendendo a andar de bicicleta, ela pode até receber algumas instruções para melhorar seu aprendizado, mas provável que ela irá aprender melhor com a tentativa e erro. Pedala, cai, levanta, pedala novamente e assim sucessivamente até ela realmente saber andar. Da forma similar ocorre com o Aprendizado de Máquina.

\hypertarget{como-a-muxe1quina-aprende}{%
\section{Como a máquina aprende?}\label{como-a-muxe1quina-aprende}}

Você é um vendedor e está interessado em clientes ``bons pagadores'' e ``maus pagadores''. Para cada cliente, possui um conjunto de dados como: idade, quantidade de faturas pagas antes do vencimento nos últimos 12 meses, quantidade de faturas atrasadas nos últimos 12 meses, região que reside, tempo de cadastro, etc. Você já se encontra com um banco de dados muito grande de clientes com seus respectivos dados e classificações como bons pagadores e maus pagadores e pretende utilizar um algoritmo de ML para aprender com esses dados de modo que, quando você receber o banco de dados de um novo cliente, esse algoritmo pode prever se a tendência desse cliente seria de bom pagador ou mau pagador.

Primeiramente, você iria alimentar seu algoritmo de ML com os dado históricos que passaram por toda uma análise se havia dados faltantes, redundantes, etc e já classificados entre cliente bom pagador e mau pagador e suas respectivas características para treiná-lo. Com estes dados o algoritmo irá aprender por meio de com quais condições são necessárias para o cliente ser classificado como bom pagador ou mau pagador. Importante ressaltar que existem diferentes algoritmos de Aprendizado de Máquina que poderiam resolver esse problema, de acordo com modelos estatísticos e comandos computacionais que atendam a certos pressupostos.

\begin{itemize}
\tightlist
\item
  \textbf{Como verificarmos se os dados já estão bons para aplicar o algoritmo? Quais modelos podemos aplicar? Como sabemos que essas previsões são confiáveis? Como evitar problemas de um modelo ruim?}
\end{itemize}

Agora que temos todo o contexto histórico podemos ir adiante do conteúdo aplicado. A tópico a seguir trataremos um pouco de alguns conceitos muito importantes que são utilizados em muitos algoritmos de Aprendizado de Máquina para que possamos gradualmente responder estes questionamentos.

\hypertarget{dicio}{%
\chapter{Um pouco de revisão}\label{dicio}}

Com os \emph{softwares} atuais é possível de que o pesquisador consiga fazer uma análise dos dados sem compreender totalmente a matemática por trás. Busco sempre que puder anexar um exemplo de acordo com cada tema apresentado para facilitar a compreensão, porém suponho de que o leitor esteja familiarizado com conceitos fundamentais de estatística, probabilidade e álgebra liner, portanto conceitos fundamentais como tipos de amostragem, probabilidades e suas distribuições, teste de hipóteses e significância, potência dos testes estatísticos, intervalos de confiança, escalares e vetores, espaço vetorial e transformação linear, produto interno, assimetria e curtose, entre outos..

Nesta seção são apresentadas brevemente um pouco desses conteúdos. É provável de que o leitor já saiba. Porém acredito de que sejam fundamentais para o Aprendizado de Máquina e seria bom para revisá-lo. Sinta-se livre em pular este capítulo. Ao caso de ser algo totalmente novo, reforço-o de introduzir com outras literaturas a respeito, pois são imprescindíveis aos conteúdos dos próximos capítulos.

\textbf{Bons estudos}.

\hypertarget{um-pouco-de-uxe1lgebra-linear}{%
\section{Um pouco de Álgebra Linear}\label{um-pouco-de-uxe1lgebra-linear}}

\begin{itemize}
\item
  \textbf{Escalares e Vetores:}
\item
  \textbf{Espaço Vetorial e Transformação Linear:}
\item
  \textbf{Produto Interno:}
\end{itemize}

\hypertarget{um-pouco-de-estatuxedstica.-parte-i}{%
\section{Um pouco de Estatística. Parte I}\label{um-pouco-de-estatuxedstica.-parte-i}}

\begin{itemize}
\item
  \textbf{Assimetria e Curtose:}
\item
  \textbf{Variância e Desvio padrão (Erro padrão)}
\item
  \textbf{Covariância:} a covariância mede a relação linear entre duas variáveis. É possível utilizar a covariância para compreender a direção da relação entre as variáveis. Valores de covariância positivos indicam que valores acima da média de uma variável estão associados a valores médios acima da outra variável e abaixo dos valores médios são igualmente associado. Valores de covariância negativos indicam que valores acima da média de uma variável estão associados com valores médios abaixo da outra variável.
\item
  \textbf{Distribuição normal:}
\item
  \textbf{Distribuição binomial:}
\item
  \textbf{Distribuição de Poisson:} \citep{banzatto1992experimentaccao} Quando número de plantas daninhas por parcela, número de insetos capturados em armadilhas luminosas, número de pulgões ou ácaros por folhas, etc.
\item
  \textbf{Teorema de Bayes:} quando tratamos de probabilidades, \(P(A|B)\) e \(P(B|A)\) podem ser parecidos, mas possuem grande diferença entre as probabilidades que representam. Por exemplo \(P(A|B)\) pode se referir sobre a probabilidade de uma pessoa que cometeu um furto (B) ser condenada (A) e \(P(B|A)\) seria a probabilidade de uma pessoa que foi condenada por furto ter efetivamente cometido um crime. A causa se torna o efeito e o efeito se torna a causa \citep{freund2009estatistica}.
\end{itemize}

Pela regra geral de multiplicação que afirma que a probabilidade da ocorrência de dois eventos é o produto da probibilidade da ocorrência de um deles pela probabilidade condicional da ocorrência do outro evento, temos:

\begin{equation} 
 P(A \bigcap B)= P(A). P(B|A) \  \mbox{ou} \ P(A \bigcap B)= P(B). P(A|B)
  \label{eq:multprob}
\end{equation}

Igualando ambas expressões, temos: \$ P(A). P(B\textbar{}A) = P(B). P(A\textbar{}B)\$ e portanto, divindo por \(P(B)\), obtém-se o Teorema de Bayes que descreve a probabilidade de um evento, baseado em um conhecimento a \emph{priori} que pode estar relacionado ao evento:

\begin{equation} 
 P(A|B) = \frac{P(A).P(B|A)}{P(B)}
  \label{eq:bayes}
\end{equation}

Para \(B_n\) e \(A_k\) atributos, podemos reescrever:

\begin{equation} 
 P(A_k|B_1,...,B_n) = \frac{P(A_k).P(B_1,...,B_n|A_k)}{P(B_1,...,B_n)}
  \label{eq:bayesn}
\end{equation}

\textbf{Exemplo:} este exemplo pode ser encontrado em \citet{freund2009estatistica}. Numa certa empresa, 4\% dos homens e 1\% das mulheres têm mais de 1,75m
de altura, respectivamente, sendo que 60\% dos trabalhadores são mulheres. Um trabalhador é escolhido ao acaso.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Qual a probabilidade de que tenha mais de 1,75m?
\end{enumerate}

Temos de informação de que 60\% dos trabalhadores são mulheres e que 1\% delas possuem mais de 1,75m. Portanto 40\% dos trabalhadores são homens, sendo 4\% deles com mais de 1,75m. Logo temos que:
\[P(> 1, 75m) = (0, 04 . 0.4) + (0, 01 . 0.6) = 0, 022 \\ → 2, 2\% \ \mbox{ de probabilidade de que tenha mais de 1,75m.}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  E que seja homem dado que o trabalhador escolhido tenha mais de 1,75m?
\end{enumerate}

Pelo enunciado ``que seja homem dado que o trabalhador escolhido tenha mais de 1,75m'', podemos perceber que já possuímos uma afirmação que já foi escolhido uma pessoa que tenha mais que 1,75m e queremos saber se é homem. Por meio da questão anterior sabemos a probabilidade P(\textgreater{} 1,75m). Portanto:
\[P(H| > 1, 75m) = \frac{P(> 1, 75m|H).P(H)}{P(> 1, 75m)}=\frac{0,04.0,4}{0, 022} \]

\[→ 72,73\% \ \mbox{de probabilidade de ser homem dado que seja maior que 1,75m.}\]

\begin{itemize}
\tightlist
\item
  \textbf{Função de verossimilhança:} a verossimilhança \(L\) de um conjunto de parâmetros \(\theta\), com dada informação \(x\). É igual a probabilidade da mesma observação \(x\) ter ocorrido dados os valores dos mesmos parâmetros \(\theta\). Conhecendo um parâmetro \(\theta\), a probabilidade condicional de \(x\) é \(P(x|\theta)\), mas se o valor de \(x\) é conhecido, pode-se realizar inferências sobre o valor de \(\theta\) \citep{bolfarine2001introduccao}.
\end{itemize}

\begin{equation} 
 L(\theta |x)=P(x| \theta)
  \label{eq:fverossimilhanca}
\end{equation}

Para ``\(n\)'' valores:

\begin{equation} 
 L(\theta |x_1,..., x_n)=\prod_{i=1}^{n} P(x_i| \theta)
  \label{eq:fsumverossimilhanca}
\end{equation}

Geralmente utiliza-se o logaritmo natural em verossimilhança \(L(\theta |x)=ln L(\theta|x)\) como função suporte e facilitar em seu estudo.

Para facilitar a compreensão, considere a observação de que você esteja ouvindo barulho em sua sala de estar num dia de natal (observação \(x\)), você parte da hipótese inicial que poderia ser o ``Papai Noel'' lhe entregando presentes (hipótese \(\theta\)). A probabilidade de ser Noel lhe entregando presente apenas porque ouviu o barulho, isto é, \(P(\theta|x)\) é baixa. No entanto o contrário, você com a afirmação de que é o Noel lhe entregando presentes, a probabilidade de haver barulho em sua sala de estar é bem alta, logo a verossimilhança \(L(\theta|x)=P(x|\theta)\).

\begin{itemize}
\item
  \textbf{Parâmetros:} podem ser vistos como características númericas de um modelo ou população. Os valores não podem ser mensurados diretamente mas que podem ser estimados através dos dados de uma amostra.
\item
  \textbf{Paramétrico x Não Paramétrico:}
\end{itemize}

\hypertarget{um-pouco-de-estatuxedstica.-parte-ii}{%
\section{Um pouco de Estatística. Parte II}\label{um-pouco-de-estatuxedstica.-parte-ii}}

\begin{itemize}
\tightlist
\item
  \textbf{Teorema do Limite Central:} quando é utilizado a média amostral para estimar a média de uma população, ocorre-se incertezas em relação ao erro. O Teorema do Limite Central é um teorema fundamental para a estatísticas e faz com que possa ser aplicado independente da forma da distribuição da população. Ele diz que se \(\overline{x}\) é a média de uma amostra aleatória de tamanho \(n\) de uma população infinita com a média \(\mu\) e o desvio-padrão \(\sigma\) e se \(n\) é grande o suficiente (em geral \(n=30\)), então possui próximo a distribuição normal padrão:
\end{itemize}

\begin{equation} 
 z=\frac{\overline{x}-\mu}{\sigma / \sqrt{n}}
  \label{eq:teoremacentralimite}
\end{equation}

Este teorema também pode ser utilizado para populações finitas, mas não é comum e são poucas situações de que haja esta possibilidade. A utilização mais comum é quando \(n\) é grande enquanto \(\frac{n}{N}\) pequeno.

\textbf{Exemplo \citep{fariaestatistic}:} O fabricante de uma lâmpada especial afirma que o seu produto tem vida média de 1.600 hors, com desvio padrão de 250 horas. O dono de uma empresa compra 100 lâmpadas desse fabricante. Qual é a probabilidade de que a vida média dessas lâmpadas ultrapasse 1.650?

Podemos aceitar que as 250 lâmpadas compradas sejam uma amostra aleatória simples da população referente às lâmpadas produzidas por esse fabricante. Como \(n=100\) é um tamanho suficientemente grande de amostra, é possível utilizarmos o Teorema Central do Limite e entender que \(X=\)vida útil de uma lâmpada se aproxima da distribuição normal \(\overline{X}\approx N(\mu;\frac{\sigma^2}{n})\). Logo:
\[\overline{X}\approx N(1600;\frac{250^2}{100})\]
\[Pr(\overline{X}>1650)=Pr\bigg( \frac{\overline{X}-1600}{\sqrt{\frac{250^2}{100}}}>\frac{1650-1600}{\sqrt{\frac{250^2}{100}}} \bigg)\]
\[=Pr(Z>2,0)\]
\[=0,5-tab(2,0)\]
\[=0,5-0,47725=0,02275\]
A probabilidade de que a vida média dessas lâmpadas ultrapasse 1.650 é de 2,275\%.

\begin{itemize}
\tightlist
\item
  \textbf{Testes de hipóteses:}
\end{itemize}

\begin{quote}
Uma hipótese estatística é uma afirmação ou conjectura sobre um parâmetro, ou parâmetros, de uma população (ou populações); pode também se referir ao tipo, ou natureza, da população (ou populações).

--- \citet{freund2009estatistica}.
\end{quote}

O Teste de Hipóteses é um procedimento estatístico que os permitem rejeitar ou não rejeitar uma hipótese estatística por meio dos dados observados de uma amostra. Para desenvolver os processos de testes de hipóteses estatísticas precisamos saber precisamente o que esperar quando uma hipótese é verdadeira, por isso em geral formula-se a hipótese contrária àquela que queremos provar. Supondo que estamos desconfiados em um jogo que seus dados não são honestos, ao formularmos a hipótese de que esses dados são viciados, dependeria do quão viciados eles são. Porém, ao supor que eles são perfeitamente equilibrados, poderíamos calcular todas as probabilidades necessárias para concluirmos a hipótese. Se pretendermos verificar que a análise de um analista de dados é mais eficiente do que o outro, iremos formular a hipótese de que ambos são igualmente eficientes. Se a durabilidade de uma camisa feita por algodão é maior que uma camisa feita por políester, formularemos a hipótese de que ambas possuem as durabilidades iguais. A hipótese de não haver diferença (hipóteses iguais) denominamos como \textbf{hipóteses nulas (\(H_0\))}, utilizada para qualquer hipótese estabelecida prioritariamente para ver se ela pode ser rejeitada. A hipótese ue aceitamos quando rejeitamos a nula, é chamada de \textbf{hipótese alternativa (\(H_A\))} \citep{freund2009estatistica}. Vamos seguir alguns exemplos de \citet{freund2009estatistica}.

\textbf{Exemplo:} um psicólogo pretende determinar se o tempo médio de reação de um adulto a um estímulo visual é realmente de 0,38 segundos. Sua hipótese nula
\[H_0: \mu=0,38\ \mbox{segundos}\]
contra a hipótese alternativa
\[H_A: \mu \neq 0,38\ \mbox{segundos}\]
em que \(\mu\) é o tempo médio de reação de um adulto ao estímulo visual. Para realizar o teste, o psicólogo decide tomar uma amostra aleatória de \(n=40\) adultos com objetivo de aceitar a hipótese nula se a média da amostra cair em algum ponto entre 0,36 e 0,40 segundos; do contrário a hipótese será rejeitada. Como a decisão se baseia em uma amostra, existe a possibilidade de a média amostral ser menor do que 0,36 segundos ou maior que 0,40 segundos mesmo se a verdadeira média amostral ser 0,38 segundos. Da mesma forma é possível que a média amostral esteja entre os intervalos de 0,36 e 0,40 segundos mesmo que a verdadeira média possua, por exemplo, 0,41 segundos. Portanto, é importante investigar a probabilidade de que o teste nos leve a uma decisão errada.

Vamos supor que o desvio padrão seja \(\sigma=0,08\) segundos para estes dados e investiguemos a possibilidade de rejeitar falsamente a hipótese nula. Iremos supor que o verdadeiro tempo médio de reação seja 0,38 segundos, então encontramos a probabilidade de que a média amostral vá ser menor ou igual a 36 segundos ou maior igual a 40. A probabilidade de que isso ocorra é dada pela somas das áreas das duas regiões coloridas apresentadas na Figura \ref{fig:testehip1} a seguir, e pode ser determinada pela distribuição amostral da média por uma distribuição normal.

Supondo que a população amostrada possa ser tratada como sendo infinita, a média da distribuição amostral é dado por:

\[\sigma_{\overline{x}}=\frac{\sigma}{\sqrt{n}}=\frac{0,08}{\sqrt{40}}\approx 0,0126\]
A linha de divisória em unidades padronizadas, são:
\[z=\frac{0,36-0,38}{0,0126}\approx -1,59 \ \mbox{e} \ z=\frac{0,40-0,38}{0,0126}\approx 1,59\]

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/testehip1} 

}

\caption{Critério de teste e distribuição amostral de \(\overline{x}\) com \(\mu =0,38\) segundos \citep{freund2009estatistica}.}\label{fig:testehip1}
\end{figure}



Por meio da Tabela Z (tabela I do livro estatistica que vou por) observamos que a área da cauda da distribuição amostral da será \(0,50000-0,4441=0,0559\). Portanto a probabilidade de obter um valor em uma ou em outra cauda da distribuição será de \(2(0,0559)=0,1118\).

Vamos agora com a possibilidade de que o teste deixa de detectar que a hipótese nula é falsa, ou seja \(\mu \neq 0,38\) segundos. Portanto iremos supor que o verdadeiro tempo médio de reação seja de 0,41 segundos. Obtendo uma média amostral no intervalo de 36 a 40 segundos levaria à aceitação errônea da hipótese nula de \(\mu=0,38\) segundos. Portanto a média da distribuição amostral será:

\[\sigma_{\overline{x}}=\frac{\sigma}{\sqrt{n}}=\frac{0,08}{\sqrt{40}}\approx 0,0126\]
As linhas divisórias em unidades padronizadas, são:
\[z=\frac{0,36-0,41}{0,0126}\approx -3,77 \ \mbox{e} \ z=\frac{0,40-0,41}{0,0126}\approx -0,79\]

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/testehip2} 

}

\caption{Critério de teste e distribuição amostral de \(\overline{x}\) com \(\mu =0,41\) segundos \citep{freund2009estatistica}.}\label{fig:testehip2}
\end{figure}



Por fim cabe ao psicólogo decidir qual risco é aceitável: a probabildiade de 0,11 de rejeitar erroneamente a hipótese nula de \(\mu = 0,38\) ou a probabilidade 0,21 de erroneamente aceitá-la quando na realidade é \(0,41\).

Portanto resume-se em:

\begin{longtable}[]{@{}lll@{}}
\caption{\label{tab:tabelahipotese} Resumo de uma situação típica dos testes de hipóteses.}\tabularnewline
\toprule
& \textbf{Aceitar \(H_0\)} & \textbf{Rejeitar \(H_0\)}\tabularnewline
\midrule
\endfirsthead
\toprule
& \textbf{Aceitar \(H_0\)} & \textbf{Rejeitar \(H_0\)}\tabularnewline
\midrule
\endhead
\textbf{\(H_0\) é verdadeiro} & Decisão Correta & Erro tipo I\tabularnewline
\textbf{\(H_0\) é falso} & Erro tipo II & Decisão Correta\tabularnewline
\bottomrule
\end{longtable}

Se a hipótese nula \(H_0\) é verdadeira e aceita ou falsa e rejeitada, a decisão é correta em ambos casos; se é verdadeira e rejeitada ou falsa aceita. O erro tipo I e a probabilidade de obtê-lo é ocorrida pela letra grega \(\alpha\) e o erro tipo II pelo \(\beta\). Portanto pelo exemplo, temos que \(\alpha=0,11\) e \(\beta=0,21\) quando \(\mu=0,41\) e o psicólogo deve decidir se aceita ou rejeita a hipótese nula de \(\mu=0,38\)

\begin{itemize}
\tightlist
\item
  \textbf{Região Crítica e nível de significância:} no geral definimos uma região crítica (RC) como o conjunto de valores no qual a probabilidade de ocorrência é pequena sob a hipótese de ser verdade o \(H_0\). Por exemplo: lançada 30 vezes uma moeda, sendo obtida num total de 28 caras. Claramente iremos desconfiar que é uma moeda honesta, visto que a probabilidade de ser obtida 28 caras em 30 lançamentos de uma moeda honesta é de 0,000000433996. Mesmo que haja essa mínima possibilidade de que a moeda honesta acerte este evento, pela perspectiva do teste de hipóteses, a obtenção de tal evento será uma evidência de que a nossa hipótese nula de honestidade da moeda não é muito plausível. Assim não dizemos que a moeda não é honesta, concluímos que não há evidência suficiente para apoiar a hipótese nula \citep{fariaestatistic}.
\end{itemize}

A definição dessa pequena probabilidade se faz por meio da escolha do \textbf{nível de significância \(\alpha\)} do teste, expressa como:

\begin{equation} 
 \alpha=Pr(\mbox{Erro tipo I})=Pr(\mbox{rejeitar} \ H_0|H_0 \ \mbox{é verdadeira})
  \label{eq:nivelsignificancia}
\end{equation}

Geralmente é utilizado em \(\alpha=0,05\), \(\alpha=0,01\) ou \(\alpha=0,10\) como nível de significância, com isso torna-se possível estabelecer a região crítica usando a distribuição amostral da estatística de teste \citep{fariaestatistic}.

De \citet{fariaestatistic}, segue:

\textbf{Exemplo 1:} Considere uma população representada por uma variável aleatória normal com média \(\mu\) e variância 400. Queremos testar:

\[H_0:\mu = 100\]
\[H_A:\mu \neq 100\]
Com base em uma amostra aleatória simples de tamanho \(n=16\). Para tal define-se a região crítica como RC: \(\overline{X}<85\) ou \(\overline{X}>115\). Qual é a probabilidade do erro tipo I?

\[\alpha=Pr(\mbox{Erro tipo I})=Pr(\mbox{rejeitar} \ H_0|H_0 \ \mbox{é verdadeira})\]
\[=Pr[\{\overline{X}<85\} \cup \{\overline{X}>115\} \ | \ \overline{X}\sim N(100;\frac{400}{16}=25)]\]
\[=Pr[\overline{X}<85 \ | \  \overline{X}\sim N(100;25)]+Pr[\overline{X}>115 \ | \ \overline{X}\sim N(100;25)]\]
\[=Pr\bigg( Z<\frac{85-100}{5} \bigg)+Pr\bigg( z>\frac{115-100}{5} \bigg)\]
\[=Pr(Z>-3)+Pr(Z>3) \rightarrow 2.Pr(Z>3)\]
\[\alpha=0,0027\]

\begin{itemize}
\tightlist
\item
  \textbf{Aplicações do Teste de Hipótese - Média com a variância conhecida:} ao caso de interessarmos na média de uma população normal e supondo que a variância seja conhecida. Pelo teste temos que:
\end{itemize}

\begin{equation} 
z=\frac{\overline{X}-\mu_0}{\sigma/\sqrt{n}}
  \label{eq:testehipmedia}
\end{equation}

onde \(\mu_o\) é o valor da média que ocorre sobre a hipótese nula. Trabalhar com unidades padronizadas \(z\) nos permitem formular vários critérios que se aplicam a muitos problemas diferentes. Lembrando que são amostras suficientemente grandes para que a distribuição amostral da média possa ser próxima por uma distribuição normal padrão.

\textbf{Exemplo \citep{freund2009estatistica}:} Uma oceanógrafa com base numa amostra aleatória de tamanho \(n=35\) e ao nível 0,05 de significância, quer testar se a profundidade média do oceano numa determinada área é de 72,4 metros conforme registrado. O que ela decidirá se obtiver \(\overline{x}=73,2\) metros e se puder supor, usando informações de estudos anteriores análogos, que \(\sigma=2,1\) metros?

\[H_0: \mu=72,4 \mbox{metros}\]
\[H_A: \mu \neq 72,4 \mbox{metros}\]
Temos que \(\alpha=0,05\), ou seja, pela tabela de distribuição normal bilateral AQUI PONHO A TABELA ANEXADA teríamos 0,025 para cada lado e portanto, ciente de que cada lado da curva equivale a 0,5 (ou 50\%) e subtraindo os 0,025, obtemos \(0,475\). Pela tabela verificamos então que iremos rejeitar a hipótese nula se \(Z \leq -1,96\) ou \(z \geq 1,96\). Logo:
\[z=\frac{73,2-72,4}{2,1/\sqrt{35}}\approx 2,25\]
Como \(z-2,25\) pertence a região critíca, então a hipótese nula deve ser rejeitada, a diferença entre \(\overline{x}=73,2\) e \(\mu=72,4\) é significante. Note que se a oceanógrafa tivesse utilizado o nível de 0,01 de significância nesse exemplo, ela não poderia ter rejeitado a hipótese nula. Pelo \textbf{valor \(p\) (probabilidade de cauda)} que é muito utilizado atualmente como medida de significância e é dado pela área total sob a curvada esquerda de \(Z=-2,25\) e da direita \(z=2,25\), observando a tabela temos que \(2(0,5000-0,4878)=0,0244\), poderíamos rejeitar a hipótese nula ao nível de 0,0244 de significância.

\begin{itemize}
\tightlist
\item
  \textbf{Aplicações do Teste de Hipótese - Média com a variância desconhecida:} vamos supor que não sabemos o valor da variância e agora a um caso de \(n\) não suficientemente grande, ou seja, utilizamos o teste \(t\):
\end{itemize}

\begin{equation} 
t=\frac{\overline{X}-\mu_0}{S/\sqrt{n}}
  \label{eq:testehipvardesc}
\end{equation}

\textbf{Exemplo \citep{freund2009estatistica}:} A safra de alfafa de uma amostra aleatória de seis lotes de teste é dada por 1,4; 1,6; 0,9; 1,9; 2,2; e 1,2 tonelada por acre. Ao nível de 0,05 de significância, teste se isso corrobora a alegação de que a safra média para este tipo de alfafa é de 1,5 tonelada por acre.

\[H_0: \mu=1,5\]
\[H_A: \mu\neq1,5\]
Temos que \(\alpha=0,05\), temos que \(n=6\) observações e portanto 6-1=5 graus de liberdade. Portanto pela tabela XXXXXXXXX de distribuição \(t\) de \emph{student} , em área na cauda superior de 0,025 e 5 G.L, rejeitaremos a hipótese nula se \(t\leq -2,75\) ou \(t\geq 2,75\). Calculando a médio e o desvio-padrão dos dados, substituindo na expressão anterior, temos:
\[t=\frac{1,533-1,5}{0,472/\sqrt{6}}\approx 0,171\]
Portanto não podemos rejeitar a hipótese nula, ou seja, os dados tendem a apoiar a alegação de que a safra média para esse tipo de alfafa é de 1,5 tonelada por acre.

Existe diversos outros como o teste para duas médias com amostras independentes ou dependentes, com proporções, etc. Ao leitor que pretende se aprofundar nesse conteúdo sugiro buscar literaturas complementares no campo de estatística.

\begin{itemize}
\item
  \textbf{Análise de Variância:}
\item
  \textbf{Supervisionada x Não supervisionada:}
\end{itemize}

\hypertarget{multlagrange}{%
\section{Multiplicadores de Lagrange}\label{multlagrange}}

\hypertarget{kkt}{%
\section{Karush-Kuhn-Tucker (KKT)}\label{kkt}}

\hypertarget{bias}{%
\section{Bias}\label{bias}}

\url{https://iaexpert.academy/2020/09/28/importancia-do-bias-nas-redes-neurais/}

\hypertarget{medidasimport}{%
\section{Medidas de Importância}\label{medidasimport}}

\begin{quote}
Um atributo é dito importante se quando removido a medida de importância considerada em relação aos atributos restantes é deteriorada , seja a precisão da medida, consistência, informação, distância ou dependência

Tradução de \citet{liu2012feature}.
\end{quote}

É fundamental estimarmos a importância de um atributo, tanto uma avaliação individual quanto à avaliação de subconjuntos de atributos. É uma questão complexa e multidimensional \citep{liu2012feature}. Podemos avaliar se os atributos selecionados pela etapa do pré-processamento auxiliam a melhorar a precisão do classificador ou a simplifcar algum modelo construído. A seguir, apresenta-se algumas medidas utilizadas \citep{lee2005seleccao}.

\hypertarget{medidasdep}{%
\subsection{Medidas de Dependência}\label{medidasdep}}

Conhecidas como medidas de \textbf{correlação} ou \textbf{associação}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/correlacao} 

}

\caption{Padrões de correlação. Elaborado por \citet{gujarati2011econometria} e adaptado \citet{theil1978}.}\label{fig:correlacao}
\end{figure}



\hypertarget{medinfo}{%
\subsection{Medidas de Informação}\label{medinfo}}

As medidas de informação determinam o ganho de informação a partir de um atributo. O ganho de informação é definido como a diferença entre a incerteza a \emph{priori} e a incerteza a \emph{posteriori} considerando-se o atributo \(X_i\). \(X_i\) é preferido ao atributo \(X_j\) se seu ganho de informação for maior que de \(X_j\). Uma das mais utilizadas é a entropia que normalmente é usada na teoria da informação para medir a pureza ou impureza de um determinado conjunto.

\citet{shannon1948mathematical}, tomou como ``ponto de partida'' encontrar uma forma matemática de medir o quanto de informação existe na transmissão de uma mensagem de um ponto a outro, denominando-a entropia. Sua proposta baseava-se na ideia de que o aumento da probabilidade do próximo símbolo diminuiria o tamanho da informação. Com isso, a entropia pode ser definida como a quantidade de incerteza que há em uma mensagem e que diminui à medida que os símbolos são transmitidos (vai se conhecendo a mensagem), tendo-se então a informação, que pode ser vista como redução da incerteza \citep{shannon1948mathematical, paviotti2019consideraccoes}. Por exemplo: ao utilizarmos como idioma a nossa língua portuguesa e ao transmitir como símbolo a letra ``q'', a probabilidade do próximo símbolo ser a letra ``u'' é maior que a de ser qualquer outro símbolo, enquanto que a probabilidade de ser novamente a letra ``q'' é praticamente nula \citep{paviotti2019consideraccoes}.

Shannon define que a entropia pode ser calculada por meio da soma das probabilidades de ocorrência de cada símbolo pela expressão \(∑ p_i = 1 = 100\%\), em que \(p_i\) representa a probabilidade do i-ésimo símbolo que compõe a mensagem. Segundo ele, estes símbolos devem ser representados através de sequências binárias, utilizando das propostas de \citet{nyquist1924certain} e \citet{hartley1928transmission}. Sua proposta consistia em representar símbolos de um alfabeto através de um logaritmo de acordo com suas respectivas unidades de informação. A entropia proposta por ele é obtida pela média das medidas de Hartley \citep{moser2012student}.

Se A é discreto com distribuição de probabilidade \(p(A)\), a entropia será:

\begin{equation} 
  H(A)=- \sum p(A)log_2(p(A)) 
  \label{eq:entropia}
\end{equation}

Para facilitar a compreensão, vamos supor um exemplo de um questionário com resposta binária entre ``sim'' e ``não'': quanto mais distribuído as probabilidades das respostas, mais desorganizada é, logo maior suaa entropia, do contrário caso for uma probabilidade de ser zero ``sim''/``não'' ou de ser 1 (100\%), ou seja, ter apenas uma opção de resposta, será menos distribuído e portanto menor usa entropia.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/entropia} 

}

\caption{Gráfico de Probabilidade x Entropia.}\label{fig:entropia}
\end{figure}



O ganho de informação portanto mede a redução da entropia (nesse caso) causada pela partição dos exemplos de acordo com os valores do atributo.

\begin{equation} 
  \mbox{Ganho de Informação}(D,T)=\mbox{entropia}(D)-\displaystyle \sum_{i=1}^k \frac{|D_i|}{|D|}. \mbox{entropia}(D_i) 
  \label{eq:ganhodeinf}
\end{equation}

É muito utilizado em algoritmo de \textbf{Árvore de decisão} que será apresentado na seção \ref{ptII} com um exemplo de seu uso.

\hypertarget{meddist}{%
\subsection{Medidas de Similaridade e Dissimilaridade}\label{meddist}}

É provável que já tenha ouvido falar em algo como medidas de distância, separabilidade, discriminação, divergência, similaridade ou dissimilaridade. É uma questão importante decidir até que ponto dois elementos de um conjunto de dados podem ser considerados com caractéristicas semelhantes ou não.

Supondo que possuímos um conjunto de dados constituído por \(n\) elementos amostrais. O objetivo é agrupar esses elementos em \(g\) grupos de acordo com um vetor \(X_j=[X_{1j}X_{2j}...X_{pj}]', j=1,2,...,n\) que representa o valor observado da variável \(i\) medida no elemento \(j\). Lembrando que existem diversas medidas diferentes e que produzem um determinado tipo de agrupamento de acordo com sua metodologia. A seguir será apresentado algumas comuns no ramo.

\hypertarget{disteuclidana}{%
\subsubsection{Distância Euclidiana}\label{disteuclidana}}

A distância Euclidiana entre dois elementos \(X_l\) e \(X_k\), com \(l \neq k\), é definida por:

\begin{equation} 
  d(X_l,X_k)=[(X_l-X_k)'(X_l - X_k)]^{1/2}=[\displaystyle \sum^p_{i=1}(X_{il}-X_{ik})^2]^{1/2}
  \label{eq:euclidiana}
\end{equation}

sendo comparado os dois elementos amostrais em cada variável pertencente ao vetor. Por exemplo, a tabela a seguir apresenta a renda mensal (em salários mínimos) e a idade de seis indivíduos de uma localidade \citep{mingoti2007analise}.

\begin{longtable}[]{@{}ccccccccc@{}}
\caption{\label{tab:dadossrendaa} Renda e Idade de 6 indíviduos \citep{mingoti2007analise}.}\tabularnewline
\toprule
\textbf{Indivíduo} & A & B & C & D & E & F & Média & Desvio Padrão\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Indivíduo} & A & B & C & D & E & F & Média & Desvio Padrão\tabularnewline
\midrule
\endhead
\textbf{Renda} & 9,6 & 8,4 & 2,4 & 18,2 & 3,9 & 6,4 & 8,15 & 5,61\tabularnewline
\textbf{Idade} & 28 & 31 & 42 & 38 & 25 & 41 & 34,17 & 7,14\tabularnewline
\bottomrule
\end{longtable}

A distância Euclidiana entre os indíviduos A e B nas variáveis Renda e Idade será:

\[d(X_A,X_B)=[(9,60-8,40)^2+(28-31)^2]^{1/2}=3,23\]
Assim sucessivamente para cada uma das observações, obtemos a matriz:

\[D_{6x6}=\begin{bmatrix}\\
 &A&B&C&D&E&F \\
 A&0&&&&&\\
 B&3,23&0&&&&\\
 C & 15,74& 12,53&0&&&\\
 D& 13,19& 12,04& 16,29&0&&\\
 E& 6,44& 7,50& 17,06& 19,33&0&\\
 F& 13,39& 10,19& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

Podendo agora analisar quais observações estão mais próximas entre si ou mais distantes de acordo com as características da Renda e da Idade.

\hypertarget{distponderada}{%
\subsubsection{Distância Ponderada}\label{distponderada}}

Também conhecido como \textbf{distância generalzada}, esta metologia tem como base uma matriz \(A_{pxp}\) de ponderação. Quando \(A_{pxp}\) for uma matriz identidade, esta distância generalizada será a \textbf{distância Euclidiana}; se \(A_{pxp}\) for a matriz inversa da matriz de covariâncias amostrais \(S^{-1}_{pxp}\), será a \textbf{distância de \citet{mahalanobis1936generalized}} e se \(A_{pxp}=diag(\frac{1}{p})\), teremos a distância \textbf{Euclidiana Média}. A escolha dessa matriz \(A_{pxp}\) reflete o tipo de informação que o pesquisador pretende utilizar na ponderação das diferenças das coordernadas dos vetores em estudo \citep{mingoti2007analise}, a distância de Mahalanobis, por exemplo, leva em consideração as possíveis diferenças de variâncias e as relações lineares entre as variáveis, em termos de variância, na ponderação.

\begin{equation} 
  d(X_l,X_k)=[(X_l-X_k)'A_{pxp}(X_l - X_k)]^{1/2}
  \label{eq:distpond}
\end{equation}

Continuando com dados da \ref{tab:dadossrendaa} e tomando como exemplo de ponderada pelo método de Mahalanobis. Ao calcular a matriz de covariância e sua respectiva inversa, obtemos:

\[S=
\begin{bmatrix}
31.471& 2.15000 \\
2.150& 50.96667 
\end{bmatrix}\]
\[S^{-1}=
\begin{bmatrix}
0,0032& -0,0013 \\
-0,0013& 0,019 
\end{bmatrix}\]

Portanto pelo cálculo da distância Ponderada por Mahalanobis:

\[d(X_A,X_B)=\bigg[(1,2 \ \ -3) S^{-1} \begin{pmatrix} 1,2 \\ -3  \end{pmatrix} \bigg]^{1/2}=0,46\]
E sucessivamente calcula-se para às outras observações.

\hypertarget{medidas-de-precisuxe3o}{%
\subsection{Medidas de Precisão}\label{medidas-de-precisuxe3o}}

Referente a tarefas de precisão, dado um algoritmo de aprendizado com sua amostra de dados. o algoritmo de maior desempenho preditivo ao modelo será selecionado \citep{kohavi1997wrappers}. Não necessariamente precisa de um único subconjunto ótimo de atributos, pois é possível alcançar a mesma precisão com diferentes subconjuntos de atributos.

A \textbf{Utilidade Incremental} por exemplo \citep{caruana1994useful}, onde uma dada amostra de dados \(S\), com um determinado algoritmo de aprendizado e um subconjunto de atributos. Um atributo \(X_i\) é incrementalmente útil para o modelo em relação ao subconjunto de dados \(F\) se a precisão da hipótese produzida pelo modelo considerando o conjunto de atributos \(X_i \cup F\) é melhor que a precisão alcançanda utilizando-se apenas o subconjunto \(F\) \citep{lee2005seleccao}.

É muito comum seu uso em algoritmos de seleção de atributos que realizam a busca no espaço de subconjuntos de atributos, removendo e adicionando-os com abordagens como \emph{wrapper} e \emph{embedded} (apresentadas na seção seguinte). Importante lembrar que um atributo considerado importante não implica que o mesmo estará no subconjunto ótimo de atributos.

\hypertarget{medidas-de-consistuxeancia}{%
\subsection{Medidas de consistência}\label{medidas-de-consistuxeancia}}

São medidas dependentes do conjunto de treinamento que permitem encontrar um subconjunto mínimo de atributos que satisfaz a proporção de inconsistência aceita (definida geralmente pelo pesquisador e com base alguma fundamentação teórica). O objetivo da análise por consistência é proporcionar a construção de hipóteses lógicas consistentes em um conjunto de treinamento. Note que elas não detectam a ocorrência de atributos redundantes, pois não possibilitam a distinção entre atributos igualmente adequados \citep{parmezan2012avaliaccao}.

Um atributo \(X_i\) é importante se aparece em toda fórmula \emph{booleana} e do contrário não importante \citep{almuallim1994learning, lee2005seleccao}, por exemplo:

\[X_1=1 \ \mbox{e} \ X_2=0 \ \mbox{então classe}=1\]
\[X_1=1 \ \mbox{e} \ X_3=0 \ \mbox{então classe}=1\]
\[X_1=0 \ \mbox{e} \ X_2=1 \ \mbox{então classe}=0\]
Partindo dessa definição, \(X_1\) é considerado importante pois é encontrado em todas as regras delimitadas, e portanto, \(X_2\) e \(X_3\) não são importantes.

\citet{dash2003consistency} e \citet{liu1996probabilistic} definem como critério de avaliação que um subconjunto de atributos importantes é definido por meio de uma \textbf{taxa de inconsistência}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Um exemplo será considerado \textbf{inconsistente} se existirem pelo menos dois exemplos exatamente iguais exceto pelo valor da classe;
\item
  A \textbf{contagem de inconsistência} é dada pelo número de vezes que este exemplo ocorre nos dados subtraído o maior número entre as diferentes classes;
\item
  a \textbf{taxa de inconsistência} de um subconjunto de atributos é a soma de todas as contagens de inconsistência de todos os exemplos do subconjunto nos dados dividido pelo número total de exemplos.
\end{enumerate}

Por exemplo: um exemplo \(E_i\) inconsistente aparece \(N_{Ei}\) vezes dos quais \(N_{C1}\) pertencem à classe \(C_1\), \(N_{C2}\) pertencem à classe \(C_2\) e \(N_{C3}\) pertencem à classe \(C_3\). Portanto \(N_{Ei}=N_{C1}+N_{C2}N_{C3}\). Supondo que \(N_{C3}\) é o maior valor entre todos, a contagem de inconsistência é \(N_{Ei}-N_{C3}\). Com dado o subconjunto e um valor mínim da taxa delimitado pelo pesquisador, se a taxa de inconsistência for menor que o definido, poderá ser dito consistente \citep{lee2005seleccao}.

Existe muitos critérios de importância de atributos em muitas literaturas e torna dificultoso em identificar quais algoritmos e metodologias são mais apropriados para o conjunto de dados. Com as medidas de importância, torna-se possível avaliar se os atributos selecionados auxiliam no modelo proposto pelo pesquisador ou o oposto. Cabe ao pesquisador com base em literaturas verificar qual utilizador de acordo com suas preferências e conjunto de dados em análise.

\hypertarget{preprocesso}{%
\chapter{Pré-processamento}\label{preprocesso}}

Para o profissional que trabalha com Aprendizado de Máquina ou outras áreas, embora exigindo boa parte do tempo nesta etapa, é uma das mais importantes. O pré-processamento é um conjunto de atividades que buscar preparar, organizar e estruturar o banco de dados (\emph{dataset}) para que possa trabalhar com os dados. Ela torna a informação de seus dados mais consistentes, com organização rígida e geralmente classificados de acordo com o seu formato (caracteres, binários, númericos, etc). Podemos dizer que ele é um conjunto de técnicas do campo de \textbf{Mineração de dados (\emph{Data mining})}, uma outra área além de Inteligência Artificial (que engloba Aprendiza de Máquina) -- que já é grande por si só - , que trata-se de uma outra dimensão de estudos e metodologias, isso sem falarmos de outros campos além destes dois. Neste tópico, vamos abordar algumas delas que são muito utilizadas nesta área. Note que em todos os procedimentos de Aprendizado de Máquina existe inúmeras metodologias para serem aplicadas em cada etapa e, de acordo com o interesse do pesquisador, pode ser utilizado diferentes estratégias com diferentes combinações. Não há uma só receita de bolo: sabemos que precisamos extrair dados, pré-processalos (aplicar uma(s) estratégia para analisar, classificar os atributos, eliminar os redundantes, preencher ou eliminar os faltantes), desenvolver seus modelos de Aprendizado de Máquina, treiná-los e por fim, avaliar todo o seu modelo e cada etapa se encontra com diversos métodos. É\ldots{} Não é fácil, mas todo esse procedimento é fundamental para que se obtenha um modelo adequado. Portanto nesta seção busquei separar em alguns tópicos para facilitar a compreensão, porém entenda que \textbf{TODAS} as metodologias e estratégias podem ser combinadas e estão entrelaçadas. É como vários conjuntos em um \emph{Diagrama de Venn} que estão dentro do Pré-processamento que está dentro de Mineração de dados e que está interseccionada com Aprendizado de Máquina (dentro de IA).

\textbf{Não se assuste:} No último capítulo deste livro estará um diagrama e uma explicação mais ``cronológica'' de todo esse cosmos, com suas ``gálaxias'' e sistemas ``solares'' de conteúdo.

\hypertarget{dados-faltantes-e-a-limpeza-de-dados}{%
\section{Dados faltantes e a Limpeza de dados}\label{dados-faltantes-e-a-limpeza-de-dados}}

Durante o desenvolvimento destes modelos é comum se deparar com dados faltantes em seu banco de dados e que podem ser ocasionadas por razões diversas como não preenchimento cadastral, problemas de armazenamento de dados ou até mesmo situações aleatórias não identificadas. A escolha da forma de tratar esses dados faltantes é fundamental para o modelo. Os valores faltantes total quando todas as informações são perdidas ou parcial quando somente uma parte delas são perdidas

\citep{little2019statistical}, descrevem que os motivos de aparecimento de dados faltantes são comumente classificados em:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{\emph{Missing Completely at Random (MCAR)}}: neste caso, as observações faltante surgiram de maneira aleatória, portanto as razões para as perdas não são relacionadas às respostas do sujeito. O uníco problema gerado pelos dados faltantes é a perda de poder da análise a ser realizada. Por exemplo, um jovem que deixou de responder uma questão de sua prova sem querer, sem motivo algum.
\item
  \textbf{\emph{Missing at Random (MAR)}}: os dados faltantes dependem das variáveis preenchidas e, portanto, podem ser totalmente explicadas pelas variáveis presentes no conjunto de dados. É possível não viesar a análise, considerando as informações que causam estes dados faltantes. Como por exemplo uma pesquisa elaborada por uma universidade com a finalidade de analisar a renda das mulheres em sua cidade porém não possui recursos financeiros suficiente para entrevistar todas as mulheres. A pesquisa é respondida por uma parcela de mulheres na cidade e todas as envolvidas estão com os dados completamente observados, seria analisado uma amostra aleatória de mulheres.
\item
  \textbf{\emph{Missing Not at Random (MNAR)}}: nesta situação os dados faltante são gerados de forma não mensurável, isto é, de eventos que o pesquisador não consegue observar e não tem controle. É o pior caso e algumas vezes, é necessário técnica mais robustas. Em geral,dados situados nos extremos da distribuição são mais propensos a serem faltantes (muito baixos ou altos em relação ao padrão da amostra).
\end{enumerate}

\hypertarget{tratamento-de-dados-faltantes}{%
\subsection{Tratamento de dados faltantes}\label{tratamento-de-dados-faltantes}}

Existem diversas metodologias de tratamentos em dados faltantes. Quando os dados são faltantes em um conjunto de dados, existem cinco grandes categorias de tratamento de análise que um pesquisador deve escolher. Como mencionado anteriormente e ainda reforço, a escolha do tratamento de análise de dados faltantes tem implicações importantes para a acurácia e o viés das estimativas.

\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tab:preprocess} Metodologia de dados faltantes \citep{tecnicasinput}. Determinados termos estão na seção \ref{dicio} e alguns outros serão apresentados ao longo do livro .}\tabularnewline
\toprule
\begin{minipage}[b]{0.30\columnwidth}\centering
\textbf{Técnicas de Análise para dados faltantes}\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\centering
\textbf{Definições}\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\centering
\textbf{Maiores Problemas}\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.30\columnwidth}\centering
\textbf{Técnicas de Análise para dados faltantes}\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\centering
\textbf{Definições}\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\centering
\textbf{Maiores Problemas}\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.30\columnwidth}\centering
\textbf{Listwise Deletion}\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Exclui todos os casos para os quais alguns dados estão faltando\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Descarta dados de respondentes com respostas parciais. Menor amostra, menor potência. Viés em MAR e MNAR.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\centering
\textbf{Pairwise Delection}\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Calcula as estimativas (médias, EP, correlações) usando todos os casos disponíveis com dados relevantes para cada estimativa.\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Diferentes correlações representam misturas de subpopulação. Às vezes, a matriz de covariância não é definida positiva. Viés em MAR e MNAR. Nenhuma amostra faz sentido para a matriz de correlação (EP impreciso).\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\centering
\textbf{Imputação Simples}\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Preenche cada valor faltante, por exemplo média, por regressão, etc.\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
A imputação média (entre casos) e a imputação por regressão são ambas tendenciosas sob MCAR! Nenhuma amostra faz sentido para a matriz de correlação (EP impreciso). EP's subestimados se você tratar o conjunto de dados como completo.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\centering
\textbf{Máxima Verossimilhança (MV)}\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Estima diretamente os parâmetros de interesse a partir de uma matriz de dados incompleta; ou calcula estimativas como média, desvio padrão, ou correlação usando algum algoritmo.\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Não-viesada sob MCAR e MAR. Melhora à medida que adiciona mais variáveis ao modelo de imputação. Número de variáveis deve ser menor que 100. EP'S preciso para FIML. para o algoritmo EM, nenhuma amostra faz sentido para a matriz de correlação (EP impreciso).\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\centering
\textbf{Imputação Múltipla (IM)}\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Imputa valores faltantes várias vezes, cria-se \emph{m} conjuntos de dados completamente imputados. Executa a análise em cada conjunto de dados imputado. Combina os \emph{m} resultados para obter estimativas de parâmetros e erros padrão.\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\centering
Imparcial sob MCAR e MAR. Melhora à medida que adiciona mais variáveis ao modelo de imputação. O número de variáveis deve ser menor que 100. EP's precisos. Fornece estimativas ligeiramente diferentes a cada vez que analisa os dados. Em Equações Estruturais, piora a convergência.\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\tightlist
\item
  \textbf{\emph{Listwise} deletion}: exclui todos os casos para os quais alguns dados estão faltando . A eliminação dos casos frequentemente reduz muito o tamanho da amostra e o poder estatístico do teste de hipóteses. Importante o pesquisador se atentar que mesmo quando o poder do teste parece adequado, este método pode produzir estimativas de parâmetros tendenciosas sob dados faltantes sistemático (MAR e MNAR). O \emph{listwise deletion} restringe a população-alvo do estudo, assim em geral quase nunca se utiliza esse procedimento. Uma vez que ele descarta dados que custaram tempo, disponibilidade dos participantes e até mesmo recursos financeiros, a eliminação desses participantes da pesquisa pode violar o princípio ético da pesquisa \citep{rosenthal1994science}.
\end{itemize}

Resumo geral: elimina todos os casos que possuem dados faltantes em sua pesquisa.

\begin{itemize}
\tightlist
\item
  \textbf{\emph{Pairwise} deletion}: este método tenta minimizar a perda que ocorre em \emph{Listwise deletion}. Como exemplo a matriz de correlação. Uma correlação como explicada em \ref{dicio}, mede a força da relação entre duas variáveis. Para cada par de variáveis para os quais os dados estão disponíveis, o coeficiente de correlação indicará a força. Em \emph{Listwise} será o mesmo tamanho para todas as correlações excluindo toda observação faltante, em \emph{Pairwise deletion} irá variar. Ela exclui apenas os casos que não tem respostas completas dentro da observação, aproveitando o maior número de casos possíveis.
\end{itemize}

Resumo geral: ao invés de eliminar as observações (coluna ou linha inteira da matriz) com dados faltantes, como \emph{listwise deletion}, este metodo elimina apenas os casos que não tem respostas completas nas combinações das observações, aproveitando o maior número possível.

\begin{itemize}
\tightlist
\item
  \textbf{Imputação simples}\emph{: envolve o preenchimento de cada dado
  faltante com uma suposição de qual deve ser o valor que está
  faltando no conjunto de dados. Os exemplos mais comuns de imputação simples são: imputação pela média - substituição de cada valor faltante pela média do grupo para a variável correspondente; imputação }hot deck* - substituição de cada dado faltante por um valor ``doador'' que possui um escore similar em outras variáveis; e imputação por regressão -- substituindo cada valor faltante por um valor predito com base em um modelo de regressão múltipla (será explicado conceito de regressão posteriormente), obtido a partir dos valores observados \citep{tecnicasinput}. A maioria das técnicas de imputação simples é tendenciosa. Por exemplo, a imputação pela média insere uma média constante para cada valor faltante, as estimativas da variância e da correlação serão tendenciosas -- mesmo que o mecanismo de dados faltantes seja completamente aleatório (MCAR). A imputação por regressão leva à subestimação da variância e superestimação da correlação (pois os valores imputados estarão exatamente na linha de regressão). Pode-se melhorar ao caso de regressão adicionando um termo de erro aleatório aos valores imputados (regressão estocástica), no entanto, ainda são imprecisas. Ao caso dos testes de hipóteses, não estima com precisão o erro padrão \citep{tecnicasinput}.
\end{itemize}

Resumo geral: envolve o preenchimento de cada dado faltante com uma ``boa adivinhação'' de qual deve ser o valor que está faltando no conjunto de dados, sendo essa estimação de acordo com o pesquisador e sua pesquisa (média, regressão, etc).

\begin{itemize}
\tightlist
\item
  \textbf{Imputação múltipla (IM)}: cada valor faltante é substituído por dois ou mais valores imputados e ordenados a fim de representar a incerteza sobre qual valor imputar, permitindo que as estimativas das variâncias estimadas sejam calculadas com dados completos \citep{rubin2004multiple}. Assim, \(m\) imputações atribuídas a cada valor faltante gera \(n\) conjuntos de dados completados que são analisados inerente aos valores observados da amostra.
\end{itemize}

Muitos utilizam este método, visto que aumenta a eficiência de estimação, facilita o estudo direto da sensibilidade de inferências, abrange uma variedade de análises e geralmente válidas por incorporar incertezas devido à falta de dados. Tornando-os mais eficientes que a imputação simples, porém mais trabalhosa e ocupa mais espaço de armazenamento. Em desvantagem desse método,pode surgir discrepância na variância quando se admite pressupostos equivocados (modelo escolhido não consistente com os dados), com isso um \(m\) pequeno se torna mais adequado com menor gravidez. Uma das característica mais importantes desse método é que os valores faltantes para cada envolvido é predito a partir de seus próprios valores observados, com o ruído aleatório adicionado para preservar uma correta quantidade de variabilidade nos dados imputados \citep{schafer2002missing}.

\citet{schafer1999multiple} recomenda que a quantidade necessária de imputações para que a estimativa de conjunto de dados tenha relativa eficiência, com a seguinte equação:

\begin{equation} 
  RE=\sqrt{1+\frac{\lambda}{m}}
  \label{eq:qimputm}
\end{equation}

onde, é \(m\) é a quantidade do conjunto de dados completados e \(\lambda\) é a taxa de informação - caso fosse 50\% dos dados faltantes, \(\lambda=0,5\).

Claro que o método para mensurar a quantidade necessária \textbf{varia de acordo com o tema da pesquisa e a escolha do pesquisador}. Dependendo área que o pesquisador está interessado, pode-se haver outras recomendações para mensurar a quantidade.

A IM é composto basicamente por três passos \citep{assunccao2012estrategias}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Imputação dos dados:} são gerados \textbf{m} bancos de dados completos através de técnicas adequadas que devem levar em conta ao máximo a relação entre os dados faltantes e os observados. Existe diversos métodos que podem ser utilizadas para este primeiro passo, um dos mais utilizados atualmente é o método de \textbf{regressão linear bayesiana} - ao caso de não entender o que são as técnicas de Regressão linear nem de Bayes, as seções XXXXXXXXXXXX instruem.
\end{enumerate}

Este método tem como resposta a variável que possui dados faltantes (\(Y\)) e como variáveis preditoras são utilizadas as demais variáveis presentes (\(X_1, X_2,..., X_k\)), com \(k\) número de preditoras. Na abordagem Bayesiana, a regressão linear é formulada através de distribições de probabilidade ao invés da abordagem clássica. Seu modelo será:

\[Y_i \sim N(\beta^T X_k , \sigma ^2 I)\]
A variável dependente \(Y_i\) é gerada a partir de uma Distribuição Normal (Gaussiana) \ref{dicio} caracterizada pela média e variância (\(\sigma^2\). A média é o produto entre os parâmetros \(\beta\) e variáveis independentes \(X_k\). O objetivo deste método é determinar a distribuição posterior para os parâmetros do modelo ao invés de encontrar um único valor. A resposta e seus parâmetros são gerados por meio de uma distribuição de probabilidade.

Para encontrar as distribuições dos parâmetros do modelo, a inferência bayesiana utiliza o Teorema de Bayes para combinar informações prévias ao experimento e dados de amostra com o objetivo de deduzir as propriedades sobre um parâmetro de interesse a partir dos dados de entrada \(X_k\) e de saída \(Y\). A aplicação de Bayes neste contexto seria:

\begin{equation}
  P(\beta|y,X)=\frac{P(y|\beta,X)P(\beta|X)}{P(y|X)}
  \label{eq:reglinbayes}
\end{equation}

onde \(P(\beta|X)\) reflete a incerteza de \(\beta\). Qualquer informação que se tenha inicialmente sobre o parâmetro é tratado como ela (pode ser utilizada como não informativa).
Em \(P(y|\beta,X)\) é a verossimilhança que diz respeito a distribuição característica dos dados (interpretada como no caso clássico). O denominado \(P(y|X)\) é tratada como uma constante de normalização para a equação e reflete a probabilidade que pode-se obter qualquer dado.

\textbf{Ressalto} que existe diversos métodos nesta primeira etapa e recomendo o leitor interessado, buscar outras literaturas.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  \textbf{Análise dos bancos de dados gerados pelo passo 1:} ao criar o conjunto de dados imputados, é importante fazer uma análise separadamente para cada um dos \(m\) banco de dados da mesma forma como tradicionalmente se faz, o modelo pode variar de acordo com o pesquisador - são apresentadas na seção SEIS AQUI COLOCAR A SEÇÃO DEPOIS.
\item
  \textbf{Combinar os resultados:} com as análises realizadas, precisa-se combinar os resultados apropriados para obter a inferência da imputação repetida. Por meio do passo 2, obtém-se estimativas para o parâmetro de interesse \(D\). Estas estimativas podem ser qualquer medida escalar como médias, variâncias, correlações, coeficientes de regressão por exemplo. A estimativa \(D\) será a combinação será a média das estimativas individuais.
\end{enumerate}

\begin{equation}
  \overline{D}=\frac{1}{m}\displaystyle \sum^{m}_{s=}\hat{D}_s
  \label{eq:mediaimputmul}
\end{equation}

Em seguida, a variância combinada é calculada:

\begin{equation}
T  =\overline{E}+ (1+\frac{1}{m})F
  \label{eq:varimputmul}
\end{equation}

em que \(\overline{E}= \frac{1}{m}\displaystyle \sum^{m}_{s=} E_s\) é a média das variâncias que preserva a variabilidade natural (\(E\)) do parâmetro de interesse nos \(m\) banco de dados e \(F=\frac{1}{(m+1)}\displaystyle \sum^{m}_{s=}(\hat{D}_s-\overline{D})^2\) o componentes que estima a incerteza causada pelos dados faltantes. Se \(F\) for muito pequeno as estimativas dos parâmetros são muito semelhantes, com menos incerteza. Do contrário as incertezas variam muito.

Resumo geral: a imputação múltipla executa uma rotina de imputação simples repetidamente (múltiplas associações sobre os valores plausíveis) e consegue estimar sem víes o erro padrão. Ocorre as imputações muitas vezes contabilizando a imprecisão de cada imputação.

\begin{itemize}
\tightlist
\item
  \textbf{Método de máxima verossimilhança (EM - Expecativa-maximização)}: proposto por \citet{fisher1912absolute} , é um método paramétrico (ver \ref{dicio}) que parte do princípio de especificar como a função de verossimilhança (ver \ref{dicio}) deveria ser utilizada como um instrumento de redução de dados \citet{casella2010inferencia}. Este método consiste na escolha do conjunto de valores para os parâmetros que torne um máximo a função de verossimilhança. A inferência de verossimilhança pode ser considerada como um processo de obtenção de informação sobre um vetor de parâmetros \(\theta\), a partir do ponto \(x\) do conjunto amostral, por meio da função de verossimilhança. Vários vetores podem produzir a mesma verossimilhança, reduzindo a informação de \(\theta\) \citep{cordeiro1999introduccao}.
\end{itemize}

O objetivo é encontrar uma estimativa do parâmetro \(\theta\), \(\hat{\theta}\), que maximize a verossimilhança. Portanto, utiliza-se o conceito de derivada (diferenciação) e igualamos a zero \citep{bolfarine2001introduccao}.
\begin{equation}
  L'(\theta;x)=\frac{\delta L(\theta;x)}{\delta \theta}=0
\label{eq:derivadaverossimilhanca}
\end{equation}

Para inferir se é um ponto máximo, aplica-se a segunda derivada e verificar se o resultado é menor que zero \citep{bolfarine2001introduccao}.

\begin{equation}
  L''(\hat{ \theta};x)=\frac{\delta^2 log L(\theta;x)}{\delta \theta^2}<0
\label{eq:derivadadoisverossimilhanca}
\end{equation}

Com algoritmo EM (Expectativa-maximização), por \citet{dempster1977maximum} é um procedimento que realiza a estimativa dos parâmetros (vetor de médias e a matriz de covariância) por meio da máxima verossimilhança em conjuntos amostrais incompletos (dados faltantes) e pode ser utilizado como uma ferramenta para inserção de dados. Por um processo iterativo, na etapa E(Estimação/Esperança) se estima os dados faltantes para completar a matriz dos dados, no caso calcula-se a esperança condicional (média condicional) da função de log-verossimilhança; no passo M (Maximização), com os dados completados, encontra-se um \(\hat{\theta}\) que maximiza a esperança condicional da log-verossimilança e então seu resultado é usado para fazer a inferência no passo E e assim sucessivamente até que o algoritmo processado tenha convergido, ou seja, a diferença entre o valores da verossimilhança dos dados incompletos na \(k\)-ésima e na \((k+1)\)-ésima iteração seja tão pequena \citetext{\citealp[ ]{enders2010applied}; \citealp{pereira2019inserccao}}.

Resumo geral: o algoritmo EM, faz a etapa E com a função de verossimilhança para encontrar um valor médio e preencher os dados faltantes, faz a etapa M utilizando a máximização de verossimilhança para encontrar um valor médio com o menor erro possível e continua, a partir do resultado do segundo passo, sucessivamente até convergir no melhor valor e menor erro possível (global) para preencher os dados faltantes.

Além de dados faltantes, é possível lidarmos com grande volume de dados. Por isso, o processamento computacional se torna cada vez mais complexo e para aumentarmos a eficiência e reduzir os custos usamos o processo de redução de dados ou a hierarquização para separarmos os conjuntos a serem estudados. Pode-se por meio de \textbf{Agregação de cubo de dados} (atividade de construção de um cubo de dados) que apesar de gerar maior necessidade de armazenamento, permite um processamento mais rápido por não necessitar varrer toda a base em busca de determinado valor. A \textbf{Seleção de subconjuntos de atributos} para utilizar os atributos altamente relevantes em detrimento dos menos relevantes (como por exemplo verificar pela significância). Ou também \textbf{reduzir a numerosidade } ou \textbf{dimensionalidade} que permitem que os dados seja estimados por alternativas de representação de dados menores e compactados e alguns métodos para hierarquizar as variáveis. Na seção de XXXXXXXXXXXX serão apresentados as principais estratégias.

\hypertarget{outlier}{%
\subsection{\texorpdfstring{\emph{Outlier}}{Outlier}}\label{outlier}}

Um \emph{outlier} é um valor que se encontra distante da normalidade e que provavelmente causará anomalias nos resultados obtidos, pois pode viesar negativamente todo o resultado de uma análise e que seu comportamento pode ser justamente o que está sendo procurado. São basicamente dados que se diferenciam drasticamente dos outros, conhecidos como anomalias, pontos fora da curva, dados discrepantes, ruídos, e que estão fora da distribuição normal.

Pode-se verificar dados incomuns apenas verificando a taebla, mas dependendo do tamanho de seu banco de dados não é uma boa recomendação. Uma das melhores maneiras de identificarmos dados \emph{outliers} é utilizando gráficos. Ao plotar um gráfico o analista consegue verificar que existe algo diferente. Como exemplo, um estudo no sistema de saúde brasileiro pela \citet{aquarela} utilizando dados da prefeitura de Vitória no Espírito Santo, analisando fatores que levam as pessoas a não comparecerem em consultas agendadas no sistema público de saúde da cidade. Padrões encontrados de que mulheres comparecerem muito mais que os homens e crianças faltam poucos às consultas, porém, uma senhora \emph{outlier}, com 79 anos agendou uma consulta e com 365 dias de antecedência apareceu à consulta. Neste caso, convém ser estudado o \emph{outlier} pelo comportamento trazer informações relevantes que podem ser adotadas para aumentar a taxa de assiduidade nos agendamentos. \emph{Outlier} do caso indicado pela seta vermelha \ref{fig:outlier}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/outlier} 

}

\caption{``Gráfico de estudo no sistema de saúde apresentando \emph{outlier} \citep{aquarela}.''}\label{fig:outlier}
\end{figure}



Por diversos motivos pode ocorrer de ter presença de \emph{outlier} nos dados e podem viesar negativamente todo resultado de uma análise e seu comportamente pode muitas vezes ser o que justamente o pesquisador está procurando. Há possibilidade do \emph{outlier} ser importante para o pesquisador entender o por que da anomalia estar acontecendo, ou para identificar algum dado extraído erroneamente, por exemplo.

Uma maneira mais complexa e muito precisa, é de identificá-los através de análise dos dados. Encontrando a distribuição estatísticas que mais e aproxima à distribuição dos dados e utilizar métodos estatísticos para detectar as anomalias. Como por exemplo o uso de histograma e a distribuição normal para verificar os dados que estão dentro e fora do intervalo de confiança (ver \ref{dicio} Distribuição normal).

\hypertarget{transformauxe7uxe3o-de-dados}{%
\section{Transformação de dados}\label{transformauxe7uxe3o-de-dados}}

\hypertarget{tipos-de-datasets}{%
\subsection{\texorpdfstring{Tipos de \emph{datasets}}{Tipos de datasets}}\label{tipos-de-datasets}}

A escolha das medidas estatísticas para sua análise ou modelo de Aprendizado de Máquina dependem muito dos tipos de dados das variáveis em observação. Estes tipos de dados podem ser numéricos (como uma sala de aula, com alunos que variam sua altura de 1,51 metros a 1,98 metros) e categórico (como uma classificação num hospital de pacientes doentes ou não doentes), embora esses dois tipos podem ser subdivididos como números inteiros e ponto flutuante para variáveis numéricas e booleano, ordinal ou nominal para variáveis categóricas.

As subdivisões mais comuns são:
- Variáveis Numéricas:
1. Variáveis inteiras (exemplo: \(1,2,3,..., n\));
2. Variáveis de ponto flutuante (parte fracionária, por exemplo: 1,17; 0,10; 47,2).

\begin{itemize}
\tightlist
\item
  Variáveis categóricas:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Variáveis booleanas (dicotômicas, binárias: Verdadeiro e Falso).
  \item
    Variáveis ordinais (1º, 2º, 3º, etc).
  \item
    Variáveis nominais (não possuem ordenação como por exemplo, cor dos olhos: azuis, castanhos, pretos e verdes).
  \end{enumerate}
\end{itemize}

Importante ressaltar que quando trabalhamos dentro da programação, possuem mais tipos além de \emph{int} (númericos inteiros) \emph{char} (caracteres) e \emph{float} (pontos flutuantes), como o \emph{double} que armazena números com ponto flutuantes com precisão dubla com o dobro da capacidade de \emph{float}, \emph{string} como cadeia de caracteres.

Muitos algoritmos possuem a limitação de trabalhar somente com atributos qualitativos (variáveis categóricas), com isso muitas vezes é necessário aplicar algum método capaz de transformar um atributo quantitativo em um atributo qualitativo (faixas de valores). Uma estratégia que cresce ao longo do tempo é o processo de \textbf{discretização} que transforma atributos contínuos em atributos discretos como por exemplo, dividir alturas entre menor que 1,70 metros e maior igual que 1,70 metros. Dependendo do estudo pode ser adequado, embora o pesquisador precisa tomar muito cuidado pois é provável que possar perder algumas informações. De mesmo modo, é possível transformar variáveis categóricas em númericas, como por exemplo classificar tamanhos como pequeno = 1, médio = 2 e grande = 3 possibilitando por meio do mapeamento manter a ordem dos valores (\citet{batista2003pre}).

É bem comum estes tipos de tratamento de dados ao caso de datas, como trabalhos que aplicam-se \textbf{séries temporais} em que o pesquisador precisa estudar a sazonalidade de algum objeto de estudo. A soja por exemplo pode-se analisar sua tendência ao longo dos anos, mas quando tratamos os dados e analisamos em outro período podemos verificar que possui sazonalidades em sua produção. Em análises para investimentos também, atentar o comportamento mensal e diário das ações de uma empresa, muitas vezes está com tendência de alta num âmbito mensal, porém ao analisar diariamente é possível que esteja em baixa.

Para facilitar a compreensão, considere a série temporal \emph{AirPassengers} que representa o número de passageiros mensalmente em uma empresa de transporte aéreo ao período de 1949 a 1960 \citep{box1976time}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/airpassengers} 

}

\caption{``Número de passageiros tratados mensalmente \citep{box1976time}.''}\label{fig:airpassengers}
\end{figure}



Para o campo de transformação de dados e séries temporais, ao leitor que pretende ir mais a fundo nestes outros ``galhos'' de estudos. Recomendo buscar outras literaturas que tem como foco este temas. Em discretizações por exemplo, \citet{dougherty1995supervised} e \citet{garcia2012survey} abordam diversos métodos que podem agradá-lo.

\hypertarget{normpadro}{%
\subsection{Normalização e padronização}\label{normpadro}}

Muitos conjuntos de dados apresentam atributos contínuos que espalham-se em diferentes faixas de valores ou possuem distintas variações, devido às suas naturezas ou escalas em que foram medidas. Estas diferenças podem ser fundamentais e precisam ser levadas em conta \citep{carvalho2011inteligencia}. Em situações também para validarmos a análise variância precisa-se dos requisitos de atiditividade, independência, normalidade e homogeneidade de variâncias - será apresentada em ANOVA seção XXXXXXXX. Quando alguma das características mencionadas acontece ou não verifica seus requisitos o pesquisador, antes de fazer uma análise não-paramétrica (\ref{dicio}), pode-se transformar seus dados \citep{banzatto1992experimentaccao}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Normalização por reescala:} através de um valor mínimio e um máximo, gera um novo intervalo onde os valores de um atributo estão contidos. Um intervalo entre 0 e 1.
  \begin{equation}
  x_{ij}=\frac{x_{ij}-min_j}{max_j-min_j}
  \label{eq:normalizacao}
  \end{equation}
\end{enumerate}

sendo \(x_i\) a observação de ordem \(i\), \(min_j\) e \(max\) os valores mínimos e máximos do atributo \(j\) respectivamente.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Transformação de raiz quadrada:} frequentemente utilizada para dados de contagens que geralmente segue uma distribuição de Poisson (\ref{dicio}), onde a média é igual à variância \citep{banzatto1992experimentaccao}.
\end{enumerate}

\begin{equation}
\sqrt{x_i}
\label{eq:transraiz}
\end{equation}

sendo \(x_i\) representando as observações do banco de dados. Quando ocorrem zeros ou valores baixos (menores que 10 ou 15), recomenda-se \(\sqrt{x+0,5} \ \mbox{ou} \sqrt{x+1,0}\) \citep{banzatto1992experimentaccao}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Transformação angular:} recomenda-se para dados expressos em porcentagens, que geralmente seguem a distribuição binomial (\ref{dicio}). Atualmente existe tabelas apropriadas para essa transformação \citep{banzatto1992experimentaccao}. Segundo \citet{banzatto1992experimentaccao} porcentagens entre 30\% e 70\% ou as porcentagens são resultantes da divisão dos valores observados nas parcelas por um valor constante tornam-se desnecessárias e pode-se analisar diretamente os dados originais, mas atente-se pois algumas vezes variar essas exceções de acordo com sua área e pesquisador que a propõe.
\end{enumerate}

\begin{equation}
arc \ sen \sqrt{\frac{x}{100}}
\label{eq:transang}
\end{equation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Transformação logaritmica:} quando verificada determinada proporcionalidade entre as médias e desvios padrões dos diversos tratamentos. É geralmente utilizada para problemas de assimetria (\ref{dicio}). Em casos, por exemplo, tratamentos com amplitude alta como uma população numerosa que varia de 1.000 a 10.000 indivíduos ou tratamentos de baixa amplitude de 10 a 100 indivíduos. Esta trasformação pode ser útil.
\end{enumerate}

\begin{equation}
log(x) \ \mbox{ou} ln(x)
\label{eq:translog}
\end{equation}

Uma vez transformados os dados em logaritmos, a soma de dados logarítmicos não tem o mesmo valor que a soma de seus antilogaritmos, mas representa o produto destes.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  \textbf{Padronização:} é um método muito utilizado por diversas áreas de pesquisa. Neste caso diferentes atributos podem abranger diferentes intervalos, porém possuir os mesmos valores para alguma medida de posição e de variação \citep{carvalho2011inteligencia}. Imagine você como economista interessado em avaliar o desempenho da produção de soja com as variáveis econômicas e monetárias o Brasil e possui as seguintes variáveis: produção de soja anual medida em milhares de toneladas, taxa básica de juros SELIC medida em porcentagem, receita média anual em milhares de reais, área plantada de soja medida em hectares. Já podemos perceber que todos possuem medidas e grandezas bem diferente uma das outras. Este o propósito da padronização, deixar com que todas as variáveis tenham uma medida em comum.
\end{enumerate}

\begin{equation}
Z_{ij}=\frac{x_{ij}-\overline{X}}{\sigma_j}
\label{eq:padronizacao}
\end{equation}

em que \(\overline{X_j}\) e \(\sigma_j\) representam a média e o desvio padrão do atributo \(j\) respectivamente. Após a transformação todos os atributos terão a média zero e desvio-padrão unitário.

Caso transformado seu banco de dados e seu banco de dados apresentarem uma distribuição contínua não-normal, ou não-homogênea ou não-aditiva, não há outra alternativa senão utilizar a estatística não-paramétrica.

Resumo geral: Muitos conjuntos de dados apresentam atributos contínuos que espalham-se em diferentes faixas de valores ou possuem variações diferentes, por motivo de suas naturezas ou escalas medidas. Estas diferenças podem ser muito importantes e precisam ser levadas em conta para não causar erros em sua pesquisa. Para isso usam-se alguns métodos para transformar seus dados para que possam ser trabalhados, apresentados os principais neste livro. Em situações para fazermos análise variância precisa-se também ser transformado seus dados caso não cumpra seus requisitos. Caso o problema ainda persistir, precisa-se utilizar estatística não-paramétrica.

\hypertarget{features-selection---seleuxe7uxe3o-de-atributos-sa}{%
\section{Features Selection - Seleção de atributos (SA)}\label{features-selection---seleuxe7uxe3o-de-atributos-sa}}

Uma literatura que achei bastante interessante foi \citet{parmezan2012avaliaccao}. Seguindo sua estrutura a respeito de Seleção de atributos. Podemos definir SA como a determinação de um subconjunto ótimo de atributos, partindo de algum critério ou medida de importância, que representa a informação importante dos dados \citep{parmezan2012avaliaccao}. Extraímos um subconjunto de \(P\) atributos a partir de um conjunto original de \(N\) atributos, sendo \(P\leq M\) \citep{parmezan2012avaliaccao, liu1998feature, lee2005seleccao}. A cada conjunto de dados com \(M\) atributos, existem \(2^M\) subconjuntos de atributos candidatos \citep{langley1994selection}.

Existem diversas metodologias para selecionarmos os atributos que podem variar em sentido de buscas e estratégias para a seleção. Repare que os tópicos mencionados anteriormente também são utilizados para remoção e seleção, foi fragmentado apenas para facilitar a compreensão.

O ``sentido de busca'' influencia na determinação do(S) ponto(s) de partida no espaço de busca, ou seja, na direção em que a busca será realizada e os operadores que serão utilizados. Elas são categorizadas, seguindo \citet{parmezan2012avaliaccao} e \citet{liu2008computational}, em:

• \textbf{Forward Selection - Seleção para Frente:} o estado inicial é estabelecido como vazio (subconjunto vazio de atributos), e os atributos são incluídos um por vez;

• \textbf{Backward Elimination - Eliminação por Trás:} o ponto de partida é iniciado com o conjunto de todos os atributos (completo), tais quais são removidos sucessivamente;

• \textbf{Bidirectional Search - Pesquisa Bidirecional:} como o próprio nome diz, duas buscas são processadas simultâneamente. Ambas terminam quando atingem o centro do espaço de busca, ou quando uma das buscas encontra os melhores atributos antes de alcançar o centro do espaço de busca;

• \textbf{Random Search - Pesquisa Aleatória:} com o propósito de evitar que a busca fique restrita a ótimos locais. Não tem uma direção específica para buscar, pois o ponto de partida da busca e o modo de adicionar ou remover atributos são decididos aleatoriamente.

Além dos sentidos de busca, existem diversas abordagens que avaliam subconjuntos de atributos e que podem remover tanto atributos irrelevantes quanto redundantes \citep{parmezan2012avaliaccao, liu2008computational}. A seguir, as principais abordagens:

• \textbf{\emph{Filter} - Filtro:}

Com a finalidade de filtrar atributos não importantes, essa abordagem é feita antes da construção dos modelos. A ideia é simplesmente receber como entrada o
conjunto de exemplos descrito utilizando somente o subconjunto de atributos importantes identificados. Ela ocorre antes do aprendizado de máquina \citep{john1994irrelevant} e utiliza-se métodos estatísticos diversos para esta seleção, como por exemplo árvores de decisão ou as ``medidas de importância'' que são apresentadas na próxima seção.

• \textbf{\emph{Wrapper} - Empacotar:} ocorre também externamente ao algoritmo de aprendizado. Este método gera um subconjuto candidato de atributos, executa o algoritmo de aprendizado considerado somente esse subcojunto selecionado de treinamento e avalia a precisão desse classificador. Repete-se esse processo para cada subconjunto de atributos até buscar um bom modelo. Como exemplo temos a análise por arvores de decisão e florestas aleatórias (serão apresentadas mais a frente). Tem como desvantagem o custo operacional desta abordagem. Exemplo de aplicações: \emph{Naive Bayes} e Máquina de vetores de suporte para classificação.

• \textbf{\emph{Embedded} - Embutida:} é realizada internamente pelo próprio algoritmo de extração de padrões. Esta estratégia seleciona o subconjunto de atributos no processo de construção do modelo de classificação, durante a fase de treinamento, e geralmente são específicos para um dado algoritmo de aprendizado. A principal diferença dos métodos do tipo \emph{embedded} e \emph{wrapper},
é que em \emph{embedded} depende em relação a um modelo preditivo específico, assim não permite a sua implementação em combinação com outros modelos \citep{souza2014computational}.

Observação e resumo geral: Note que o que muitas vezes confunde o leitor é o excesso de categorias - que ironicamente tem o propósito de organizar e facilitar. Basicamente são estratégias diferentes com sentidos diferentes de se iniciar a busca de atributos que podem ser irrelevantes ou relevantes: antes de criar um modelo de Aprendizado de maquina; usa-se um modelo de aprendizado para selecionar os atributos antes de iniciar uma etapa de análise {[}pode-se até mesmo realizar outro algoritmo de aprendizado após este algoritmo de seleção{]} ou a própria seleção com a análise {[}mesmo algoritmo para selecionar e concluir{]}). Quando misturamos esta estratégia, denominamos de \textbf{híbridos}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/diferenssa} 

}

\caption{``Diferença de \emph{Filter}, \emph{Wrapper} e \emph{Embedded} respectivamente (modificado de \citet{covoes2010seleccao}).''}\label{fig:diferenssa}
\end{figure}



\hypertarget{valid}{%
\chapter{Validação de um modelo}\label{valid}}

\hypertarget{fitt}{%
\section{\texorpdfstring{\emph{Overfitting, Underfitting}}{Overfitting, Underfitting}}\label{fitt}}

Sendo \textbf{muito importantes} nesta área, o \textbf{\emph{Underfitting} (sub-ajustado)} e \textbf{\emph{Overfitting}} (sobre-ajustado)** são dois termos que temos que estar sempre atentos. Um bom modelo não deve sofrer de nenhum deles \citep{silver2013sinal}. Vamos entender melhor do que eles se tratam.

\hypertarget{overfitting-um-cenuxe1rio-de-overfitting-ocorre-quando-nos-dados-de-treino-o-seu-modelo-ml-tem-um-desempenho-excelente-poruxe9m-quando-utilizamos-os-dados-em-novos-bancos-de-dados-seu-resultado-uxe9-ruim.-nesta-situauxe7uxe3o-seu-modelo-aprendeu-tuxe3o-bem-as-relauxe7uxf5es-existentes-dos-conjuntos-de-dados-para-treino-que-acabou-apenas-decorando-esses-dados.-portanto-ao-receber-as-informauxe7uxf5es-das-variuxe1veis-preditoras-aos-novos-dados-o-modelo-tenta-aplicar-as-mesmas-regras-decoradas-poruxe9m-com-estes-novos-dados-diferentes-do-treino-esta-regra-nuxe3o-tem-validade-e-seu-desempenho-uxe9-afetado.}{%
\subsection{\texorpdfstring{\textbf{Overfitting}: Um cenário de \emph{overfitting} ocorre quando, nos dados de treino, o seu modelo ML tem um desempenho excelente, porém quando utilizamos os dados em novos bancos de dados, seu resultado é ruim. Nesta situação, seu modelo aprendeu tão bem as relações existentes dos conjuntos de dados para treino que acabou apenas decorando esses dados. Portanto ao receber as informações das variáveis preditoras aos novos dados, o modelo tenta aplicar as mesmas regras decoradas, porém com estes novos dados (diferentes do treino) esta regra não tem validade e seu desempenho é afetado.}{Overfitting: Um cenário de overfitting ocorre quando, nos dados de treino, o seu modelo ML tem um desempenho excelente, porém quando utilizamos os dados em novos bancos de dados, seu resultado é ruim. Nesta situação, seu modelo aprendeu tão bem as relações existentes dos conjuntos de dados para treino que acabou apenas decorando esses dados. Portanto ao receber as informações das variáveis preditoras aos novos dados, o modelo tenta aplicar as mesmas regras decoradas, porém com estes novos dados (diferentes do treino) esta regra não tem validade e seu desempenho é afetado.}}\label{overfitting-um-cenuxe1rio-de-overfitting-ocorre-quando-nos-dados-de-treino-o-seu-modelo-ml-tem-um-desempenho-excelente-poruxe9m-quando-utilizamos-os-dados-em-novos-bancos-de-dados-seu-resultado-uxe9-ruim.-nesta-situauxe7uxe3o-seu-modelo-aprendeu-tuxe3o-bem-as-relauxe7uxf5es-existentes-dos-conjuntos-de-dados-para-treino-que-acabou-apenas-decorando-esses-dados.-portanto-ao-receber-as-informauxe7uxf5es-das-variuxe1veis-preditoras-aos-novos-dados-o-modelo-tenta-aplicar-as-mesmas-regras-decoradas-poruxe9m-com-estes-novos-dados-diferentes-do-treino-esta-regra-nuxe3o-tem-validade-e-seu-desempenho-uxe9-afetado.}}

As principais causas e soluções de um \emph{overfitting} são:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Algoritmo muito complexo para os dados: caso for possível, pode-se simplificar o modelo utilizado por um algoritmo mais simples, com menos parâmetros. Permitindo reduzir as chances do modelo sofrer \emph{overfitting}.
\item
  Poucos dados para treinar: dependendo da quantidade de dados utilizados para treinar, pode ser que seja uma amostra pequena, com isso recomenda-se aumentar seu tamanho coletando mais dados.
\item
  Ruídos nos dados de treinamento: é comum dentro do banco de dados existir algum tipo de ruído, isto é, \emph{outlier} (valores extremos ou até mesmo valores incorretos nos dados). Esses ruídos podem fazer com que o modelo aprenda sobre ele, levando ao overfitting. Seria recomendado pré-processamento adequado para tratar essa interferência.
\end{enumerate}

\hypertarget{underfitting}{%
\subsection{\texorpdfstring{\textbf{Underfitting}}{Underfitting}}\label{underfitting}}

No cenário \emph{underfitting}, o desempenho já é ruim no próprio treinamento de seu algoritmo.

As principais causas e soluções de um \emph{underfitting} são:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Algoritmo inadequado: bem provável que o modelo estatístico proposto pelo pesquisa pode não ter sido adequado ao comportamento dos dados. Por exemplo aplicar um algoritmo para funções de primeiro grau (linear) em um conjunto de dados com comportamento exponencial (função de segundo grau). Recomendável o pesquisador substituir o algoritmo escolhendo outro com outros parâmetros para solucionar o underfitting.
\item
  Características não representativas: há possibilidade de que as características que estamos utilizando para treinar o modelo não sejam representativas, ou seja, não possuem relação entre si ou não sejam importantes para o modelo aplicado.
\item
  Modelo com muitos parâmetros de restrição: o modelo torna-se inflexível, restrito, e não consegue se ajustar de forma adequada aos dados.
\end{enumerate}

Segue abaixo a Figura \ref{fig:graficofit} demonstrando os dois casos anteriores e um modelo adequado.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/graficofit} 

}

\caption{``Gráfico representando um \emph{Underfitting}, um Modelo bem ajustado e um \emph{Overfitting} respectivamente.''}\label{fig:graficofit}
\end{figure}



\hypertarget{validauxe7uxe3o-cruzada}{%
\section{Validação Cruzada}\label{validauxe7uxe3o-cruzada}}

A fim de que não haja previsões desastrosas geradas pelo modelo, para medirmos o desempenho real do modelo criado, é necessário que realizemos testes com ele, utilizando dados diferentes dos que foram apresentados no início. Portanto uma das técnicas mais utilizadas é a \textbf{Cross-validation (Validação Cruzada)}.

Após a realização do pré-processamento (analisar), iremos separar a totalidade dos dados históricos existentes em dois grupos, sendo o primeiro responsável pelo aprendizado do modelo, e o segundo por realizar os testes.
Seguindo o mesmo exemplo de bons ou mau pagadores, usualmente separamos o conjunto de dados dos clientes em duas amostras. Uma com

\hypertarget{como-escolher-um-bom-modelo}{%
\section{Como escolher um bom modelo?}\label{como-escolher-um-bom-modelo}}

\hypertarget{aocroc}{%
\section{AOC e ROC}\label{aocroc}}

\hypertarget{Algoritmosaprendizagem}{%
\chapter{Algoritmos de Aprendizagem I}\label{Algoritmosaprendizagem}}

\emph{Existe uma infinidade de algoritmos utilizados em machine learning, cada um com uma finalidade específica. Há também características que podem inviabilizar a escolha do modelo mais preciso para determinado problema, como a utilização alto poder computacional.}

\hypertarget{naive-bayes}{%
\section{Naive Bayes}\label{naive-bayes}}

Antes de falarmos sobre este algoritmo, vamos para o conceito matemático. Em (\ref{dicio}) tratamos do Teorema de Bayes para \(n\) atributos. Colocando-o como probabilidade condicional:
\[p(A|B_{1},...,B_{n}) = \]
\begin{equation} 
  p(A)p(B_{1}|A)p(B_{2}|A,B_{1}),p(B_{3}|A,B_{1},B_{2})...p(B_{n}|A,B_{1},B_{2},...,B_{n−1})
  \label{eq:bayescond}
\end{equation}

Assumindo que cada atributo \(B_i\) é condicionalmente independente de todos os outros \(B_j\) para \(j\neq i\) e \(p(B_i|A,B_j)=p(B_i|A)\) o modelo poderá ser expresso como:

\begin{equation} 
  p(A_k|B_1,...,B_n)=p(A_k)p(B_1|A_k)p(B_2|A_k),...=p(A_k)\prod_i^n p(B_i|A_k) \ k ∈{1,...,k}
  \label{eq:bayesprodutorio}
\end{equation}

Por fim para podermos classificar, aplicamos argumento de máxima para otimizarmos a função, assim obtém-se o classificador de Naive Bayes:

\begin{equation} 
  \mbox{classificador} \ \hat{y}=argmax \ p(A_k)\displaystyle \prod_{i=1}^n p(B_i|A_k) \ \ k ∈{1,...,k}
  \label{eq:naivebayes}
\end{equation}

Lembrando que para cada atributo, a sua distribuição de probabilidades é assumida como normal.

O Naive Bayes é uma técnica de classificação baseado no teorema de Bayes com uma suposição de independência entre os preditores, ou seja, este classificador assume que a presença de uma característica particular em uma classe não está relacionada com a presença de qualquer outro fator. Por exemplo, uma fruta verde, redonda e com um tamanho de diâmetro X pode ser uma melancia, porém mesmo que estas variáveis dependam uns dos outros e de outras características, todas estas propriedades contribuem de forma independente para a probabilidade de que seja uma melancia. Este modelo é muito utilizado devido que é fácil de construir e particularmente útil para grandes volumes de dados. Porém a própria independência entre os preditores a torna desvantajosa na prática e caso haja variáveis categóricas num conjunto de dados de teste que não forem treinadas, o modelo não irá estimar estas novas variáveis.

\hypertarget{exbayes}{%
\subsection{Exemplo}\label{exbayes}}

No diagnóstico de uma nova doença e que foi feito testes em 100 pessoas aleatórias (exemplo de \citet{organica}).

Após coletarmos a análise, descobrimos que das 100 pessoas, 20 possuíam a doença (20\%) e 80 pessoas estavam saudáveis (80\%), sendo que das pessoas que possuíam a doença, 90\% receberam o resultado positivo no teste da doença, e 30\% das pessoas que não possuíam a doença também receberam o teste positivo. Caso uma nova pessoa realizar o teste e receber um resultado positivo, qual a probabilidade de ela realmente possuir a doença?

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/bayes} 

}

\caption{Dados coletados de uma amostra de 100 pessoas aleatórias.}\label{fig:bayes}
\end{figure}



Com o algoritmo de Naive Bayes, buscamos encontrar uma probabilidade da pessoa possuir a doença dado que ela recebeu um resultado positivo, multiplicando a probabilidade de possuir a doença pela probabilidade de ``receber um resultado positivo, dado que tem a doença''. De mesmo modo verificar a probabilidade de não possuir a doença dado que recebeu um resultado positivo.

Ou seja, ao caso de ter a doença dado que o resultado deu positivo:
\[P(doença|positivo) = 20\% . 90\% \] \[P(doença|positivo) = 0,2 * 0,9 \] \[P(doença|positivo) = 0,18\]
Para o caso de não ter a doença, dado que deu positivo:
\[P(não \ doença|positivo) = 80\%.30\%\]
\[P(não \ doença|positivo) = 0,8 * 0,3\]
\[P(não\ doença|positivo) = 0,24\]
Após isso precisamos normalizar os dados, para que a soma das duas probabilidades resulte 1 (100\%). Como vimos em pré-processamento \ref{preprocesso}, a \textbf{Normalização por reescala} por meio de um valor mínimio e um máximo, gera um novo intervalo onde os valores de um atributo estão contidos. Um intervalo entre 0 e 1. Portanto, dividimos o resultado pela soma das duas probabilidades.

\[P(doença|positivo) = 0,18/(0,18+0,24) = 0,4285\]
\[P(não doença|positivo) = 0,24/(0,18+0,24) = 0,5714\]
Logo, podemos concluir que se o resultado do teste da nova pessoa for positivo, ela possui aproximadamente 43\% (0,4285) de chance de estar doente.

Naive Bayes é uma técnica de classificação baseado no teorema de Bayes com uma \textbf{suposição de independência entre os preditores} diferentemente do caso em \ref{dicio} (Teorema de Bayes), ou seja, O Naive Bayes assume que a presença de uma característica particular em uma classe não está relacionada com a presença de qualquer outro fator. Ao caso da melancia, uma fruta verde, redonda e com um tamanho de diâmetro X é possível ser ela, porém mesmo que estas variáveis dependam uma das outras e de outras características, elas contribuem de forma independente para a probabilidade de que seja uma melancia. É um modelo simples de construir e útil para grandes volumes de dados. Porém a própria independência entre os preditores a torna desvantajosa para apliação prática e que variáveis categóricas num conjunto de dados de teste que não foram treinadas, não irá estimar essa nova variável.

Por isso \emph{Naive} vem do significado ``ingênuo'', pois como a Figura \ref{fig:naive} demonstra, os atributos contribuem de forma independente para a probabilidade de A.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/naive} 

}

\caption{Gráfico de Probabilidade x Entropia.}\label{fig:naive}
\end{figure}



\hypertarget{reg}{%
\section{Regressão}\label{reg}}

A análise de variância, pressupõe a independência dos efeitos dos diversos tratamentos utilizados no experimento. Quando a hipótese não é verificada, necessitamos refletir a dependência entre os efeitos dos tratamentos. No caso de experimentos quantitativos, frequentemente justifica a existência da equação de regressão, que une os valores dos tratamentos aos analisados. Em grande parte, trata de estimação e/ou previsão do valor médio (para população) da variável dependente com base nos valores conhecidos da variável explanatória. É uma análise supervisionada.

\hypertarget{reglin}{%
\subsection{Análise de Regressão Linear Simples}\label{reglin}}

Como na prática não conseguimos análisar uma população, trabalhamos em cima de amostras e estimamos para o todo, para que possamos fazer uma aproximação. Partimos da ideia de estimarmos uma função com dados amostrais com o menor erro possível. Portanto, o \(Y_i\) (população) observado pode ser expresso como:

\begin{equation}
    Y_i=\hat{Y_i}+\hat{\mu_i}
    \label{eq:frp}
\end{equation}

E o modelo para função de regressão amostral:
\begin{equation}
    Y_i=\hat{\beta_0}+\hat{\beta_1}X_i+\hat{\mu_i}
    \label{eq:fra}
\end{equation}

em que:

\(\hat{Y_i}\) é o valor observado com \(i\) níveis de \(X\) (estimador da esperança \(E(Y|Xi)\)), \(\hat{\beta_0}\) a constante de regressão estimado e intercepto de \(\hat{Y}\), \(\hat{\beta_1}\) o coeficiente de regressão estimado que seria a variação de \(\hat{Y}\) em função da variação de cada unidade de \(X\), \(X_i\) com \(i\) níveis da variável independente e \(\hat{\mu_i}\) é o erro associado à distância entre o valor observado e o correspondente ponto na curva. Note que os ``chapéis'' em cima das variáveis é utilizado quando referimos a estimações, ou seja, são variáveis de dados amostrais e não a população.

Mas como estimaremos os parâmetros da função de forma que fique mais próxima possível e com o menor erro? Com o método dos \textbf{Mínimos Quadrados Ordinários (MMQ)} atribuído ao Carl Friedrich Gauss - matemático alemão - torna-se possível estimar os melhores \(\beta_0\) e \(\beta_1\) que minimizam os erros.

Como não podemos observar a função de regressão populacional (FRP), precisamos estimá-lo por meio da função de regressão amostral:
\[Y_i=\hat{\beta_0}+\hat{\beta_1}X_i+\hat{\mu_i} \]
\[Y_i=\hat{Y_i}+\hat{\mu_i}\]
\[\mbox{Logo temos que} \rightarrow \ \hat{\mu_i}=Y_i-\hat{\beta_0}-\hat{\beta_1} X_i\]

Podemos ver que os erros \(\hat{\mu_i}\) (resíduos) são basicamente as diferenças entre os valores observados e estimados de \(Y\). Ao caso de dados com \(n\) pares de observações de \(Y\) e \(X\), queremos encontrar a FRA que se encontra o mais próximo possível do \(Y\) observado, ou seja, escolher a
FRA de modo que a soma dos resíduos \(\sum \hat{\mu}_i=\sum(Y_i-\hat{Y_i})\) seja a menor possível. Porém, como se pode ver pelo diagrama de dispersão na Figura \ref{fig:mmq}, os erros possuem a mesma importância com variações entre sinais positivos e negativos e sua somatória será zero. Isso dificultaria a possibilidade de minimizarmos.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/mmq} 

}

\caption{Critério do minímos quadrados \citet{gujarati2011econometria}.}\label{fig:mmq}
\end{figure}



Para evitarmos isso, utilizamos o critério dos mínimos quadrados, de modo que elevamos os resíduos ao quadrado. Fazendo isso, o método dá mais peso aos resíduos (não irão mais se anular), podendo visualizar melhor o ``tamanho'' do erro total e obter propriedades estatísticas mais desejáveis.
\[\sum \hat{\mu}^2_i=\sum(Y_i-\hat{Y_i})^2 \]
\begin{equation}
    = \sum (Y_i-\hat{\beta_0}-\hat{\beta_1})X_i^2 
    \label{eq:mmqeq}
\end{equation}

O método dos mínimos quadrados nos oferece estimativas únicas de \(\beta_0\) e \(\beta_1\) que proporcionam o menor valor possível (encontrando \(\hat{\beta_0}\) e \(\hat{\beta_1}\)) de \(\sum \hat{\mu}_i\). Por meio de cálculo diferenciável (recomendo o leitor interessado em se aprofundar na definição matemática buscar literaturas em foco estatístico ler, como por exemplo de \citet{gujarati2011econometria}) é possível obter:

\begin{equation}
    \sum Y_i=n\hat{\beta_0} + \hat{\beta_1} \sum X_i
    \label{eq:sumyi}
\end{equation}

\begin{equation}
    \sum Y_i X_i=\hat{\beta_0} \sum X_i + \hat{\beta_1} \sum X_i^2
    \label{eq:sumyixi}
\end{equation}

Para encontrarmos os valores dos \(\beta's\) a fim de minimizar. Precisamos aplicar a derivada parcial:

\[\mbox{temos que:  }\ \sum\hat{\mu}_i^2=\sum(Y_i-\hat{\beta_0}-\hat{\beta}_1X_i)^2\]
\[\frac{\partial(\sum\hat{\mu})}{\partial \hat{\beta}_0}\rightarrow-2\sum\hat{\mu}=-2\sum(Y_i-\hat{\beta}_0-\hat{\beta}_1X_i)\]
\[\frac{\partial(\sum\hat{\mu})}{\partial \hat{\beta}_1}\rightarrow-2\sum\hat{\mu}X_i=-2\sum(Y_i-\hat{\beta}_0-\hat{\beta}_1X_i)X_i\]
\[(Y_i-\hat{\beta}_0-\hat{\beta}_1X_i)=0 \ \ \ (I)\]
\[(Y_i X_i-\hat{\beta}_0X_i-\hat{\beta}_1X_i^2)=0 \ \ \ (II)\]
Expandindo o somatório de (I):
\[-\sum Y_i+ n\hat{\beta}_0+\hat{\beta}_1\sum X_i=0\]
Note que se isolarmos \(\sum Y_i\), obtém-se a equação \eqref{eq:sumyi}. Ao isolarmos \(\hat{\beta}_0\) obtemos:
\[\hat{\beta}_0=\frac{\sum Y_i}{n}-\hat{\beta}_1\frac{X_i}{n} \ \ \ (III)\]
\begin{equation}
\hat{\beta}_0=\overline{Y}_i-\hat{\beta}_1\overline{X}_i
\label{eq:betazero}
\end{equation}

Expandindo (II), obtemos:
\[-\sum X_iY_i+\hat{\beta}_0\sum X_i+\hat{\beta}_1\sum X_i^2=0 \ \ \ (IV)\]
Note também que isolando \(\sum X_i Y_i\) teremos a equação \eqref{eq:sumyixi}.

Por fim, substituindo (III) em (IV) e manipulando algebricamente, também temos \(\hat{beta}_1\):
\[\hat{\beta}_1=\frac{n\sum X_iY_i-\sum X_i \sum Y_i}{n\sum X_i^2-(\sum X_i)^2}=\frac{\sum (X_i-\overline{X})(Y_i-\overline{Y})}{\sum(X_i-\overline{X})^2}\]
\begin{equation}
\hat{\beta_1}=\frac{\sum x_i y_i}{\sum x_i^2}
\label{eq:betaum}
\end{equation}
em que \(\overline{X}\) e \(\overline{Y}\) são as médias amostrais de \(X\) e de \(Y\) e que \(x_i=(X_i-\overline{X})\) e \(y_i=(Y_i-\overline{Y})\).

Os estimadores são conhecidos como \textbf{estimadores de mínimos quadrados}. Cada estimador proporciona um único valor do parâmetro populacional relevante e que, após obtê-los, torna-se possível elaborar a linha de regressão amostral que passa pelas médias amostrais de \(X\) e de \(Y\).

Para obtermos o erro padrão da estimativa como uma medida resumida da ``qualidade do ajustamento'' da linha de regressão, podemos pela expressão:

\begin{equation}
\hat{\sigma}=\sqrt{\frac{\sum \hat{\mu}_i^2}{n-2}}
\label{eq:desvioreg}
\end{equation}

Lembrando que para obtermos a variância, basta elevarmos ao quadrado.

Para que seja feito o modelo de regressão, ela depende das premissas: independência das variáveis erro, homogeneidade das variâncias, normalidade e relação linear entre as variáveis \(X\) e \(Y\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Para a independência do termo de erro, os valores assumidos pelo regressor \(X\) podem ser fixos ou mudar de acordo com variável dependente \(Y\). Para o o caso de não serem fixos, a covariância entre a variável e a o termo erro precisa ser zero (independentes). \(cov(X_i,\mu_i)=0\).
\item
  O valor médio do erro \(\mu_i\) é zero. Ou seja: \(E(\mu_i|X_i)=0\) e se \(X\) não aleatório \(E(\mu)i=0\). Isto implica de que não haja viés de especificação do modelo diante da análise empírica, os fatores não inclusos específicamente no modelo agrupados em \(\mu_i\) não afetam sistematicamente o valor médio de \(Y\) \citep{gujarati2011econometria}.
\item
  Variância constante de \(\mu_i\) (\textbf{Homocedasticidade}). A variância do termo de erro será a mesma independente do valor de \(X\).
\item
  Entre os termos de erro, dados qualquer valor de \(X\), não há autocorrelação. Ou seja \(cov(\mu_i,\mu_j|X_i \ \mbox{e} \ X_j)=0\), em que \(i\) e \(j\) são duas observações diferentes \citep{gujarati2011econometria}. Para entender melhor, na figura a seguir, não queremos (a) e (b).
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/autocorrmu} 

}

\caption{Padrões de correlação entre os termos de erro. (a) correlação serial positiva; (b) correlação serial negativa; (c) correlação zero \citet{gujarati2011econometria}.}\label{fig:autocorrmu}
\end{figure}



Para o caso das observações \(X's\) com \(Y\) precisa-se haver correlações entre si.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\item
  O número de observações \(n\) deve ser maior que o número de parâmetros a serem estimados e que os valores de \(X\) em uma amostra não devem ser os mesmos ou muito discrepantes (poderá haver problemas de \emph{outliers} que será apresentado em \ref{outlier}).
\item
  Uma das propriedades da distribuição normal é que qualquer função linear que possui variáveis com distribuição normal também é normalmente distribuída; as variáveis com distribuição normal, covariância ou correlações iguais a zero, indicam que há independência das variáveis presentes na amostra. Por isso é importante a etapa de pré-processamento. Aos interessados, recomendo-os buscar em algumas literaturas alguns testes de normalidade, como a de \citep{shapiro1965analysis}, para verificar o comportamento do conjunto de dados.
\end{enumerate}

Segundo o \textbf{Teorema de Gauss-Markov}, dadas as premissas do modelo clássico de regressão linear, os estimadores de mínimos quadrados dos estimadores não viesados possuem variância mínima. Podemos dizer que são o melhor estimador linear não viesado \citep{gujarati2011econometria}.

\begin{itemize}
\tightlist
\item
  \textbf{Coeficiente de determinação \(r^2\): medir a qualidade de seu ajuste}
\end{itemize}

Estimamos os parâmetros e o erro da função, agora precisamos considerar a \textbf{qualidade do ajuste} da linha de regressão ajustada a um conjunto de dados, ou seja, vamos descobrir quão ``bom'' o ajuste dessa linha de regressão
amostral é adequada aos dados. Se todas as observações estivessem exatamente em cima da linha de regressão, seria ``perfeito'', o que raramente acontece e provávelmente seria um problema de \textbf{Overfitting} (será apresentado em \ref{valid} para verificarmos a validade do modelo). O coeficiente de terminação \(r^2\) é um medida que diz quanto a linha de regressão
amostral ajusta-se aos dados.

Para entendermos melhor, vamos visualizar por Diagrama de Venn \citep{kennedy1981ballentine}. O círculo \(Y\) representa a variação da variável dependente \(Y\) e o círculo \(X\), a variação da variável explanatória \(X\) como vimos em regressão linear. A área sombreada indica o quanto em que a variação de \(Y\) é explicada pela variação de \(X\). Quanto maior a área sobreposta, maior a parte da variação de \(Y\) é explicada por \(X\). O coefiente de determinação \(r^2\) é apenas a medida numérica dessa sobreposição. Na Figura \ref{fig:ballentine}, conforme move-se da esquerda para a direita, a sobreposição aumenta, ou seja, uma proporção cada vez maior da variação de \(Y\)
é explicada por \(X\) (o \(r^2\) aumenta). Sem sobreposição, \(r^2=0\) e com total sobreposição, \(r^2=1\), pois 100\% da variação de \(Y\) é explicada por \(X\). Portanto o coefienciente situa-se no intervalo entre 0 e 1.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/ballentine} 

}

\caption{Coeficiente de determinação, prossegue a sobreposição de (a): \(r^2=0\) até (f) \(r^2=1\) \citep{gujarati2011econometria}.}\label{fig:ballentine}
\end{figure}



Podemos chegar ao coeficiente de determinação apenas por manipulação algébrica:

\[\mbox{sabemos que:} \ y_i=\hat{y}_i+\hat{\mu}_i\]
\[\mbox{elevando ao quadrado e somando a amostra:} \ \sum y^2_i=\sum \hat{y}^2_i+\sum \hat{\mu}^2_i+2\sum \hat{y}_i \hat{\mu}_i \]
\[\mbox{como} \ \sum \hat{\mu}_i=0, \ \mbox{temos que:}\ \sum y^2_i= \hat{y}^2_i+\sum \hat{\mu}^2_i \]
\[\sum y^2_i=\hat{\beta}^2_1 \sum x_i^2+\sum \hat{\mu}^2_i \]

\begin{equation}
    \mbox{podemos dizer} \ SQT=SQE+SQR
    \label{eq:sqt}
\end{equation}

sendo SQT a soma total dos quadrados, SQE a soma do quadrados explicados e SQR soma dos quadrados dos resíduos.

\[\mbox{dividindo a equação anterior por SQT:}\]
\[1=\frac{SQE}{SQT}+\frac{SQR}{SQT} \]
\[\mbox{definindo}\ r^2 \ \mbox{como:} \ \frac{SQE}{SQT} \]

\begin{equation}
    \mbox{obtemos:} \ r^2=1-\frac{SQR}{SQT} \rightarrow 1 - \frac{\sum \hat{\mu}_i}{\sum (Y_i - \overline{Y}_i)^2}
    \label{eq:coefdet}
\end{equation}

\(r^2\) portanto, mede a proporção ou percentual da variação total de Y explicada pelo modelo de regressão. Por manipulação algébrica, podemos verificar também que \(r^2=\hat{\beta}^2_1(\frac{S^2_x}{S^2_y})\), sendo \(S^2_x\ \mbox{e} \ S^2_y\) as respectivas variâncias amostrais de \(X\) e \(Y\).

Note que ao aplicarmos a raiz quadrada no coeficiente de determinação obtemos o coeficiente de correlação visto em \ref{medidasdep}, que mede o grau de associação entre duas variáveis.

\[r=\pm \sqrt{r^2}\]
- \textbf{Análise de Variância na Regressão}

Anteriormente vimos que \(\sum y^2_i=\hat{\beta}^2_1 \sum x_i^2+\sum \hat{\mu}^2_i\) podem ser expressas como \(STQ=SQE+SQR\), a soma total de quadrados (STQ) composta pela soma dos quadrados expicados pela regressão (SQE) e a soma do quadrado dos resíduos (SQR). Como sabe-se sobre análise de variância, associados a eles encontra-se os graus de liberdade, onde \(STQ\) possui \(n-1\) g.l ao calcular a média da amostra \(\overline{Y}\). A \(SQR\) tem \(n-2\) g.l (ao caso de duas variáveis com o intercepto presente) e a \(SQE\) possui 1 g.l (ao caso de duas variáveis) pela função \(SQE=\hat{\beta_1^2}\sum x^2_i\).

A tabela \textbf{ANOVA} com a hipótese nula \(H_0: \beta_1=0\) para verificar a existência da relação e a influência de \(X\) em \(Y\) ficará como:

\begin{longtable}[]{@{}lllll@{}}
\caption{\label{tab:anovareg} Tabela ANOVA para um modelo de regressão de duas variáveis.}\tabularnewline
\toprule
\begin{minipage}[b]{0.17\columnwidth}\raggedright
C.V\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
G.L\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
S.Q\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Q.M\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
F.C\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.17\columnwidth}\raggedright
C.V\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
G.L\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
S.Q\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Q.M\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
F.C\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.17\columnwidth}\raggedright
Regressão (SQE)\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\(\sum \hat{y}_i^2=\hat{\beta}_1^2 \sum x_i^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\(\hat{\beta}_1^2 \sum x_i^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\(\frac{Q.M.SQE}{Q.M.SQR}\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
Erro (SQR)\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
n-2\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\(\sum \hat{\mu}_i^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\(\frac{\sum \mu_i^2}{n-2}=\hat{\sigma}^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
Total (STQ)\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
n-1\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\(\sum \hat{y}_i^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\textbf{Não esqueça:} dependendo das variáveis em estudo é possível que haja comportamento polinomial ao observarmos no gráfico, podendo ser quadrática, cúbica, etc. Os procedimentos são os mesmos de que linear, mas basicamente incluímos a variável e seu respectivo grau. Dependendo do comportamento muitas vezes é mais fácil ao invés e manter em exponencial (não linear), linearizarmos a função por meio dos logaritmos, semi-logaritmicos entre outros. Isso faz com que temos menos trabalho para tratarmos e estimarmos os parâmetros da função exponencial.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/explog} 

}

\caption{Em (a) curva de função exponencial e (b) após aplicarmos o logaritmo \citep{gujarati2011econometria}.}\label{fig:explog}
\end{figure}



Atualmente é bem comum utilizarmos o modelo \textbf{log-log}, pois seu coeficiente angular \(\beta_i\) mede a \textbf{elasticidade} de \(Y\) em relação a \(X\), ou seja, a variação percentual de \(Y\) correspondente a uma variação percentual em \(X\). Por exemplo: na Figura \ref{fig:explog} se \(Y\) representa a quantidade demandada de camisetas e \(X\) seu preço unitário. Em (a) temos a relação da quantidade de demanda por camisetas e o preço, mas com a transformação logaritmica teremos a estimação de \(-\beta_2\) (pois é uma reta descendente) que indica a elasticidade preço (variação em \(ln(Y)\) por unidade de variação em \(ln(X)\)). Portanto teríamos a variação percentual da quantidade demandada de camisetas dada uma variação percentual do preço. Atente-se: \textbf{porcentagem} \citep{gujarati2011econometria}.

\hypertarget{regmult}{%
\subsection{Regressão Linear Múltipla}\label{regmult}}

Na prática deparamos com muitas outros fatores que podem influenciar em sua variável dependente \(Y\). Portanto são acrescentadas dentro de seu modelo de regressão mais variáveis, o que é conhecido como \textbf{Regressão Linear Múltipla}, nada mais do que uma ampliação da regressão linear simples. Num modelo, por exemplo, com três variáveis (caso mais simples) pode ser expressa para a amostra como:

\begin{equation}
    Y_i=\hat{\beta_0}+\hat{\beta_{1}}X_{1i}+\hat{\beta_{2}}X_{2i}+\mu_i
    \label{eq:regmult}
\end{equation}

Da mesma forma, \(Y_i\) a variável dependente, \(X_{2}\) e \(X_{3}\) as independentes explanatórias (explicativa), \(\mu_i\) o erro estocático e \(i\) para indicar \(i\)-ésima observação. Ao caso dos parâmetros, \(\beta_0\) como intercepto, \(\beta_1\) e \(\beta_2\) os \textbf{coeficientes parciais de regressão/angulares}. \(\beta_2\) mede a variação no valor médio de \(Y\) (esperança de \(Y\)), por unidade de variação em \(X_2\), mantendo \(X_3\) constante, ou seja, traz o efeito ``direto'' de uma unidade de variação em \(X_2\) sobre o valor médio de \(Y\), excluindo o efeito de \(X_3\) na média de \(Y\). De mesmo modo, \(X_3\) com \(X_2\) constante.

A regressão múltipla pressupõe as mesma hipóteses de que a regressão linear simples, porém como acréscimo - e muito importante- que as variáveis independentes devem estar \textbf{ausentes de multicolinearidade}, ou seja, não devem haver relação linear entre si. Se essa relação linear existir entre \(X_2\) e \(X_3\) \textbf{são colineares} ou \textbf{linearmente dependentes}, do contrário \textbf{linearmente independentes}. Caso a multicolinearidade for perfeita, os coeficientes de regressão das variáveis \(X\) serão indeterminados e seus erros padrão, infinitos. Se a multicolinearidade for menos que perfeita, serão determinado mas com grandes erros padrão (em relação aos próprios
coeficientes), o que trará um modelo ruim para sua estimação.

Para medirmos a multicolinearidade é comum a análise de \textbf{correlação de pearson} entre todas as variáveis, como mencionada em \textbf{Medidas de Dependência \ref{medidasdep}}, ou analisar a ocorrência de intervalo de confiança mais amplo, verificação de razões ``t'' insignificantes mesmo que seu \(R^2\) esteja alto, parâmetros estimados muitos sensíveis a qualquer alteração de dados e comumente utilizado para verificar o \textbf{fator de inflação de variância (FIV)} \citep{montgomery2012introduction}, que pode ser expressa como:

\begin{equation}
    VIF_j=\frac{1}{1-r^2_j} \ \ j=1,2,...,p
    \label{eq:vif}
\end{equation}

sendo \(r^2\) o coeficiente de correlação ao quadrado e \(j\) para referir as variáveis. Por exemplo, se \(r^2_{23}\), refe-se ao coeficiente de correlação entre as variáveis \(X_2\) e \(X_3\). Segundo ,quando este indicador apresenta o valor acima de cinco, é possível a existência de multicolinearidade \citep{maroco2014analise}.

De mesmo modo que em regressão linear simples, são estimados os MQO, Máxima verossimilhança e o \textbf{coeficiente de determinação múltiplo \(R^2\)} (mesma interpratação para regressão linear simples \(r^2\)) para que se obtenha a melhor aproximação possível.

\hypertarget{mpl}{%
\subsection{Modelo de Probabilidade Linear (MPL)}\label{mpl}}

Considerando um modelo típico de regressão linear simples:
\[Y_i=\beta_0+\beta_1 X_i+\mu_i \]

em que \(X =\)sua renda e \(Y=1\) de que você compre um celular e \(0\) não compre. Como o regressando é binário, ou dicotômico, chamamos de probabilidade linear (MPL). Pode ser interpretada como probabilidade condicional de que o evento ocorra dado \(X_i\), isto é, Pr \((Yi = 1 | Xi)\). Neste caso, é a probabilidade de você comprar um celular e cuja renda é dado por \(X_i\).

Para entender este modelo, vamos supor \(E(\hat{\mu}_i)=0\) para evitarmos estimadores tendenciosos (erros). Portanto:

\begin{equation}
    E(Y_i|X_i)=\beta_0+\beta_1 X_i
    \label{eq:regcond}
\end{equation}

Com \(P_i=\)probabilidade de que \(Y_i=1\)(ocorrência do evento) e \((1-P_i)\)=probabilidade de \(Y_i=0\)(não ocorrência do evento). \(Y_i\) possui a seguinte \textbf{distribuição de probabilidade de Bernoulli}:

\begin{longtable}[]{@{}cc@{}}
\caption{\label{tab:bernoulireg}}\tabularnewline
\toprule
\textbf{\(Y_i\)} & \textbf{Probabilidade}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{\(Y_i\)} & \textbf{Probabilidade}\tabularnewline
\midrule
\endhead
\(0\) & \(1-P_i\)\tabularnewline
\(1\) & \(P_i\)\tabularnewline
\textbf{Total} & \(1\)\tabularnewline
\bottomrule
\end{longtable}

Aplicando a esperança, obtemos:

\begin{equation}
    E(Y_i)=0(1-P_i)+1(P_i)=P_i
    \label{eq:esperbernoulli}
\end{equation}

Igualando \eqref{eq:esperbernoulli} com \eqref{eq:regcond}, obtemos:

\begin{equation}
    E(Y_i|X_i)=\beta_0+\beta_1 X_i
    \label{eq:regprob}
\end{equation}

Isso verifica que a esperança condicional do modelo de regressão \eqref{eq:frp} pode ser interpretada como a probabilidade
condicional de \(Yi\). Note que, como explicado em \ref{dicio} sobre \textbf{Distribuição Bernoulli} e \textbf{Distribuição Binominal}, caso haja \(n\) observações independentes, cada um com uma probabilidade \(p\) (sucesso) e probabilidade \((1 - p)\) (fracasso) e \(X\) dessas observações representarem o número de sucessos, \(X\) então segue a distribuição binomial (com médi \(np\) e variância \(np(1-p)\). Lembrando que a probabilidade \(P_i\) situa-se entre 0 e 1 \(\rightarrow 0 \leq E(Y_i|X_i) \leq 1\).

Alguns detalhes importantes:

\begin{itemize}
\item
  A hipótese de normalidade de \(\mu_i\) não se verifica no caso dos modelos de probabilidade linear, pois os termos de erro assumem também apenas dois valores, seguindo a distribuição de Bernoulli. Se objetivo for a estimação pontual, a hipótese de normalidade deixa de ser necessária \citep{gujarati2011econometria} e que conforme aumentamos o tamanho da amostra indefinidamente, os estimadores de MQO tendem geralmente a distribuir-se normalmente.
\item
  Como sabe-se, a média e variância de uma distribuição Bernoulli possuem respectivamente \(p\) e \(p(1-p)\). Logo a variância é heterocedástica \(var(\mu_i)=P_i(1-P_i)\) e portanto os estimadores de MQO não são eficientes (não possuem variância mínima). Podemos fazer a transformação para que seja homocedástico:
  \[\sqrt{E(Y_i|X_i)-[1-E(Y_i|X_i)]}=\sqrt{P_i(1-P_i)=\sqrt{w_i}}\]
  \begin{equation}
    \frac{Y_i}{\sqrt{w)i}} = \frac{\beta_0}{\sqrt{w)i}}+\frac{\beta_1 X_i}{\sqrt{w)i}}+\frac{\mu_i}{\sqrt{w)i}}
    \label{eq:probhomecedastico}
  \end{equation}
\end{itemize}

Com a transformação, pode-se calcular por MQO (ponderados).

\textbf{Alternativas para o MPL:}

\begin{itemize}
\item
  Como mencionado, a probabilidade condicional situa-se entre \(0\) e \(1\), porém por MQO não levarem em conta esta restrição. Pode-se verificar os valores que constam entre o intervalo, considerando os valores negativos como \(0\) e maiores que \(1\) como iguais a \(1\) ou aplicar algum outro modelo para garanti-los dentro dos intervalos.
\item
  O \(R^2\) costuma-se situar muito abaixo de 1. Por ser limitado em caso de modelos binários, muitos pesquisadores buscam evitar seu uso.
\end{itemize}

Os modelos mais comuns para ser utilizado como alternativa ao MPL são o \textbf{logit} e o \textbf{probit} para evitar estes problemas.

\hypertarget{logit}{%
\subsubsection{Logit}\label{logit}}

A fim de fazer com que \(P_i\) varie entre 0 e 1 e relacione-se linearmente a \(X_i\), a \textbf{função de distribuição logística} pode ser expressa como:

\begin{equation}
    P_i=\frac{1}{1+e^{-Z_i}}=\frac{e^Z_i}{1+e^Z_i}
    \label{eq:logitpi}
\end{equation}

e \((1-P_i)\) da probabilidade fracasso:

\begin{equation}
    1-P_i=\frac{1}{1+e^{Z_i}}\rightarrow e^{Z_i}
    \label{eq:logitmenospi}
\end{equation}

onde \(Z_i=\beta_0+\beta_1X_i\). Assim \(Z_i\) varia de \(-\infty\) a \(\infty\) e portanto \(P_i\) entre 0 e 1.

Para estimarmos a MQO, precisamos linearizar a função:

\begin{equation}
    L_i=ln(\frac{P_i}{1-P_i})=Z_i=\beta_0+\beta_1 X_i
    \label{eq:logitlinear}
\end{equation}

O modelo \textbf{logit} faz com que:

\begin{itemize}
\item
  A probabilidade varie entre 0 e 1, enquanto \(Z\) e \(L\) possam variar de \(-\infty\) a \(\infty\);
\item
  Mesmo que as probabilides não sejam lineares, \(L\) é linear em \(X\);
\item
  Pode-se aplicar com mais regressores e com mesma interpretação angular medindo a variação de \(L\) para uma unidade variação em \(X\) e para o intercepto;
\item
  Se \(L\) torna-se maior e positivo quando as chances do evento de interesse ocorrer aumenta, do contrário (maior e negativo) de não ocorrer;
\item
  Como em MPL, o modelo Logit é heterocedástico precisa-se ponderar \citep{gujarati2011econometria, cox1970analysis}:
  \begin{equation}
    \sqrt{w_i}L_i=\beta_0 \sqrt{w_i}+\beta_1\sqrt{w_i}X_i+\sqrt{w_i}\mu_i 
    \label{eq:mqplogit}
  \end{equation}
\end{itemize}

em que, com a variância \(\hat{\sigma}^2=\frac{1}{N_i\hat{P_i}(1-\hat{P_i})}\), \(W_i\) é o peso \(N_i\hat{P_i}(1-\hat{P_i})\). Por fim, aplicar o mínimos quadrados ponderados (da mesma forma que MQO, porém com a nova transformação de dados) e estimarmos os parâmetros normalmente.

Como o \(R^2\) não é significativa nos modelos binários. É comum utilizar as \textbf{pseudo \$R\^{}2} {[}long1997regression{]} - existe uma variedade delas - ou o \textbf{Count \(R^2\)} que nada mais é que o número de previsões corretas com o número total de observações. Para a hiótese nula de que todos os coeficientes angulares são simultâneamente iguais a zero, utiliza-se a \textbf{estatística da razão de verossimilhança} que segue a distribuição \(\chi^2\) que equivale ao teste F.

Ressalto que existe muitos outros modelo de regressão, como por exemplo os modelos \textbf{Probit} e \textbf{Tobit}. Podemos dizer que possuem em geral os mesmos fundamentos da regressão que conhecemos, porém possuem algumas particularidades como a distribuição acumulada adequada dependendo da situação. O modelo \textbf{Probit} é muito utilizado quando supomos de que na distribuição do termo de erro, segue uma distribuição normal e utilizamos um limiar como referência para podermos estimar a probabilidade (possui resultados semelhantes de Logit). Ao caso da \textbf{Tobit} é muito utilizada para estimar relações com variáveis dependentes censuradas (por exemplo \(Y_i=Y_i^* \ \mbox{para} \ Y_i^* > 0 \ \mbox{e} \ Y_i=0 \ \mbox{para} \ Y_i^*\leq 0\)). Importante o pesquisador preparar seus dados e ter ciência de qual problema tratar e como lidar com este problema, para que se aplique um modelo adequado à situação.

\hypertarget{exemplo1reg}{%
\subsection{Exemplos}\label{exemplo1reg}}

Com base em \citet{morettin2017estatistica}, vamos a alguns exemplos de regressão linear simples:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A tabela a seguir, apresenta dados sobre o índice de mortalidade por câncer de pulmão (100=média) e o índice de consumo de fumo (100=média) para 25 grupos ocupacionais.
\end{enumerate}

\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tab:cancercigarro} Índice de mortalidade por câncer de pulmão e índice de consumo de fumo para 25 grupos sociais. Disponível em: \url{http://lib.stat.cmu.edu/datasets/} \emph{apud} \citep{morettin2017estatistica}, p.~160.}\tabularnewline
\toprule
\textbf{Ocupação} & \textbf{Câncer} & \textbf{Fumo}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Ocupação} & \textbf{Câncer} & \textbf{Fumo}\tabularnewline
\midrule
\endhead
Fazendeiro, profissionais de atividades florestais, pescador & 84 & 77\tabularnewline
Minerador, cavouqueiro & 116 & 137\tabularnewline
Operários da produção de combustíveis, coque e produtos químicos & 123 & 117\tabularnewline
Vidraceiro e ceramista & 128 & 94\tabularnewline
Fundidor & 155 & 116\tabularnewline
Operários da fabricação de eletroeletrônicos & 101 & 102\tabularnewline
Profissionais de engenharia e atividades associadas & 118 & 111\tabularnewline
Madereiros, marceneiros & 113 & 93\tabularnewline
Curtidores em confecção de artigos de couro & 104 & 88\tabularnewline
Operários da fabricação de artigos têxtis & 88 & 102\tabularnewline
Operários da confecção de vestuário & 104 & 91\tabularnewline
Profissionais da produção de alimentos, bebidas e tabaco & 129 & 104\tabularnewline
Operários da fabricação de papel e atividades gráficas & 86 & 107\tabularnewline
Operários da fabricação de outros produtos & 96 & 112\tabularnewline
Operários da construção civil & 144 & 113\tabularnewline
Pintores e decoradores & 139 & 110\tabularnewline
Operadores de máquinas, guindastes etc. & 113 & 125\tabularnewline
Operários não incluídos nestas categorias & 146 & 113\tabularnewline
Profissionais de transportes e comunicações & 128 & 115\tabularnewline
Estoquistas em armazéns, depósitos e lojas, almoxarifes\ldots{} & 115 & 105\tabularnewline
Escreventes, escriturários, funcionários de escritórios & 79 & 87\tabularnewline
Vendedores & 85 & 91\tabularnewline
Profisisonais de seviços, esportes e recreadores & 120 & 100\tabularnewline
Administradores e gerentes & 60 & 76\tabularnewline
Artistas e proissionais e técnicos em geral & 51 & 66\tabularnewline
\bottomrule
\end{longtable}

\newpage

\textbf{a.} Trace o gráfico de mortalidade por câncer de pulmão em relação ao índice de fumo. Que padrão podemos observar?

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/cancerfumo} 

}

\caption{Gráfico de mortalidade por câncer em relação ao índice de fumo.}\label{fig:cancerfumo}
\end{figure}



Podemos verificar que conforme aumenta o número do índice de fumo, aumenta o índice de mortalidade por câncer. Visualizando o gráfico podemos perceber que possui uma correlação alta e positiva entre as variáveis.

\textbf{b.} Considerando Y = índice de mortalidade por câncer de pulmão e X = índice de fumo, estime um mdelo de regressão linear e obtenha as estatísticas de regressão.

Ao calcularmos a média de X e Y, \(\overline{Y}=109,0\) e \(\overline{X}=102,08\), podemos calcular \(y_i=Y_i-\overline{Y}\) e \(x_i=X_i-\overline{X}\) entre outras estatísticas habituais.

\begin{longtable}[]{@{}lcccccccc@{}}
\toprule
& Câncer & Fumo & \(y_i\) & \(x_i\) & \(x^2_i\) & \(y_ix_i\) & \(y^2_i\) & \(X^2_i\)\tabularnewline
\midrule
\endhead
& 84 & 77 & -25 & -25 & 629.01 & 627 & 625 & 5929\tabularnewline
& 116 & 137 & 7 & 35 & 1219.41 & 244.44 & 49 & 18769\tabularnewline
& 123 & 117 & 14 & 15 & 222.61 & 208.88 & 196 & 13689\tabularnewline
& 128 & 94 & 19 & -8 & 65.29 & -153.52 & 361 & 8836\tabularnewline
& 155 & 116 & 46 & 14 & 193.77 & 640.32 & 2116 & 13456\tabularnewline
& 101 & 102 & -8 & 0 & 0.01 & 0.64 & 64 & 10404\tabularnewline
& 118 & 111 & 9 & 9 & 79.57 & 80.28 & 81 & 12321\tabularnewline
& 113 & 93 & 4 & -9 & 82.45 & -36.32 & 16 & 8649\tabularnewline
& 104 & 88 & -5 & -14 & 198.25 & 70.4 & 25 & 7744\tabularnewline
& 88 & 102 & -21 & 0 & 0.01 & 1.68 & 441 & 10404\tabularnewline
& 104 & 91 & -5 & -11 & 122.77 & 55.4 & 25 & 8281\tabularnewline
& 129 & 104 & 20 & 2 & 3.69 & 38.4 & 400 & 10816\tabularnewline
& 86 & 107 & -23 & 5 & 24.21 & -113.16 & 529 & 11449\tabularnewline
& 96 & 112 & -13 & 10 & 98.41 & -128.96 & 169 & 12544\tabularnewline
& 144 & 113 & 35 & 11 & 119.25 & 382.2 & 1225 & 12769\tabularnewline
& 139 & 110 & 30 & 8 & 62.73 & 237.6 & 900 & 12100\tabularnewline
& 113 & 125 & 4 & 23 & 525.33 & 91.68 & 16 & 15625\tabularnewline
& 146 & 113 & 37 & 11 & 119.25 & 404.04 & 1369 & 12769\tabularnewline
& 128 & 115 & 19 & 13 & 166.93 & 245.48 & 361 & 13225\tabularnewline
& 115 & 105 & 6 & 3 & 8.53 & 17.52 & 36 & 11025\tabularnewline
& 79 & 87 & -30 & -15 & 227.41 & 452.4 & 900 & 7569\tabularnewline
& 85 & 91 & -24 & -11 & 122.77 & 265.92 & 576 & 8281\tabularnewline
& 120 & 100 & 11 & -2 & 4.33 & -22.88 & 121 & 10000\tabularnewline
& 60 & 76 & -49 & -26 & 680.17 & 1277.92 & 2401 & 5776\tabularnewline
& 51 & 66 & -58 & -36 & 1301.77 & 2092.64 & 3364 & 4356\tabularnewline
Soma & 2725 & 2552 & 0 & 0 & 6278 & 6980 & 16366 & 266786\tabularnewline
\bottomrule
\end{longtable}

Podemos agora calcular \(\hat{\beta_1}=\frac{\sum x_i y_i}{\sum x_i^2}=\frac{6980}{6278}\approx 1,112\) e portanto, podemos encontrar \(\hat{\beta}_0=\overline{Y}_i-\hat{\beta}_1\overline{X}_i \rightarrow 109,000-1.112 \ . \ 102,080\approx -4,50\).

Agora que temos os estimadores \(\beta_0\) e \(\beta_1\), podemos encontrar \(\hat{y}_i=\beta_0+\beta_1 . X_i\), o erro \(\mu_i=Y_i-\hat{y}_i\) e seu quadrado \(\mu^2\).

\begin{longtable}[]{@{}ccc@{}}
\toprule
\(\hat{y}\) & \(\mu_i=Y_i-\hat{y}_i\) & \(\mu^2\)\tabularnewline
\midrule
\endhead
81.11 & 2.89 & 8.32\tabularnewline
147.83 & -31.83 & 1012.88\tabularnewline
125.59 & -2.59 & 6.70\tabularnewline
100.02 & 27.98 & 783.09\tabularnewline
124.48 & 30.52 & 931.66\tabularnewline
108.91 & -7.91 & 62.58\tabularnewline
118.92 & -0.92 & 0.84\tabularnewline
98.90 & 14.10 & 198.69\tabularnewline
93.35 & 10.65 & 113.53\tabularnewline
108.91 & -20.91 & 437.27\tabularnewline
96.68 & 7.32 & 53.57\tabularnewline
111.13 & 17.87 & 319.17\tabularnewline
114.47 & -28.47 & 810.56\tabularnewline
120.03 & -24.03 & 577.42\tabularnewline
121.14 & 22.86 & 522.52\tabularnewline
117.81 & 21.19 & 449.19\tabularnewline
134.48 & -21.48 & 461.54\tabularnewline
121.14 & 24.86 & 617.95\tabularnewline
123.37 & 4.63 & 21.48\tabularnewline
112.25 & 2.75 & 7.58\tabularnewline
92.23 & -13.23 & 175.12\tabularnewline
96.68 & -11.68 & 136.44\tabularnewline
106.69 & 13.31 & 177.23\tabularnewline
80.00 & -20.00 & 400.12\tabularnewline
68.88 & -17.88 & 319.86\tabularnewline
2725 & 0 & 8605,31\tabularnewline
\bottomrule
\end{longtable}

Sua variância, com \(n=25\) observações, \(\sigma^2=\frac{\sum \mu_i^2}{n-2}=\frac{8605,31}{23}=374,144\) e o coeficiente de determinação \(r^2=1-\frac{\sum \mu^2_i}{\sum y^2_i}=1-\frac{8605}{16366}=0,4742\).

O ajuste da reta de regressão linear será portanto \(\hat{y}=-4,50+1,11x\).

\textbf{c.} Teste a hipótese de que o fumo não tem influência sobre o câncer de pulmão com nível de significância \(\alpha=5\%\).

Queremos
\[H_0: \ \hat{\beta_1}=0\]
\[H_1: \ \hat{\beta_1}\neq 0\]

Temos que \(SQR = \sum \hat{\mu}^2 = 8605,31\) e \(SQ Total = \sum \hat{y}^2_i=16366\). Logo \(SQE = SQT - SQR \approx 7760,695.\) Por fim, os Quadrados médios que referem-se a divisão das somas dos quadrados pelos seus respectivos graus de liberdade, podemos calcular e verificar o valor F tabelado.

\begin{longtable}[]{@{}llllll@{}}
\toprule
\begin{minipage}[b]{0.14\columnwidth}\raggedright
C.V\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
G.L\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
S.Q\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
Q.M\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
F.C (\(\frac{Q.M. \  SQE}{Q.M.\ SQR}\))\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
F. Tabelado (\(1,n-2,\alpha=5\%\))\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.14\columnwidth}\raggedright
Regressão\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
7760,695\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
7760,695\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
20,743\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
4,280\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.14\columnwidth}\raggedright
Erro\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
23\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
8605\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
374,144\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.14\columnwidth}\raggedright
Total\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
24\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
16366\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
681,917\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Como \(F.C > F. Tabelado\). Rejeita-se \(H_0\) e há relação linear e influência sobre o câncer de pulmão com 5\% de significância. Por meio do uso do software R, chegou-se a um p-valor de 0.000141, pode-se rejeitar \(H_0\) (é significativo) com baixa porcentagem de significância.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A seguir, os dados são referentes a porcentagem da população economicamente ativa empregada no setor primário e o respectivo índice de analfabetismo para algumas regiões metropoliatanas brasileiras.
\end{enumerate}

\begin{longtable}[]{@{}lll@{}}
\caption{\label{tab:ecoativa} Indicadores Sociais para Áreas Urbanas, IBGE, 1977 \emph{apud} \citep{morettin2017estatistica}, p.~92.}\tabularnewline
\toprule
\textbf{Regiões Metropolitanas} & \textbf{Setor Primário (X)} & \textbf{Índice de Analfabetismo (Y)}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Regiões Metropolitanas} & \textbf{Setor Primário (X)} & \textbf{Índice de Analfabetismo (Y)}\tabularnewline
\midrule
\endhead
São Paulo & 2,0 & 17,5\tabularnewline
Rio de Janerio & 2,5 & 18,5\tabularnewline
Belém & 2,9 & 19,5\tabularnewline
Belo Horizonte & 3,3 & 22,2\tabularnewline
Salvador & 4,1 & 26,5\tabularnewline
Porto Alegre & 4,3 & 16,6\tabularnewline
Recife & 7,0 & 36,6\tabularnewline
Fortaleza & 13,0 & 38,4\tabularnewline
\bottomrule
\end{longtable}

\textbf{a.} Sabedo que a reta de regressão linear simples ajustada é \(\hat{y}=13,561+2,289x\), faça o teste de significância:

\[SQT=\sum \hat{y}^2_i - \overline{Y}=5305,85-\frac{38298,49}{8}=518,538\]
\[SQE = 400,26 \ \mbox{e} \ SQR=118,12\]
\[\mbox{(encorajo-o ao leitor verificar)}\]
Queremos
\[H_0: \ \hat{\beta_1}=0\]
\[H_1: \ \hat{\beta_1}\neq 0\]

\begin{longtable}[]{@{}llllll@{}}
\toprule
\begin{minipage}[b]{0.14\columnwidth}\raggedright
C.V\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
G.L\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
S.Q\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
Q.M\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
F.C (\(\frac{Q.M. \  SQE}{Q.M.\ SQR}\))\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
F. Tabelado (\(1,n-2,\alpha\))\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.14\columnwidth}\raggedright
Regressão (SQE)\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
1\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
400,26\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
400,26\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
20,33\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
5,99\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.14\columnwidth}\raggedright
Erro (SQR)\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
6\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
118,12\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
19,686\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.14\columnwidth}\raggedright
Total\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
7\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
518,54\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
-\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Como \(F.C > F. Tabelado\), rejeita-se \(H_0\) à \(5\%\) do nível de significância, à inclinação \(\beta_1\) é diferente de zero e assim há relação linear simples entre o porcentual de analfabetismo e porcentual do setor primário.

\textbf{b.} Estime o índice de analfabetismo para 20\% da população empregada no setor primário.

\[\hat{y}=13,561+2,289 \ . \ 20\%=59,341\%\]
O porcentual do valor estimado do índice de analfabetismo é de 59,341\% para 20\% da população empregada no setor primário.

\textbf{c.} Determine o coeficiente de determinação e interprete seu resultado.

\[r^2=\frac{SQE}{SQT}=\frac{400,26}{518,54}=0,7719\]
Logo, da variação total do índice de analfabetismo, 77\% é explicado pela equação da reta.

\hypertarget{GD}{%
\section{Gradiente Descendente (GD)}\label{GD}}

Para a obtenção dos parâmetros de forma analítica, como regressões, muitas vezes é difícil obter os parâmetros que minimizam determinada função de interesse. Dificuldades em obter a solução do sistema na forma fechada (ou não existir) ou quando \(n\) é muito grande, o cálculo da inversa (estimando os parâmetros matricialmente) pode ser muito caro computacionalmente.

O \textbf{Gradiente Descendente (GD)} pode ser muito útil dependendo da situação, conhecido também como \textbf{máximo declive}, é um método númerico utilizado em otimização. Tem como finalidade identificar um mínimo local de uma função de modo iterativo, no qual a cada iteração toma-se a direção do gradiente. Muitas vezes serve como base para algoritmos de segunda ordem como Métodos de Newton, por exemplo.

É uma função para casos gerais, por praticidade vamos supor que temos uma função denominada custo com apenas dois parâmetros \(J(\theta_0,\theta_1)\) e queremos estimar seus parâmetros que minimizam seus erros. Inicialmente atribuímos quaisquer estimativas iniciais para valores de \(\theta_0\) e \(\theta_1\), com o GD vamos alterandos os valores dos \(\theta's\) para reduzirmos \(J(\theta_0,\theta_1)\) até que se chegue a um valor mínimo local.

Um exemplo que gosto muito, por \citet{andrewcoursera}: observe a Figura \ref{fig:gd} e imagine que você está em um campo, com dois montes. Mantenha sua imaginação de que está situado na cruz preta - ponto 0 - no primeiro monte vermelho. Com o GD vamos olhar 360 graus ao redor do ponto em que você está situado apenas para descobrir a resposta de que ``se você fosse dar um pequeno passo em alguma direção ao seu redor com o objetivo de ir para o ponto mais baixo do campo o mais rápido possível, para qual direção você deve andar?''

Supondo que após olhar para todos os lados, com análise de GD você descobriu que seu primeiro passo será no ponto 1 da Figura \ref{fig:gd}. Após isso, você observa novamente para todos os lados e faz outra análise de GD para verificar aonde você vai se deslocar em seu segundo passo para chegar o mais rápido possível até concluir que será o ponto 2. Assim, sucessivamente, você vai se deslocando para os respectivos pontos 3, 4 e sucessivamente até convergir em seu objetivo Z, porém caso você iniciasse pelo ponto K, é bem possível que por meio do GD você descesse o monte por outro trajeto, encontrando outros pontos ótimos locais até chegar a outro ponto otimizado (descer por completo o monte). Esta é a ideia do Gradiente Descendente, por meio de iterações, o algoritmo vai identificando os pontos ótimos (estimadores mínimos) até convergir num ótimo local da função.

Em caso de funções simples como regressão linear, não é necessário o uso de GD. Mas em casos com muitas variáveis e ordens, pode ser bem viável.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/gd} 

}

\caption{Gráfico tridimensional a exemplo de Gradiente Descendente \citep{andrewcoursera}.}\label{fig:gd}
\end{figure}



O algoritmo pode ser expresso como:

\begin{equation}
    \theta_j := \theta_j - \alpha \frac{d}{d \theta_j}J(\theta_0,\theta_1) \ \mbox{com} \ j=\theta_0 \ \mbox{e} \ j=\theta_1 
    \label{eq:GD}
\end{equation}

com \(j\) referindo-se à quantidade de observações (parâmetros que pretendemos estimar) da amostra.

O algoritmo é processado da seguinte forma: imagine na mesma Figura \ref{fig:gd} que você irá dar seu primeiro passo, olhou os 360 graus e inseriu as variáveis em seu algoritmo de GD e seu destino é em \(Z=10\). Seu algoritmo calcula se você passou seu destino mais do que devia ou se você está atrás de \(Z\) ainda e também verifica se precisa dar passos grandes por estar bem longe de seu destino, ou passos menores. Supondo que seu \(\alpha\) um pouquinho alto, podemos dar um passo grande para descer o monte (1) pela diferença da observação que você inseriu com \(\alpha \frac{d}{d \theta_j}J(\theta_0,\theta_1)\). Caso fosse uma taxa pequena de \(\alpha\), seu passo seria menor e sua derivada (taxa de variação) vai lhe dizer se você passou do ponto ótimo de \(Z\) (o quão a frente) ou está para trás (quão para trás) desse ponto ótimo.

Com o primeiro passo dado (supor passo \(1 = 40\)), você precisa fazer o mesmo procedimento tomando agora o passo 1 como se fosse o inicial novamente, ou seja, atualizando sua função para cada \(\theta\) \textbf{simultâneamente} (caso dois \(\theta\)'s de entrada para a função, atualiza-se para ambos) até encontrar o novo valor ótimo do próximo passo no ponto \(2=15\). Conforme vai se aproximando de \(Z\), seus passos vão ficando cada vezes menores ( de 15 para 11; de 11 para 10,50; de 10,50 para 10,10; de 10,10 para 10,05; etc) até chegar na melhor aproximação de \(Z=10\) que é o ponto ótimo da função.

Assim o algoritmo encontra os melhores parâmetros para buscar o ponto otimizado, com a estimatiza dos melhores parâmetros para a aproximação com os menores erros (sim! Podemos encontrar os parâmetros dos exemplos de regressão com este algoritmo também!)

Desta forma, atribuímos (``\(:=\)'') para a própria observação de entrada da função receber ela mesma subtraída \(\alpha\) que multiplica a derivada da função em relação a observação de entrada. Para que atualize a cada passo (iteração). \textbf{\(\alpha\)( learning rate - taxa de aprendizagem)} é um valor fixo que controla o tamanho do passo em cada iteração: quando \(\alpha\) for pequeno, o método fica lento, quando grande ele pode falhar na convergência e até mesmo divergir. Seu valor depende muito da pesquisa e de suas fundamentações teóricas, o que recomendo o leitor quando utilizar este método verificar um valor adequado, pode ser que dependendo do valor da taxa demore muito para finalizar o algoritmo pela quantidade de iterações (tamanhos de passos muito pequenos) ou divergir (tamanho de passos muito grandes). \citet{rendle2008online} divulgaram que a fatoração de matrizes para a predição de \emph{ratings} nos dados do desafio \emph{Netflix} precisou de 200 iterações, usando uma taxa de aprendizagem de 0,01.

Para facilitar a compreensão do efeito da taxa de variação, observe a Figura \ref{fig:gd1}. No primeiro gráfico você inicia seu algoritmo com o valor \(\theta\) e com a derivada podemos observar que inclinação da reta tangente ao ponto é positiva (\(\frac{d}{d\theta}j(\theta)\geq 0\)), portanto em \(\theta=\theta-\alpha.\mbox{um valor positivo}\), faz que com que esse novo \(\theta\) (segunda iteração) seja menor que o da primeira iteração, visto que terá que subtrair e deslocar-se para esquerda para tender ao ponto mínimo. Da mesma forma, ao segundo gráfico, podemos verificar que a inclinação é negativa (\(\frac{d}{d\theta}j(\theta)\leq 0\)), portanto \(\theta=\theta-\alpha.\mbox{um valor negativo}\), fará com que o novo \(\theta\) seja maior do que da primeira iteração, pois irá somar e deslocar-se para direita tendendo ao ponto mínimo.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/gd1} 

}

\caption{Efeito da taxa de variação no Gradiente Descendente.}\label{fig:gd1}
\end{figure}



Como pode-se perceber, a taxa de aprendizagem e a taxa de variação são fundamentais e complementares para o algoritmo de GD, pois elas dizem o tamanho do passo e em que posição estamos em relação ao ponto ótimo da função.

\hypertarget{exemplos}{%
\subsection{Exemplos}\label{exemplos}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Uma variável:}Vamos supor a seguinte função custo:
\end{enumerate}

\[j(\theta)=\theta^2\]

Queremos minimizá-la \(min \ j(\theta)\). Portanto precisamos inicialmente colocar um número aleatório para nosso parâmetro - não ótimo - para que o algoritmo atualize a cada iteração. Vamos supor a taxa de aprendizagem (\emph{learning rate}) \(\alpha=0,1\) e \(\theta=4\) para facilitar. Ou seja, \(j(\theta)=4^2=16\). Vamos atualizar os parâmetros:

\[\theta := \theta-\alpha.\frac{d}{d\theta}j(\theta) \]
\[\mbox{derivando a função} \ j(\theta)=\theta^2 \ \mbox{e substituindo:}\]
\[\theta:= \theta -\alpha.2\theta \]
\[\mbox{substituindo os valores de}\ \alpha\ \mbox{e}\ \theta: \]
\[\theta:=4-0,1 \ .\ 2\ .\ 4 \]
\[\rightarrow \theta:=3,2\]

Na iteração obtemos \(\theta=3,2\). Se subsituirmos em \(j(\theta)\) novamente, iremos obter \(j(\theta)=(3,2)^2=10,24\). Agora atualizando novamente para a próxima iteração:
\[\theta:= \theta -\alpha.2\theta \]
\[\theta:=3,2-0,1\ .\ 2\ .\ 3,2\]
\[\theta:= 2,56\]

Portanto, \(j(\theta)=(2,56)^2=6,55\). Sucessivamente, vamos fazendo as iterações até convergir:

\begin{longtable}[]{@{}cc@{}}
\toprule
\textbf{\(\theta\)} & \textbf{\(j(\theta)\)}\tabularnewline
\midrule
\endhead
4 & 16\tabularnewline
3,2 & 10,24\tabularnewline
2,56 & 6,55\tabularnewline
2,04 & 4,19\tabularnewline
1,632 & 2,663\tabularnewline
. & .\tabularnewline
. & .\tabularnewline
. & .\tabularnewline
0 & 0\tabularnewline
\bottomrule
\end{longtable}

Da mesma forma, se iniciarmos o algoritmo com -4:

\begin{longtable}[]{@{}cc@{}}
\toprule
\textbf{\(\theta\)} & \textbf{\(j(\theta)\)}\tabularnewline
\midrule
\endhead
-4 & 16\tabularnewline
-3,2 & 10,24\tabularnewline
-2,56 & 6,55\tabularnewline
-2,04 & 4,19\tabularnewline
-1,632 & 2,663\tabularnewline
. & .\tabularnewline
. & .\tabularnewline
. & .\tabularnewline
0 & 0\tabularnewline
\bottomrule
\end{longtable}

Note que conforme \(\theta\) diminui, o custo também. Conforme mais iterações são aplicadas, mais ``ótimo'' será. Graficamente para -4 em vermelho e +4 em azul:

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/gdx2} 

}

\caption{Função \(X^2\) com valores de entrada -4 e +4.}\label{fig:gdx2}
\end{figure}



\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Duas variáveis:} Vamos supor a seguinte função de custo com \(\alpha=0,1\), \(\theta_1=1\) e \(\theta_2=2\):
  \[j(\theta_1,\theta_2)=\theta_1^2+\theta_2^2\]
  \[j(\theta_1,\theta_2)=1^2+2^2=5\]
  Queremos \(min \ j(\theta_1,\theta_2)\)Como explicado, ao caso de haver mais de um parâmetro precisamos separar atualizar cada um simultâneamente e aplicar derivada parcial em sua função:
\end{enumerate}

\[\theta_1:=\theta_1-\alpha \frac{d}{d\theta_1}j(\theta_1,\theta_2) \ \ \mbox{e}\ \ \theta_2:=\theta_2-\alpha \frac{d}{d\theta_2}j(\theta_1,\theta_2)\]
\[\mbox{calculando as derivadas parciais de}\ j(\theta_1,\theta_2)=\theta_1^2+\theta_2^2\ \mbox{obtemos:}\]
\[\frac{d}{d\theta_1}j(\theta_1,\theta_2)=2\theta_1 \ \
\mbox{e}\ \ \frac{d}{d\theta_2}j(\theta_1,\theta_2)=2\theta_2\]

\[\mbox{substituindo:}\]
\[\theta_1:=\theta_1-\alpha.\ 2\theta_1 \ \ \mbox{e}\ \ \theta_2:=\theta_2-\alpha .\ 2\theta_2 \]
\[\mbox{inserindo os valores:}\]
\[\theta_1:=1-0,1.\ 2.\ 1 \ \ \mbox{e}\ \ \theta_2:=2-0,1.\ 2.\ 2\]
\[\theta_1:=0,8 \ \mbox{e} \ \theta_2=1,6\]

Portanto após a iteração, temos que \(j(\theta_1,\theta_2)=0,8^2+1,6^2=3,2\). Da mesma forma, para a próxima iteração temos:

\[\theta_1:=0,8-0,1.\ 2.\ 0,8 \ \ \mbox{e}\ \ \theta_2:=1,6-0,1.\ 2.\ 1,6\]
\[\theta_1:=0,64 \ \mbox{e} \ \theta_2=1,28\]

Portanto teremos \(j(\theta_1,\theta_2)=0,64^2+1,28^2=2,048\). Assim sucessivamente:

\begin{longtable}[]{@{}ccc@{}}
\toprule
\textbf{\(\theta_1\)} & \textbf{\(\theta_2\)} & \textbf{\(j(\theta_1,\theta_2)\)}\tabularnewline
\midrule
\endhead
1 & 2 & 5\tabularnewline
0,8 & 1,6 & 3,2\tabularnewline
0,64 & 1,28 & 2,48\tabularnewline
. & . & .\tabularnewline
. & . & .\tabularnewline
. & . & .\tabularnewline
0 & & 0\tabularnewline
\bottomrule
\end{longtable}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Erro quadrado médio (Regressão Linear Simples:)} Observe a função de regressão linear:
  \[f_\theta(X)=\theta_0+\theta_1*X\]
\end{enumerate}

A função de custo:
\[j(\theta)=\frac{1}{m}\displaystyle \sum^m_{i=1}(f_\theta(x^i)-y^i)^2\]

Primeiramente vamos encontrar a derivada parcial de \(j(\theta_0,\theta_1)\):
\[\frac{d}{d\theta_0}j(\theta_0,\theta_1=\frac{d}{d\theta_0}(\frac{1}{m}\displaystyle \sum^m_{i=1}(f_{\theta}(x^i)-y^i)^2) \rightarrow \frac{2}{m}\displaystyle \sum^m_{i=1}(f_\theta(x^i)-y^i) \]
\[\frac{d}{d\theta_1}j(\theta_0,\theta_1=\frac{d}{d\theta_1}(\frac{1}{m}\displaystyle \sum^m_{i=1}(f_{\theta}(x^i)-y^i)^2) \rightarrow \frac{2}{m}\displaystyle \sum^m_{i=1}(f_\theta(x^i)-y^i)x^i\]
Pode-se também multiplicar a função de custo por \(\frac{1}{2}\) para que quando faz-se a derivada, facilite no cálculo e multiplicar a função de custo por um escalar não irá afetar a localização do mínimo.
\[j(\theta)=\frac{1}{2m}\displaystyle \sum^m_{i=1}(f_\theta(x^i)-y^i)^2\]
Com isso em foco de minimizarmos, basta aplicarmos o banco de dados de \(X\) e \(Y\) em seu modelo e de seus dois \(\theta's\) de entrada. Repetindo as iterações para atualizar seus valores até a convergência e identificando os parâmetros que se aproximam.

\hypertarget{regularizacao}{%
\section{Regularização}\label{regularizacao}}

Como sabe-se, um Modelo de Regressão Linear Simples (MRLS) pode ser expresso como:

\begin{equation}
    y_i=\beta_0+\displaystyle \sum^p_{j=1}x_{ij}\beta_j+\mu_i, \mbox{com} \ i=1,2,...,n
\end{equation}

em que \(y_i\) é variável resposta, e cada vetor \(x_i=(x_{i1},x_{i2},...,x_{ip})^T\) representa as \(p\) características observadas para cada observação \(i\) da amostra; \(\beta_0\) o intercepto e o vetor dos coeficientes \(\beta=(\beta_1,\beta_2,...,\beta_p)^T\) trata-se dos parâmetros a serem estimados e estabelecem a relação entre a variável resposta e as preditoras.

Sabemos também que métodos de seleção de variáveis como \emph{backward, forward} e \emph{stepwise} buscam amenizar o erro da predição e melhorar a interpretação do modelo, porém visto que o processo é discreto na escolha das variáveis regressoras (retendo ou descartando), o modelo resultante pode apresentar grande variância e portanto, não diminuir esse erro de predição quando compararmos com o modelo completo. A \textbf{regularização} é uma outra abordagem com estes mesmos propósitos, ela desestímula o ajuste excessivo dos dados, afim de diminuir sua variância. A regressão \textbf{\emph{Lasso}} e a regressão \textbf{\emph{Ridge}} são métodos utilizados para regularizar o modelo por meio de penalidades, alterando alguns fatores de modo a priorizar (ou não) partes da equação e por fim, melhorar a qualidade de predição.

\hypertarget{penalizacoes}{%
\subsection{\texorpdfstring{Penalizações - Regressão \emph{Lasso} e a Regressão \emph{Ridge}}{Penalizações - Regressão Lasso e a Regressão Ridge}}\label{penalizacoes}}

O método dos mínimos quadrados, como sabemos, consiste em minimizar a soma dos quadrados dos resíduos do modelo e fatores como multicolinearidade por exemplo, que pode ser ou não controlados pelo pesquisador, pode influenciar na pesquisa e muitas vezes apontar como não significativas variáveis importantes. O MMQ quando penalizado e, partindo das mesmas suposições do MRLM, pode apresentar uma melhoria. Ela será expressa como:

\begin{equation}
    min_\beta \bigg\{\displaystyle \sum^n_{i=1}(y_i-\displaystyle \sum^p_{j=1}x_{ij}\beta_j)^2+s\displaystyle \sum^p_{j=1}|\beta_j|^q\bigg\}
    \label{eq:penalizacao}
\end{equation}

onde \(s\) é o fator de penalização, um parâmetro de ajuste (\emph{tuning parameter}) no qual deve ser maior do que a soma dos valores absolutos dos coeficientes do modelo e o termo \(s\displaystyle \sum^p_{j=1}|\beta_j|^q\) representa a penalização. Ao caso de \(q=0\), é contabilizado a quantidade de coeficientes não-nulos presentes no modelo, uma penalizção do tipo \textbf{\(L_0\)}.

Para \(q=1\) é a penalização do tipo \textbf{\(L_1\)}, conhecida como \textbf{Lasso}. Robert Tibshirani propôs em seu artigo \emph{Regression Shrinkage and Selection via the LASSO} \citep{tibshirani1996regression}, é uma técnica que a cada dia torna maior seu uso no Aprendizado de Máquina com sua interessante possibilidade para seleção de variáveis. O \emph{Lasso} pode ser usado em análises com um grande banco de dados, especialmente se a quantidade de covariáveis (qualquer variável contínua e geralmente não controlada durante a coleta de dados) for maior do que o número de observações e também garante que uma boa parte dos coeficientes destas covariáveis seja nula, sugerindo que as demais são as características importantes a serem analisadas \citep{silva2018tecnica}. Um modelo é \textbf{esparso (sparse model)} quando apenas alguns dos coeficientes possuem estimações diferentes de zero \citep{hastie2015statistical}, ele melhora na interpretação com a vantagem de facilitar as estimações computacionais e pode fornecer maior precisão de predição.

A técnica \emph{Lasso} basicamente minimiza a soma dos quadrados dos resíduos do modelo utilizando o parâmetro de ajuste \emph{tuning parameter} \(s\) que deve ser maior de que a soma dos valores absolutos dos coeficientes do modelo. Este parâmetro desempenha um papel fundamental, pois serve como um ``grau'' de quanto irá encolher durante a estimação, quanto maior seu valor, menor a distância entre os estimadores. Existe diversas técnicas para estimar seu valor.

Uma penalização \textbf{\(L_1\)} que faz com que essa regularização \emph{Lasso} force os coeficientes a zerar (quando há múltiplas atributos altamente correlacionados, selecionam apenas um desses atributos e zeram o coefiente das menos importantes, de forma a minimizar a penalização \(L_1\)). Podemos entender que esse modelo realiza uma seleção de atributos (por este motivo o termo inglês \emph{Shrinkage}, encolhimento), gerando vários coeficientes com peso zero e ignorados, facilitando na interpretação do modelo e diminuindo a variância. O \emph{Lasso} pode conduzir a uma região de restrição convexa e connsequentemente a um problema de otimização convexo e usa seu mecanismo de penalizar os coeficientes de acordo com o seu valor absoluto.

Quando \(q=2\), temos a penalização do tipo \textbf{\(L_2\)} que corresponde à regressão \textbf{\emph{Ridge}} (regressão em cristas). O método \emph{Ridge} foi introduzido originalmente por \citet{hoerl1959optimum} para examinar superfícies de resposta quadráticas \(k\)-dimensionais, ou seja é um método gráfico e de inferência sobre os níveis ótimos de um fator de um superfície de resposta a distâncias fixas do centro da região experimental expecíficada \citep{do2009metodo}.

Muitos também a utilizam como método alternativo ao MMQ no caso de haver multicolinearidade em uma amostra. Como a penalização \(L_2\) é maior para coeficientes maiores por haver \(q=2\), ela faz com que os atributos que contribuem menos para o poder preditivo do modelo sejam levados para uma ``irrelevância'' em relação às de maior contribuição - como sabe-se o impacto de um expoente quadrático é maior em valores altos do que o impacto do mesmo expoente em valores bem pequenos - e têm como objetivo suavizar os atributos que sejam relacionados uns aos outros.

Pode-se dizer que a diferença entre \(L_1\) e \(L_2\), num geral, é que a regressão Lasso não é diferenciável e a \(L_2\) é, para \(q<1\) as regiões serão não convexas e para \(q<1\) os problemas serão convexos \citep{silva2018tecnica}. A penalização Ridge encolhe os parâmetros, mas não a seleção de variáveis. Ao caso da penalização de \emph{Lasso} que possui uma penalização pelos valores absolutos ela encolhe e faz a seleção dos atributos.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/lassoridge2d} 

}

\caption{Regiões de restrição para valores diferentes de \(q\) em \(\mathbb{R}^2\). de \citet{silva2018tecnica} com base em \citet{hastie2015statistical}.}\label{fig:lassoridge2d}
\end{figure}



\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/lassoridge3d} 

}

\caption{Regiões de restrição para valores de \(q=\{2;1;0,8\}\) em \(\mathbb{R}^3\). de \citet{silva2018tecnica} com base em \citet{hastie2015statistical}.}\label{fig:lassoridge3d}
\end{figure}



\hypertarget{elasticnet}{%
\subsection{\texorpdfstring{Elastic Net - \(L_1+L_2\)}{Elastic Net - L\_1+L\_2}}\label{elasticnet}}

A técnica \textbf{\emph{Elastic Net}} \citep{zou2005regularization} também tem como propósito a penalização para que se melhore a acurácia dos estimadores de mínimos quadrados. Ela se trata exatamente de combinar os termos de regularização de \(L_1\) e de \(L_2\).

\begin{equation}
    \lambda\bigg[ \frac{1}{2}(1-\alpha)||\beta||_2^2+\alpha||\beta||_1\bigg]
  \label{eq:elsticnet}
\end{equation}

\citet{hastie2015statistical} citam que o principal estímulo para este estudo é que quando as variáveis são muito correlacionadas, o \emph{Lasso} não tem um bom desempenho. A Adiçaõ do termo \(\frac{1}{2}(1-\alpha)||\beta||^2_2\) auxilia a controlar estas fortes correlações entre os grupos de variáveis e manter a característica da regressão Lasso de tornar modelos esparsos \citep{silva2018tecnica}. Como consequência do uso dos dois métodos, é preciso determinar dois hiperparâmetros para obter soluções ótimas.

Ao observar um gráfico de \emph{Elastic Net}, pode-se observar de que este método compartilha de atributos gráficos de \(L_1\) e \(L_2\): bordas e cantos afiados indicando a seleção e um contorno curvado para o compartilhamento de coeficientes.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/elasticnet} 

}

\caption{\emph{Elastic Net} em \(\mathbb{R}^3\). de \citet{silva2018tecnica} com base em \citet{hastie2015statistical}.}\label{fig:elasticnet}
\end{figure}



\hypertarget{ptII}{%
\chapter{Algoritmos de Aprendizagem II}\label{ptII}}

\hypertarget{svm}{%
\section{\texorpdfstring{Máquina de Vetores Suporte - \emph{Support Vectors Machine}}{Máquina de Vetores Suporte - Support Vectors Machine}}\label{svm}}

A Máquina de Vetores de Suporte (SVMs, do inglês \emph{Support Vectors Machine}), são embasadas pela teoria de aprendizado estatística, desenvolvida por \citet{vapnik2013nature} com o propósito de resolver problemas de classificação de padrões, foi originalmente desenvolvida para classificação binária, construindo um hiperplano como superfície de decisão que separa classes linearmente separáveis (ao caso de não-linearmente separáveis utiliza-se função de mapeamento). Muitos a comparam com redes neurais pelo fato de ser eficiente em trabalhar com dados de alta dimensionalidade \citep{sung2003identifying, ding2001multi}. É utilizada atualmente tanto para regressão quanto para qualissificação e é uma análise supervisionada.

Vamos supor um gráfico com características \(X_1\) e \(X_2\) e já classificados na amostra os indivíduos que estão e não estão doentes, quanto maior o valor de ambos maior a probabilidade do indivíduo ser classificado como doente.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/svm1} 

}

\caption{Gráfico de \(X_1\) e \(X_2\) classificado em doentes e não doentes.}\label{fig:svm1}
\end{figure}



Um exemplo como esse é simples observar que podemos separar os dados traçando uma linha reta. Classificando os doentes para a direita e acima do gráfico e não doentes a esquerda e abaixo. Esta linha é o que chamamos de \textbf{hiperplano de separação}.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/svm2} 

}

\caption{Gráfico de \(X_1\) e \(X_2\) classificado em doentes e não doentes por meio de um hiperplano.}\label{fig:svm2}
\end{figure}



Lembrando que hiperplano é uma generalização de um plano: uma dimensão é um ponto, duas dimensões é uma linha e três é um plano. Quando tratamos de mais dimensões é o que denominamos hiperplano. O SVM pode trabalhar com qualquer dimensão.

Podemos encontrar em uma amostra vários hiperplanos de separação e válidos para a classficação de um \emph{dataset}. Mas não necessariamente este é o melhor. Até mesmo pode ser que classifique alguns errados.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/svm3} 

}

\caption{Gráfico de \(X_1\) e \(X_2\) com a classificação de doentes e não doentes por mais de um hiperplano de separação.}\label{fig:svm3}
\end{figure}



O objetivo do algoritmo de SVM é identificar um hiperplano ``ideal'' que busca classificar o conjunto de dados da melhor maneira possível (menor erro). Ao verificar as distâncias perpendiculares entre as observações e o hiperplano de separação, obtemos uma \textbf{Margem}. Os pontos menos distantes do hiperplano são os que a definem. Estes pontos são os \textbf{Vetores de Suporte (VS)}, que têm este nome pois eles dão suporte ao hiperplano. Caso forem movidos, a margem acompanhará o movimento.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/svm4} 

}

\caption{Gráfico de \(X_1\) e \(X_2\) com a classificação de doentes e não doentes pelo hiperplano e sua margem.}\label{fig:svm4}
\end{figure}



\hypertarget{classificauxe7uxe3o-de-padruxf5es-linearmente-separuxe1veis}{%
\subsection{Classificação de Padrões Linearmente Separáveis}\label{classificauxe7uxe3o-de-padruxf5es-linearmente-separuxe1veis}}

Uma classificação linear consiste em determinar uma função \(f: X \subseteq \mathbb{R}^N \rightarrow \mathbb{R}^N\) que atribuirá um valor de \(+1\) se \(f(x)\geq 0\) e \(-1\) se \(f(x)<0\). Sendo assim pelo produto interno (ver Produto Interno em \ref{dicio}):

\begin{equation}
f(x)= \langle\vec{w}.\vec{x}\rangle+b
\label{eq:classlin}
\end{equation}

\begin{equation}
= \displaystyle \sum^n_{i=1} \vec{w_i} \vec{x}_i+b
\label{eq:classlin2}
\end{equation}

em que \(\vec{w}\) e \(b\) são popularmente conhecido como \textbf{vetor peso} e \textbf{\emph{bias}} e parâmetros responsáveis em controlar a função e a regra da decisão \citep{lima2002maquinas}. Os valores destes parâmetros são obtidos pelo processo de aprendizagem a partir dos dados de entrada \citep{gonccalves2015maquina}. Sendo o vetor peso \(\vec{w}\) que define uma direção perpendicular ao hiperplano e com a variação de \(b\) o hiperplano é movido paralelamente a ele mesmo.

Portanto um SVM linear procura encontrar um hiperplano ótimo que separe da melhor maneira possível os dados de cada classe (margem máxima).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/svm5} 

}

\caption{Interpretação geométrica de \(\vec{w}\) e \(b\) sobre um hiperplano \citep{lima2002maquinas, gonccalves2015maquina}.}\label{fig:svm5}
\end{figure}



\hypertarget{margmax}{%
\subsection{Hiperplano de Separação Ótima / Margem Máxima}\label{margmax}}

Um hiperplano é considerado de margem máxima se separa um conjunto de vetores sem erros e a distância entre os vetores de classes diferentes mais próximos do hiperplano é a máxima possível.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/margmax} 

}

\caption{(a) Um hiperplano de separação com uma pequena margem. (b) Um hiperplano de Margem máxima \citep{da2009classificaccao}.}\label{fig:margmax}
\end{figure}



Assumindo que o conjunto de dados é linearmente separável, o hiperplano ótimo é que possuir a maior margem:

\begin{equation}
\langle\vec{w}.\vec{x}\rangle+b=0
\label{eq:maiormarg}
\end{equation}

em que \(\vec{w}\) e \(b\), o vetor peso e \emph{bias} respectivamente.

Assumindo a restrição:

\[\langle\vec{w}.\vec{x}_i\rangle+b\geq + 1 \ , \ \mbox{para} \ y_i=+1\]
\begin{equation}
\langle\vec{w}.\vec{x}_i\rangle+b\leq - 1 \ , \ \mbox{para} \ y_i=-1
\label{eq:restricaoclassif}
\end{equation}

Os classificadores lineares que separam o conjunto de dados em treinamento possuem margem positiva. Esta restrição nos mostra que não há dados entre 0 e \(\pm1\), tendo como a margem sempre maior que a distância entre os hiperplanos \(\langle\vec{w}.\vec{x}_i\rangle+b=0\) e \(|\langle\vec{w}.\vec{x}_i\rangle+b= 1|\). Fazendo com que as SVMs sejam chamadas de \textbf{Margens Rígidas}, do inglês \emph{Hard Margin}. Com isso, ao combinar ambas equações restrições:

\begin{equation}
y_i(\langle\vec{w}.\vec{x}_i\rangle+b)\geq  1 \ ,  \ i=\{1,2,...,n\}
\label{eq:restricaoclassifcom}
\end{equation}

Ou:
\begin{equation}
y_i(w^T.\vec{x}_i+b)\geq  1 \ ,  \ i=\{1,2,...,n\}
\label{eq:restricaoclassifcomb}
\end{equation}

Aplicando a distância Euclidiana (\(d_+\) e \(d_-\)) entre os vetores de suporte positivos/negativos e o hiperplano, definido a margem \(\rho\) de um hiperplano de separação como sendo a maior geométrica entre todos os hiperplano, é possível representar \(\rho(d_+ + d_-)\) \citep{gonccalves2015maquina}.

\begin{equation}
d_i(\vec{w},b;\vec{x}_i)=\frac{|\langle\vec{w}.\vec{x}_i\rangle+b|}{||\vec{w}||}=\frac{y_i(|\langle\vec{w}.\vec{x}_i\rangle+b)}{||\vec{w}||}
\label{eq:distanciahip}
\end{equation}

em que \(d_(\vec{w},b;\vec{x}_i)\) é a distância de um dado \(\vec{x}_i\) ao hiperplano \((\vec{w},b)\) \citep{lima2002maquinas}. Ao levarmos em consideração a restrição de \eqref{eq:restricaoclassifcomb}, podemos expressar:

\begin{equation}
d(\vec{w},b;\vec{x}_i)\geq \frac{1}{||\vec{w}||}
\label{eq:distcrestri}
\end{equation}

Identificando \(\frac{1}{||\vec{w}||}\) como o limite inferior da distância entre os vetores de suporte \(\vec{x}_i\) e o hiperplano \((\vec{w},b)\). Logo, as distância serão:

\begin{equation}
d_+=d_-=\frac{1}{||\vec{w}||}
\label{eq:distanciamarg}
\end{equation}

A margem é sempre maior que a última instância, a minimização de \(||\vec{w}||\) nos traz a maximização da margem. Podemos definir a margem \(\rho\) como \citep{gonccalves2015maquina}:

\begin{equation}
\rho=(d_+=d_-)=\frac{2}{||\vec{w}||}
\label{eq:margemsvm}
\end{equation}

Assim teremos a distância entre hiperplanos e os vetores de suporte:

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/svm6} 

}

\caption{Distância entre hiperplanos e vetores de suporte \citep{gonccalves2015maquina}.}\label{fig:svm6}
\end{figure}



Para minimizarmos \(||\vec{w}||\) (maximizarmos esta margem), podemos utilizar a teoria dos multiplicadores de Lagrange (ver Multiplicadores de Lagrange em \ref{dicio}):

\begin{equation}
L(\vec{w},b,\alpha)=\frac{1}{2}||\vec{w}||^2-\displaystyle \sum^n_{i=1}\alpha_i(y_i(\langle\vec{w}.\vec{x}_i\rangle+b)-1)
\label{eq:lagrangemargem}
\end{equation}

em que \(\alpha_i\) são os multiplicadores de Lagrange. Então agora visamos minimizar \(L(\vec{w},b,\alpha)\), em relação a \(\vec{w}\) e \(b\) e a maximização dos \(\alpha_i\) (encontrar os pontos ótimos pelas derivadas parciais iguals a zero). Portanto:

\[\frac{\partial L}{\partial b}=0\]
\[\frac{\partial L}{\partial \vec{w}}=\bigg(\frac{\partial L}{\partial w_1},\frac{\partial L}{\partial w_2},...,\frac{\partial L}{\partial w_n}\bigg)=0\]
Obtemos por meio delas:

\begin{equation}
\displaystyle \sum^n_{i=1}\alpha_i y_i=0
\label{eq:lagrangemarge1}
\end{equation}

\begin{equation}
\vec{w}=\displaystyle \sum^n_{i=1}\alpha_i y_i \vec{w}_i
\label{eq:lagrangemarge2}
\end{equation}

Substituindo as equações \eqref{eq:lagrangemarge1} e \eqref{eq:lagrangemarge2} em \eqref{eq:lagrangemargem}, chegamos em:

\begin{equation}
L =\displaystyle \sum^n_{i=1}\alpha_i-\frac{1}{2} \displaystyle \sum^n_{i=1}\sum^n_{j=1}\alpha_i\alpha_j y_i y_j \langle x_i.x_j\rangle
\label{eq:lagrangemarge3}
\end{equation}

com \(\alpha_i\geq0,i\{1,2,...,n\}\). Serão representados os valores ótimos de \((\vec{w},b)\) por \((\vec{w}^*,b^*)\). E \(\alpha^*_i\) assume valores positivos para os exemplos de treinamento que estão a uma distância do hiperplano ótimo igual a largura da margem, os vetores de suporte \citep{gonccalves2015maquina}. Podemos perceber que o hiperplano de separação ótimo é obtido pelos vetores de suporte e não de todo o conjunto \citep{lorena2003introduccaoas}.

Com um vetor suporte dado \(\vec{x}_j\), obtemos valor de \(b^*\) pela condição de KKT (ver Karush-Kuhn-Tucker em \ref{dicio}):

\begin{equation}
b^* =y_j-\langle\vec{w}^*.\vec{x}_j \rangle.
\label{eq:kktsvm}
\end{equation}

Com todos os valores dos parâmetros calculados podemos, por fim, ter um novo padrão \(z\) calculando:

\begin{equation}
sgn(\langle \vec{w}^* . \vec{z}\rangle+b^*)
\label{eq:sgn}
\end{equation}

sendo \(sgn\) a função sinal que fornece o valor 1 se o número for positivo, valor 0 se o número for zero e -1 se for negativo.

Pode-se também utilizar as \textbf{Margens Flexíveis}, que busca não garantir todas as observações no lado certo, tolerando algumas violações. Basicamente atribui-se um erro para cada observação que viola o hiperplano proporcional o quanto passou a margem e o violou. Acrescentando na função este erro para compensar. Nos algoritmos dos \emph{softwares} estatísticos, é comum o uso de uma constante \textbf{C} que controla a severidade do modelo, dando limite do tanto do erro que pode haver no algoritmo. Seu valor depende muito da pesquisa e de sua fundamentação teórica, pois pode ser que aumente a quantidade de vetores de suporte e até mesmo podendo causando problemas de \textbf{overfitting} (\ref{fitt}).

\hypertarget{classificauxe7uxe3o-de-padruxf5es-nuxe3o-linearmente-separuxe1veis}{%
\subsection{Classificação de Padrões Não-Linearmente Separáveis}\label{classificauxe7uxe3o-de-padruxf5es-nuxe3o-linearmente-separuxe1veis}}

Nas situações reais a maioria dos padrões são mais complexos e não-lineares. O conjunto de dados é classificado como não-linearmente separável ao caso de não ser possível separar os dados com um hiperplano:

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/svm7} 

}

\caption{Padrões linearmente e não-linearmente separável respectivamente \citep{gonccalves2015maquina}.}\label{fig:svm7}
\end{figure}



Segundo \citet{smola2000introduction}, o teorema de Cover afima que um problema não-linear possui maior probabilidade de ser linearmente separável em um espaço de mais alta dimensionalidade. Com isso, a SVM não-linear faz uma mudança de dimensionalidade por meio das funções \emph{Kernel} para tratarmos de uma problema de classificação linear e permitindo elaborar o hiperplano ótimo (note que ACP possui uma ideia similar dado suas propriedades).

Um conjunto de entrada \(X\) com pares \(\{(x_1,y_1);(x_2,y_2),...,(x_n,y_n)\}\) de uma amostra de treinamento (não-linearmente separável), são mapeados por meio de uma função \(\phi\) a fim de obter um novo conjunto de dados \(X'\) linearmente separável em um espaço de maior dimensionalidade, representado por \(\{(\phi(x_1),y_1),...,(\phi(x_n),y_n)\}\).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/svm8} 

}

\caption{Mapeamento de um conjunto de entrada \(X\) para o espaço caracerística. Um novo conjunto \(X'\).}\label{fig:svm8}
\end{figure}



Com os dados de treinamento mapeados para o espaço de características, utiliza-se os valores mapeados \(\phi(x)\) ao invés de \(x\), sendo assim o problema consiste em:

\begin{equation} 
L =\displaystyle \sum^n_{i=1}\alpha_i-\frac{1}{2} \displaystyle \sum^n_{i=1}\sum^n_{j=1}\alpha_i\alpha_j y_i y_j \langle \phi(x_i).\phi(x_j)\rangle
\label{eq:svnphi}
\end{equation}

em que \(\alpha_i \geq 0\). Para classificação não-linear as mesmas considerações de KKT descrito no linear. O hiperplano fica expresso como:
\begin{equation}
(\vec{w}\phi \ . \ (\vec{x}))+b=0
\label{eq:hipotimophi}
\end{equation}

Ao problema de classificação não-linear de um novo padrão \textbf{z}:
\begin{equation}
sgn(\langle \vec{w}^* \ . \ \phi(z)\rangle+b^*)
\label{eq:naolinzphi}
\end{equation}

Uma função \emph{Kernel}, pertencente a um domínio que permita calcular o produto interno para calculá-lo, recebe dois dados de entrada \(x_i\) e \(x_j\) destes dados no espaço de características.
\begin{equation}
\kappa=(x_i,x_j)=\langle \phi(x_i) \ . \ \phi(x_j)\rangle
\label{eq:kernel}
\end{equation}

A função precisa satisfazer as condições do \textbf{Teorema de Mercer}, portanto a matriz \(K\) é positivamente definida (autovalores maiores que zero). \(K\) é obtida por:

\begin{equation}
K=K_{ij}=\kappa(x_i,x_j)
\label{eq:mercer}
\end{equation}

As funções \emph{Kernel} mais utilizadas são:

\begin{longtable}[]{@{}ll@{}}
\caption{\label{tab:kernel} \emph{Kernels} mais populares \citep{gonccalves2015maquina}.}\tabularnewline
\toprule
\textbf{Tipo de Kernel} & \textbf{Função \(\kappa(x_i,x_j)\)}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Tipo de Kernel} & \textbf{Função \(\kappa(x_i,x_j)\)}\tabularnewline
\midrule
\endhead
Polinomial & \((\langle x_i.x_j\rangle +1)^p\)\tabularnewline
Gaussiano & \(e^{(-\frac{\|\|x_i-x_j\|\|^2}{2\sigma^2})}\)\tabularnewline
Sigmoidal & \(tanh(\beta_0 \langle x_i.x_j\rangle )+\beta_1\)\tabularnewline
\bottomrule
\end{longtable}

Lembrando que o pesquisador precisa escolher alguns parâmetros, bem como a definição de qual algoritmo utilizar no SVM \citep{lorena2003introduccaoas}.

\hypertarget{exemplosvm}{%
\subsection{Exemplos}\label{exemplosvm}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Vamos supor o seguinte conjunto de dados:
  \[\{ (4,1), (4,-1), (5,1), (5,-1), (0,-1), (0,2), (0,1), (1,2) \}\]
\end{enumerate}

Ao observamos no gráfico, podemos observar que os vetores de suporte são:
\[\{s_1=(1,2),s_2=(4,1),s_3=(4,-1)\}\]

Agora, vamos inserir o valor 1 de entrada do \emph{Bias}:

\[\{\hat{s_1}=(1,2,1),\hat{s_2}=(4,1,1),\hat{s_3}=(4,-1,1)\}\]
Precisamos agora encontrar o valor de \(\alpha_i\):

\[\alpha_1 \phi(s_1).\phi(s_1)+\alpha_2 \phi(s_2).\phi(s_1)+\alpha_3 \phi (s_3).\phi (s_1)=-1\]
\[\alpha_1 \phi(s_1).\phi(s_2)+\alpha_2 \phi(s_2).\phi(s_2)+\alpha_3 \phi (s_3).\phi (s_2)=+1\]
\[\alpha_1 \phi(s_1).\phi(s_3)+\alpha_2 \phi(s_2).\phi(s_3)+\alpha_3 \phi (s_3).\phi (s_3)=+1\]

E portanto:
\[\alpha_1 \hat{s_1}.\hat{s_1}+\alpha_2 \hat{s_2}.\hat{s_1}+\alpha_3 \hat{s_3}.\hat{s_1}=-1\]
\[\alpha_1 \hat{s_1}.\hat{s_2}+\alpha_2 \hat{s_2}.\hat{s_2}+\alpha_3 \hat{s_3}.\hat{s_2}=+1\]
\[\alpha_1 \hat{s_1}.\hat{s_3}+\alpha_2 \hat{s_2}.\hat{s_3}+\alpha_3 \hat{s_3}.\hat{s_3}=+1\]

\[\left\{
\alpha_1
\begin{pmatrix}
1\\2\\1
\end{pmatrix}
\begin{pmatrix}
1\\2\\1
\end{pmatrix} +
\alpha_2
\begin{pmatrix}
4\\1\\1
\end{pmatrix}
\begin{pmatrix}
1\\2\\1
\end{pmatrix}+
\alpha_3
\begin{pmatrix}
4\\-1\\1
\end{pmatrix}
\begin{pmatrix}
1\\2\\1
\end{pmatrix}
\right\}=-1\]

\[\left\{
\alpha_1
\begin{pmatrix}
1\\2\\1
\end{pmatrix}
\begin{pmatrix}
4\\1\\1
\end{pmatrix} +
\alpha_2
\begin{pmatrix}
4\\1\\1
\end{pmatrix}
\begin{pmatrix}
4\\1\\1
\end{pmatrix}+
\alpha_3
\begin{pmatrix}
4\\-1\\1
\end{pmatrix}
\begin{pmatrix}
4\\1\\1
\end{pmatrix}
\right\}=+1\]

\[\left\{
\alpha_1
\begin{pmatrix}
1\\2\\1
\end{pmatrix}
\begin{pmatrix}
4\\-1\\1
\end{pmatrix} +
\alpha_2
\begin{pmatrix}
4\\1\\1
\end{pmatrix}
\begin{pmatrix}
4\\-1\\1
\end{pmatrix}+
\alpha_3
\begin{pmatrix}
4\\-1\\1
\end{pmatrix}
\begin{pmatrix}
4\\-1\\1
\end{pmatrix}
\right\}=+1\]

Resolvendo as matrizes, temos:
\[\alpha_1(1+4+1)+\alpha_2(4+2+1)+\alpha_3(4-2+1)=-1\]
\[\alpha_1(4+2+1)+\alpha_2(16+1+1)+\alpha_3(16-1+1)=+1\]
\[\alpha_1(4-2+1)+\alpha_2(16-1+1)+\alpha_3(16+1+1)=+1\]
E portanto:
\[6\alpha_1+7\alpha_2+3\alpha_3=-1\]
\[7\alpha_1+18\alpha_2+16\alpha_3=+1\]
\[3\alpha_1+16\alpha_2+18\alpha_3=-1\]
Logo \(\alpha_1=2,44\),\(\alpha_2=2,83\) e \(\alpha_3=-2,06\). Encontrando \(\vec{w}=\displaystyle \sum^n_{i=1}\alpha_i \hat{s_i}\):

\[\vec{w}=2,44\begin{pmatrix} 1\\2\\1\end{pmatrix}+
2,83\begin{pmatrix} 4\\1\\1\end{pmatrix}+
-2,06\begin{pmatrix} 4\\-1\\1\end{pmatrix}\]
\[\begin{pmatrix}5,52\\9,77\\3,21\end{pmatrix}\]

Portanto temos que \(w=\begin{pmatrix} 2,44\\2,83\end{pmatrix}\) e \(b=-2,06\). Com a equação \(y=wx+b\) e todos os dados, podemos plotar o hiperplano.

\hypertarget{decisiontree}{%
\section{\texorpdfstring{Árvore de Decisão (\emph{Decision Tree})}{Árvore de Decisão (Decision Tree)}}\label{decisiontree}}

A Árvore de Decisão - \emph{Decision Tree} - é muito utilizada em algoritmos para classificação de dados, tem como objetivo construir classificadores que predizem classes baseadas nos valores de atributos de um \emph{dataset} (análise supervisionada). Ela pode ser aplicada tanto em variáveis categóricas quanto contínuas de entrada e de saída. Na árvore de decisão, dividimos a população ou amostra em dois ou mais conjuntos homogêneos com base nos divisores mais significativos das variáveis de entrada. É um modelo fácil de compreensão, útil para explorar os dados e classificar os dados, sem restrição do tipo de seus dados e pode ser considerada como não paramétrica, porém precisa-se tomar cuidado em ocorrer um sobreajuste e a aplicação em variáveis contínuas pode perder informações.

Há muitos algoritmos de classificação que constroem árvores de decisão. Cada um pode ter melhor desempenho em determinada situação e outro algoritmo pode ser mais eficiente em outros tipos de situações, não há como apontar qual o melhor método. Ela é composta por:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Nó Raiz/Nodos: Representa a população ou uma amostra, podendo ser ainda dividido em dois ou mais conjuntos homogêneos;
\item
  Divisão e Arcos: É o processo de dividir um nó em dois ou mais sub-nós, gerando arcos provenientes destes nodos que recebem os valores possíveis para estes atributos;
\item
  Nó de Decisão: Quando um sub-nó é dividido em sub-nós adicionais;
\item
  Folha/Nó de Término: Os nós não divididos são denominados de Folha ou Nó de Término, representam as diferentes classes de um conjunto de treinamento;
\item
  Poda: O processo de remover sub-nós de um nó de decisão é chamado poda. Existe técnicas para avaliar o bom momento de podar o galho (sub-nó) da árvore.
\end{enumerate}

Segue abaixo uma demonstração da ramificação da árvore:

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/decisiontree} 

}

\caption{Terminologia de Árvore de Decisão.}\label{fig:decisiontree}
\end{figure}



Um nó que é dividido em sub-nós é chamado de nó pai. Os sub-nós são os nós filhos do nó pai.

Em geral são determinadas regras em seu algoritmo. As regras são escritas considerando o trajeto do nó raiz até uma folha da árvore. Por elas tenderem a crescer muito, de acordo com algumas aplicações, elas são muitas vezes substituídas pelas regras. Isto acontece em virtude das regras poderem ser facilmente modularizadas. Uma regra pode ser compreendida sem que haja a necessidade de se referenciar outras regras \citep{ingargiola1996building}.

Sua função é de particionar recursivamente um conjunto de treinamento, até que cada subconjunto obtido deste particionamento contenha casos de uma única classe. Com esta finalidade, basicamente a árvore de decisão verifica e compara a distribuição de classes durante a construção da árvore. Após finalizar a árvore, sua saída são dados organizados de maneira compacta, que são utilizados para classificar novos casos \citep{holsheimer1994data}. De início não é utilizado nenhum modelo estatístico nela, apenas classifica os atributos de acordo com as amostras provenientes - precisa-se de cuidado ao seu uso pois tende a ser sensível com a amostra de treinamento. Mas atualmente utilizam técnicas estatísticas para aperfeiçoar o modelo e avaliar seus resultados \citep{shiba2005classificaccao}. Ela tem um bom desempenho quando há poucos atributos altamente relevantes, ao caso de complexidade no conjunto de dados poderá haver grandes dificuldades.

Geralmente utilizam-na para classificação (variáveis categóricas), mas também é possível para a Análise de Regressão (variáveis contínuas) que ja vimos. Para as árvores de regressão são utilizadas quando a variável dependente é contínua. O valor obtido pelos nós de término nos dados de treinamento é o valor médio das observações. Para classificação o obtido pelos nós de término nos dados de treinamento é a moda, ou seja, a observação mais recorrente no conjunto de dados. Ambos processos continuam o processo de divisão até atingir algum critério fornecido pelo pesquisador. Mas como fazemos esta divisão para podermos classificar?

A decisão de como fazer estas divisões dos nós pode influenciar muito na precisão do algoritmo e portanto, seus resultados. Pode-se utilizar pelo qui-quadrado (ver \ref{testesanova}), por ganho de informação (ver \ref{medinfo}), Índice de Gini, redução de variância, entre diversos outros.

Ao Índice de Gini, aplicado no sistema \emph{Classification and Regression Trees} (CART)\citep{breiman1984classification}, mede a impureza de uma partição de dados, ela basicamente nos mostra que se selecionarmos aleatoriamente dois atributos de uma população ou amostra, ambos devem ter a mesma classe e a soma da probabilidade será se esta amostra/população for pura.

É utilizada portanto para variáveis categóricas como ``Sucesso'' e ``Fracasso'', ou seja, aplica-se em divisões binárias. Quanto maior for este índice, mais homogêneo será. Foi criado como uma medida de variância para dados categóricos \citep{light1971analysis}, é expresso como:
\[G(p_1,p_2,...,p_j)=\displaystyle \sum_{j}p_j  \sum_{i\neq j}\]
\[= \displaystyle \sum_j p_j(1-p_j) \]
\begin{equation}
= \displaystyle 1-\sum_j p^2_j
\label{eq:indgini1}
\end{equation}

Para evitarmos problemas como \textbf{overfitting} por exemplo, que ocorre quando o seu modelo aprendeu tão bem as relações existentes dos conjuntos de dados para treino que acabou apenas decorando esses dados (será apresentado em \ref{fitt}). Existe diversos meios que variam de acordo com propostas de diferentes pesquisas. Pode-se definir um número mínimo de amostras que são necessárias em um nó para se fazer a divisão, ou delimitar amostras mínimas para o nó terminal e o máximo de nós terminais, determir a profundidade máxima da árvore (o quanto ela vai ramificar e expandir-se), atentar ao quanto de recurso será utilizado para treinarmos o modelo e quanto irão para serem testados (visto que não pode ser o mesmo conjunto de dados para ambos pois ela apenas iria decorar e replicar).

A poda (pós-poda) de uma árvore é importante para que se verifique a melhor divisão e chegue até a condição de parada especificada. Um exemplo que gosto muito e creio que facilitará para a compreensão da poda \citep{analytics} : suponha que há duas pistas, você está em seu veículo verde na pista da direita com uma certa quantidade de carros em sua frente movendo a aproximados 80\(km/h\) cada. Na pista da esquerda encontra-se dois caminhões de entrega de encomendas à apenas 30\(km/h\) cada. Caso você vá pela esquerda irá alcançar o carro à frente, podendo passar até chegar atrás do caminhão e irá manter seu veículo a 30\(km/h\) procurando desesperadamente encontrar alguma oportunidade de voltar para a direita. Entretando todos os outros carros ultrapassam você.

Seria uma ótima escolha caso você precisasse ultrapassá-los em poucos segundos. Mas a um prazo maior poderia ser uma escolha bem ruim. Esta é a diferença entre a árvore de decisão sem e com a poda. O algoritmo de árvore de decisão com restrições não irá visualizar os caminhões a frente e adotará o trajeto interessante naquele momento e iria optar pela esquerda. Porém quando utilizamos a poda, estamos observando alguns passos à frente antes de tomarmos decisões de que lado iríamos. Ao observar que para a esquerda é ruim, poda-se este galho.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/poda} 

}

\caption{Desenho de veículos em uma pista. Adaptado de \citep{analytics}.}\label{fig:poda}
\end{figure}



Para que se faça a poda, inicia-se o algoritmo de árvore de decisão até uma grande profundidade em sua ramificação; analisa-se a parte inferior da árvore (os filhos e seus resultados) removendo folhas que estão dando retornos negativos quando comparadas ao topo (comparando o erro de cada nó e a soma dos erros dos nós descendentes, ou algum outro método estatístico similar). Tem também algoritmos de pré-poda que buscar não particionar mais o conjunto de treinamento com algum determinado critério como não ultrapassar a uma determinada variação de ganho de informação, parar se todas as instâncias pertencem à mesma classe, valores de atributos iguais, significância estatística, redução de erro, etc. Os algoritmo de ``pós-poda'' são mais lentos e pode haver um custo bem maior que o de ``pré-poda'', mas são mais confiáveis.

Um dos cálculos mais utilizados para a poda da árvore é a \textbf{taxa de erro} que representa a razão entre o número de casos com classificação errada (\(c_e\)) e o número de casos classificados corretamente (\(cc\)) pela partição, caso a taxa de erro aumente conforme a ramificação, irá podar:

\begin{equation}
E(T)=\frac{ce}{ce+cc}
\label{eq:txerro}
\end{equation}

Na seção

\hypertarget{extree}{%
\subsection{Exemplos}\label{extree}}

Aos exemplos de Árvore de Decisão, vamos tomar como base da literatura de \citep{analytics}.

Vamos supor uma amostra com 30 alunos com duas características cada: Sexo (meninos e meninas), Classe (I e II). Temos como propósito elaborar um modelo de árvore de decisão para prevermos quais alunos iriam jogar tênis durante o intervalo. Portanto precisamos classificar estes alunos com base nestas duas características. Supondo valores pré-estabelecidos dos alunos, a árvore segregará os alunos com base nestas variáveis e identificará a variável que cria os melhores conjuntos homogêneos e heterogêneos entre si.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/decision} 

}

\caption{Divisão de alunos que jogam tênis, traduzido de \citep{analytics}.}\label{fig:decision}
\end{figure}



\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Índice de Gini - Usando o Índice de Gini, vamos verificar qual divisão produz sub-nós mais impuros. Dentro de 10 meninas, apenas duas jogam tênis no intervalo, ou seja 20\%; aos 20 meninos, 13 que equivale a 65\%. Ressalta-se que os dados foram arredondados em duas casas para facilitar a exemplificação.
\end{enumerate}

\[\mbox{sub-nó Meninas}= 1 -(0,2^2+0,8^2)=0,320\]
\[\mbox{sub-nó Meninos}= 1 -(0,65^2+0,35^2)=0,455\]

A medição de impureza para as Meninas é 0,320. Como são duas possibilidades (Menina \emph{versus} Menino), podemos dividir por 0,5 para uma compreensão mais intuitiva, obteremos 0,64. Caso fosse \(0,5 / 0,5 = 1\), significaria que o agrupamento é o mais impuro possível, pois é muito distribuído e não apenas uma variável predominante no conjunto amostral. Ao caso dos Meninos (0,455), obtemos um valor de 0,91 (bem impuro) ao dividirmos por 0,5.

Vamos analisar agora o valor de Gini dado que foi selecionado 10 meninas e 20 meninos de uma amostra de 30 alunos. Um valor ponderado:

\[Gini=\frac{10}{30}.(0,20^2+0,80^2)+\frac{20}{30}.(0,65^2+0,35^2)=0,59\]
\[\mbox{impureza: }1-0,59=0,41\]

Da mesma forma, calculamos para a classe I e II:

\[\mbox{sub-nó Classe I}= 1 -(0,43^2+0,57^2)=0,49\]
\[\mbox{sub-nó Classe II}= 1 -(0,56^2+0,44^2)=0,49\]

O valor ponderado:

\[Gini=\frac{14}{30}.(0,43^2+0,57^2)+\frac{16}{30}.(0,56^2+0,44^2)=0,51\]
\[\mbox{impureza: }1-0,51=0,49\]

Como Sexo possui um Índice de Gini maior que da Classe, ou uma impureza menor, o algoritmo irá fazer com que a divisão do nó ocorra em gênero. Caso houvesse mais variáveis como Altura, iria comparar entre as três. O de maior valor de Índice seria a nova referência de ramificação (se tornando um nó de divisão) caso haja outras características para mais ramificações.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Ganho de Informação - Inicialmente precisamos calcular a entropia do nó pai e em seguida calcular a entropia de cada nó individual da divisão e a média ponderada de todos os sub-nós disponíveis na divisão. Sabemos que de 30 alunos, 15 irão jogar tênis e 15 não, logo:
\end{enumerate}

\[\mbox{Entropia para o nó pai: } H(A)=- \sum p(A)log_2(p(A))\]
\[H(A)=-(\frac{15}{30}log_2(15/30)+\frac{15}{30}log_2(15/30))=1\]

Portanto o nó é totalmente impuro, o que faz sentido, pois ele é exatamente 50\% dos dados distribuído em jogar tênis e outros 50\% de não jogar no intervalo (maior distribuição possível entre as duas possibilidades).

Para o nó feminino, 2 que irão jogar e 8 que não irão jogar tênis num total de 10 meninas a entropia será \(- ((2/10) log_2 (2/10) + (8/10) log_2 (8/10)) = 0,72\) e para nó masculino com 13 que irão e 7 não no total de 20 meninos temos: \(- ((13/20) log_2 (13/20) + (7/20) log_2 (7/20)) = 0,93\).

Portanto o Ganho de Informação será:

\[\mbox{Ganho de Informação}(D,T)=\mbox{entropia}(D)-\displaystyle \sum_{i=1}^k \frac{|D_i|}{|D|}. \mbox{entropia}(D_i)\]
\[\mbox{Entropia}_{pai}(D)-\sum_{i=1}^k peso. Entropia_{filho}\]
\[= 1-((10/30).0,72 + (20/30). 0,93) = 0,14\]

Do mesmo modo, vamos calcular em Classe I, \(- ((6/14) log_2 (6/14) + (8/14) log_2 (8/14)) = 0,99\) e para nó Classe II, \(- ((9/16) log_2 (9/16) + (7/16) log_2 (7/16)) = 0,99\).

E o Ganho de Informação:

\[G.I = 1-((14/30) . 0,99 + (16/30) . 0,99) = 0,01\]
Como o Ganho de Informação de Sexo é maior que o de Classe (menos impuro), a árvore irá iniciar sua ramificação a partir da característica Sexo. Caso houvesse mais variáveis como Altura, iria comparar entre as três o G.I e a de maior G.I seria considerado a nova ``Pai'' para que se possa recalcular caso haja outras características para mais ramificações.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Exemplo numérico - Adilson tem uma lanchonete e recebe cerca de 300 clientes por mês. Cada cliente gasta em média R\$100,00. Uma concorrente vai abrir uma nova unidade próximo de seu estabelecimento, o que reduzirá seu número de clientes a não ser que Adilson amplie seu comércio. Considerando que está apertado financeiramente, está na dúvida se vale este investimento contabilizando num prazo de 5 meses. A análise foi: caso ele investisse R\$40.000,00, as chances de ele obter 330 clientes por mês é de 30\% e de obter 380 é 70\%. Se Adilson não optar expandir, não irá gastar nada porém com a concorrente, irá ter uma probabilidade de 60\% de atender 250 clientes por mês e de 40\% de atender 290. Qual seria sua decisão, tomando como base o algoritmo de Árvore de Decisão?
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/decisionlanche} 

}

\caption{Árvore de Decisão sobre o lucro da lanchonete.}\label{fig:decisionlanche}
\end{figure}



Pode-se calcular pelo Valor Esperado (Média). Para a primeira situação, gastando R\$40.000,00, em 5 meses seu valor esperado será:
\[V.E=(0,3\ .\ 125.000,00)+(0,7\ . \ 150.000,00)= 142.500,00\]

Ao segundo caso, em que Adilson não irá optar o investimento em seu estalecimento:
\[V.E=(0,6\ .\ 125.000,00)+(0,4\ . \ 145.000,00)= 133.000,00\]

Portanto Adilson tem uma probabilidade maior de escolher investir os R\$40.000,00 para ampliar sua lanchonete. Lembrando que foi utilizado o critério de médias, podendo haver diversos outros.

\hypertarget{AC}{%
\section{Análise de Componentes Principais}\label{AC}}

A Análise de Componentens Principais, popularmente conhecida como ACP ou PCA (\emph{Principal Component Analysis}), em inglês, foi introduzida por \citet{pearson1901liii} e fundamentada no artigo de \citet{hotelling1933analysis}. É uma \textbf{análise multivariada} que tem como objetivo explicar a estrutura de variância e covariância de um vetor aleatório, composto por \(p\)-variáveis aleatórias, através da construção de combinações lineares das variáveis originais que são chamadas de componentes principais e não correlacionadas entre si \citep{mingoti2007analise}. É uma técnica bastante utilizada em diversas áreas do conhecimento, como a biologia, a agronomia, a zootécnica, a ecologia, a engenharia florestal, a medicina, a economia, entre outras áreas. Muitos sugerem o seu uso quando o volume de dados ou variáveis é grande possibilitando reduzir a dimensão da matriz de dados que compõem o conjunto de variáveis resposta com apenas poucos componentes, ou seja, \(p\) variáveis originais substituídas por \(k\) (sendo \(k < p\)) componentes principais não correlacionadas.

Vamos supor um conjunto de dados em apenas duas dimensões \((x, y)\) e que pode ser plotado em um plano cartesiano. Podemos verificar pelo seu comportamento que possuem alta correlação positiva.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/pca1} 

}

\caption{Gráfico bidimensional \(x\) por \(y\).}\label{fig:pca1}
\end{figure}



Mas se quisermos descobrir a variação do conjunto de dados, o ACP busca encontrar um novo sistema de coordenadas em que cada ponto tem um novo valor \((x, y)\). Os eixos não representam algo físico, mas representam combinações de \(x\) e \(y\) que denominamos \textbf{``componentes principais''}, escolhidas para analisar a variação do eixo. Observe que rotacionamos o gráfico na Figura \ref{fig:pca2} e que após a ACP, podemos verificar a possibilidade de dercartar a componente referente ao eixo \(y\), visto que a componente do eixo \(x\) explica 99,30\% da variação total dos dados, ou seja, o primeiro componente tem uma maior dispersão (variância). Possibilitando pela componente principal do eixo \(x\), analisar e até mesmo classificar as observações, como por exemplo, a observação 1 e 2 como um conjunto e a 3, 4 e 5 como um segundo conjunto.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/pca2} 

}

\caption{Gráfico de \(x\) por \(y\) rotacionado.}\label{fig:pca2}
\end{figure}



Com mais dimensões, o ACP torna-se ainda mais útil pois possibilita observarmos o conjunto de dados num melhor ângulo.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/pca3} 

}

\caption{Gráfico tridimensional, em \citet{powellpca}.}\label{fig:pca3}
\end{figure}



Portanto, a ACP assume que os dados originais estão representados por características (variáveis) correlacionadas com o objetivo de transformar essas variáveis em novas (componentes principais) por meio de mudança de base do espaço vetorial que não sejam correlacionadas entre si e que estas novas variáveis (menores que as originais) retenha a maior parte da variação apresentada pelas originais, tornando possível a classificação.

A suposição de normalidade não é requisito para sua técnica, mas ainda sim é conveniente padronizar (\ref{normpadro}) cada variável, permitindo que todas as variáveis tenham o mesmo peso para evitarmos viés de escala \citep{hongyu2016analise}. A padronização das variáveis do vetor pelas respectivas médias e desvios padrões, gera novas variáveis centradas em zero e com variâncias iguais a 1. Assim, as componentes principais são determinadas a partir da matriz de covariâncias das variáveis originais padronizadas \citep{mingoti2007analise}.

Agora que sabemos o que é ACP, vamos apresentar alguns conceitos de Álgebra Linear e Estatísticas para compreendermos como é aplicado este método.

\hypertarget{autovalores-e-autovetores}{%
\subsection{Autovalores e Autovetores}\label{autovalores-e-autovetores}}

Caso ainda não tenha muito contato com a Álgebra Linear, recomendo buscar algumas literaturas a respeito. Em \ref{dicio} encontra-se sobre Escalar, Vetores, Espaço Vetorial e Transformação Linear que serão tratadas neste tópico.

Dado uma matriz \(A_{mxn}\) que define uma transformação linear (não muda sua dimensão), existem vetores onde sua orientação não é afetada por esta transformação, os \textbf{autovetores}. Na Figura \ref{fig:autovetor}, \(u\) é um autovetor e \(V\) não.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/autovetor} 

}

\caption{\(u\) é um autovetor de \(T\), porém \(V\) não.}\label{fig:autovetor}
\end{figure}



Um vetor é dito ser autovetor da matriz \(A_{mxn}\) se a transformação linear deste vetor \(T(u)\) é colinear a este vetor, ou seja, \(A_{mxn}\vec{u}=\lambda \vec{u}\). Sendo que \(\lambda\) é um escalar e chamado de \textbf{autovalor} da matriz correspondente ao autovetor. Para encontrarmos o autovetor:
\[A_{mxn}\vec{u}=\lambda \vec{u} \]
\[A_{mxn}\vec{u}-\lambda \vec{u}=0 \]
\begin{equation}
(A_{mxn}-\lambda l)\vec{u}=0
    \label{eq:autovetor}
\end{equation}

esta equação tem solução trivial, ou seja, diferentes da nula \((\vec{v}\neq 0 )\) se e somente se, seu determinante é zero. Conhecido como \textbf{Equação caracterísica} e sua solução são os \textbf{autovalores}:
\begin{equation}
    \mbox{Eq. Característica}\ \  det(A_{mxn}-\lambda l)=0  
    \label{eq:eqcarac}
\end{equation}

Note também que toda transformação linear (matriz) em um espaço
vetorial complexo (números imaginários) tem, pelo menos, um autovetor (real ou complexo).

\hypertarget{exautovetor1}{%
\subsubsection{Exemplo}\label{exautovetor1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Vamos considerar um operador linear \textbf{\(T: R^2 \rightarrow R^2\)}. Com \(T(x,y)=(4x+5y,2x+2y)\). Quais são os autovalores a matriz \(A=\begin{bmatrix} 4 &5 \\ 2 &2 \end{bmatrix}\)?
\end{enumerate}

Vamos resolver a equação característica \(det(A_{mxn}-\lambda l)=0\).

\[det(A_{mxn}-\lambda l)=\begin{bmatrix}
4 &5 \\ 
2 &2 
\end{bmatrix} - \lambda \begin{bmatrix}
1 &0 \\ 
0 &1 
\end{bmatrix} = \begin{bmatrix}
4-\lambda &5 \\ 
2 &2-\lambda 
\end{bmatrix}\]

Com \(det(A_{mxn}-\lambda l)=0:\)
\[(4-\lambda)(2-\lambda)-10=0 \]
\[\lambda^2-6\lambda-2=0 \\ \mbox{resolvendo a equação: } \ 
\lambda_1 \approx 6,32 \  \ \mbox{e} \ \ \lambda_2 \approx -0,32\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Considere amatriz \(A=\begin{bmatrix} 1 &0 \\ 1 &-2 \end{bmatrix}\).
\end{enumerate}

Vamos resolver a equação característica \(det(A_{mxn}-\lambda l)=0\).

\[det(A_{mxn}-\lambda l)=\begin{bmatrix}
1 &0 \\ 
1 &-2 
\end{bmatrix} - \lambda \begin{bmatrix}
1 &0 \\ 
0 &1 
\end{bmatrix} = \begin{bmatrix}
1-\lambda &0 \\ 
1 &-2-\lambda 
\end{bmatrix}\]

Resovendo este sistema, obtemos os autovalores:
\[\lambda_1=1 \ \ \lambda_2=-2\]
Vamos encontrar agora seus respectivos autovetores, lembrando que \(A_{mxn}\vec{u}=\lambda \vec{u}\):
\[ \mbox{Primeiro encontrar os autovetores de }\lambda_1=1:\]
\[A_{mxn}\vec{u}=\lambda \vec{u}\]
\[\begin{bmatrix}
1 &0 \\ 
1 &-2 
\end{bmatrix}. \begin{bmatrix}
x \\ 
y  
\end{bmatrix}=1.\begin{bmatrix}
x \\ 
y  
\end{bmatrix} \]
\[x=x \]
\[x-2y=y \]
\[\mbox{logo: } x=3y\]

Portanto em \(\lambda_1=1\) será \(X=\begin{bmatrix}3y\\y\end{bmatrix}\), com o autovetor de \(y=1\) e \(x=\begin{bmatrix}3\\1\end{bmatrix}\).

Agora para o segundo autovalor \(\lambda_2=-2\):
\[A_{mxn}\vec{u}=\lambda \vec{u} \]
\[\begin{bmatrix}
1 &0 \\ 
1 &-2 
\end{bmatrix}. \begin{bmatrix}
x \\ 
y  
\end{bmatrix}=-2.\begin{bmatrix}
x \\ 
y  
\end{bmatrix} \]
\[x=-2x\]
\[x-2y=-2y \]
\[ \mbox{logo: } x=0\]

Portanto em \(\lambda_2=-2\) será \(y=\begin{bmatrix}0\\1\end{bmatrix}\) e \(x=0\).

Logo o primeiro autovetor será \(X=\begin{bmatrix}3\\1\end{bmatrix}\) e o segundo \(y=\begin{bmatrix}0\\1\end{bmatrix}\).

\hypertarget{estatuxedsticas}{%
\subsection{Estatísticas}\label{estatuxedsticas}}

Alguns conceitos de Estatísticas são fundamentais para que se entenda a ACP:

\begin{itemize}
\tightlist
\item
  \textbf{Covariância x Correlação:} como apresentado em \ref{dicio}, a covariância é semelhante à correlação (ver \ref{normpadro}) entre duas variáveis, no entanto, elas diferem que os coeficientes de correlação são padronizados. Isso faz com que um relacionamento linear varie entre \(-1 \leq \rho \leq 1\). A correlação mede tanto a força como a direção da relação linear entre duas variáveis. Ao caso da covariância os valores não são padronizados. Assim, a covariância pode variar de \(-\infty \leq Cov (x,y) \leq \infty\) demonstrando quanto \(x\) e \(y\) mudam juntas. Portanto o valor para uma relação linear ideal depende muito dos dados. Como os dados não são padronizados, é difícil determinar a força da relação entre as variáveis. Note que o coeficiente de correlação é uma função da covariância:
\end{itemize}

\[\rho_{x,y}=\frac{cov(x,y)}{\sigma_x \sigma_y}\]

Uma covariância positiva sempre resulta em uma correlação positiva e uma covariância negativa sempre resulta em uma correlação negativa.

Quando temos um vetor de \(n\) variáveis em vez de apenas duas, iremos obter uma matriz de covariâncias ou correlação. Contendo em sua diagonal a variância \(\sigma^2\), pois \(cov(x_i,x_i)=\sigma^2(x_i)\), por exemplo:

\[\begin{bmatrix}
cov_{1,1} &cov_{1,2=2,1}  &cov_{1,3=3,1} \\ 
cov_{1,1=2,1} &cov_{2,2}  &cov_{2,3=3,2} \\ 
cov_{3,1=1,3} &cov_{2,3=3,2} & cov_{3,3}
\end{bmatrix} = \begin{bmatrix}
var_{1} &cov_{1,2=2,1}  &cov_{1,3=3,1} \\ 
cov_{1,1=2,1} &var_{2}  &cov_{2,3=3,2} \\ 
cov_{3,1=1,3} &cov_{2,3=3,2} & var_{3}
\end{bmatrix}\]

\hypertarget{a-acp}{%
\subsection{A ACP}\label{a-acp}}

Agora que compreendemos alguns conceitos importantes, podemos entender melhor a metodologia da ACP. Assumindo que os dados originais estão representados por variáveis correlacionadas (etapa de pré-processamento), ou seja, não independentes. Vamos ao objetivo de transformar essas \(p\) variáveis em outras novas \(k\) (com \(k<p\)) de ordem decrescente de variabilidade e que não sejam correlacionadas e que as primeiras novas variáveis retenham a maior parte da variação apresentadas pelas originais a fim de podermos classificá-los.

Dado um vetor \(X=(X_1,X_2,..., X_p)'\) aleatório de \(p\) variáveis originais com vetor de médias \(\mu=(\mu_1,\mu_2,...,\mu_p)\) e matriz de covariâncias \(A_{mxn}\) e \(\lambda_1\geq\lambda_2\geq...\geq\lambda_p\) os autovalores da matriz de covariâncias, com seus respectivos autovetores normalizados \(e_i'=e_1,e_2,...,e_p\). O primeiro componente principal \(y_1\), como dito que deve ser ordem decrescente de variabilidade, será uma combinação linear do vetor aleatório \(X\) de forma que a variância \(var(y_1)=\sigma^2_{y_{1}}\) seja a máxima (maior possível), ou melhor, precisamos encontrar um vetor \(e_1\) tal que \(y_1=(e_1)^T X\) e \(var(y_1=(e_1)^T X\) seja máxima. De mesmo modo para \(y_2\) e um vetor \(e_2\) e assim sucessivamente para \(p\) variáveis em seu banco de dados.

Portanto a matriz dos autovetores normalizados da matriz de covariância \(A_{mxn}\) é:

\begin{equation}
    O_{mxn}= 
\begin{bmatrix}
e_{11} &e_{21}  &. &.  &. &e_{p1} \\ 
e_{12} &e_{22}  &. &.  &. &e_{p2} \\ 
.      &.       &. &.  &. &. \\ 
.      &.       &. &.  &. &. \\ 
.      &.       &. &.  &. &. \\ 
e_{1p} &e_{2p}  &. &.  &. &e_{pp} 
\end{bmatrix}
=[e_1,e_2,...,e_p]
\label{eq:autovetormatrix}
\end{equation}

E dos autovalores:
\begin{equation}
\Lambda_{mxn}=
\begin{bmatrix}
\lambda_1 & &0\\
& \lambda_2 & \\
0 & & \lambda_n
\label{eq:autovalormatrix}
\end{bmatrix}
\end{equation}

Portanto, as variáveis aleatórias que constituem o vetor \(Y\) não são correlacionadas entre si. Com isso, a ideia de utilizar combinações lineares em \(Y\) como forma de representar a estrutura de covariâncias do vetor \(X\) torna-se interessante, a fim de reduzir o espaço de variáveis de \(p\) para \(k<p\) dimensões. Os vetores \(X\) e \(Y\) terão a mesma variância total e generalizada, com \(Y\) de vantagem de não haver variáveis correlacionadas e facilitando na interpretação conjunta delas (análise multivariada). Portanto:

\begin{equation}
   Y_j=e_j'X=e_{j1}X_1+e_{j2}X_2+...+e_{jp}X_p
   \label{eq:cp}
\end{equation}

A esperança e variância:
\begin{equation}
E[Y_j]=e_j'\mu=e_{j1}\mu_1+e_{j2}\mu_2+...+e_{jp}\mu_p
\end{equation}

\begin{equation}     
Var[Y_j]=e_j' A_{mxn}e_j=\lambda_j
\end{equation}

Lembrando que \(Cov[Y_j,Y_k]=0, \ j\neq k\) e que cada autovalor \(\lambda_j\) representa a variância de uma componente principal \(Y_j\). A primeira componente terá a maior variabilidade e a última menor.

Para calcularmos a correlação estimada entre a \(j\)-ésima componente principal e a variável aleatória \(X\), podemos expressar:
\begin{equation}   
r_{Y_j,X_i}=\frac{e_{ji}\sqrt{\lambda_j}}{\sqrt{\sigma}}
\end{equation}

De mesmo modo para tratarmos de amostras, são trabalhados com \(\hat{Y_j}\) e \(\hat{X_j}\) e seus respectivos, autovetores, autovalores, matriz de covariância amostral e correlação.

Os maiores autovalores são os que orientam o sinal, os demais podem ser descartados. Porém quantos componentes principais devemos utilizar? Precisamos verificar a proporção da variação total dos dados originais que uma componente pode explicar, a partir disso selecionarmos. Lembrando que cada autovalor \(\lambda_i\) refere-se a \(var(y_i)\).

Para calcularmos a variação total, expressa-se pela somatória de todos os autovalores:
\begin{equation}
    \displaystyle \sum_j \lambda_j 
    \label{eq:vartot}
\end{equation}

Portanto, para analisar cada \(i\) componente, ou seja, cada autovalor (variação ``explicada'' por cada componente):
\begin{equation}
    p_i=\frac{\lambda_j}{\displaystyle \sum_j \lambda_j} 
    \label{eq:varind}
\end{equation}

Sendo geralmente escolhido as componentes com seus respectivos autovalores que explicam entre 70\%-90\% segundo alguns pesquisadores. Outros como \citet{kaiser1960application}, propõe aceitar, observando diretamente, somente os autovalores iguais ou superiores à unidade.

\textbf{Importante:} sobre utilizar matriz de covariância ou de correlação depende muito das fundamentações teóricas e recomendaçõesdos pesquisadores. Em geral, utiliza-se a matriz de correlação (quando padronizamos e elaboramos a matriz) ao caso de padronizar escalas distintas que podem viesar, como por exemplo, medidas de distância e de peso.

Caso esteja utilizando software para a análise, dependendo do software utilizado com seu determinado modelo de formulação de componentes principais, pode ocorrer essa troca de sinal que nada mais é do que uma reflexão em relação ao eixo, uma rotação em seu espaço vetorial n-dimensional em torno da origem, poderá ocasionar uma ``rotação'' em torno do eixo. Tratando de algebra linear e suas combinações lineares, a combinação poderá possuir soluções diferentes que diferem apenas o sinal.

\textbf{Resumo geral:} É comum o pesquisador trabalhar com um volume de dados muito grande e que estão muitas vezes correlacionadas. A Análise de Componentes principais busca explicar a estrutura de variância e covariância de um vetor aleatório com \(p\) variáveis, possibilitando por meio da combinação linear deste vetor aleatório novas componentes (denominada componente principal) com menos variáveis (\(k<p\)) que o conjunto de dados original e não correlacionadas de modo que estas componentes principais retenha a maior parte da variação apresentada pelas originais, possibilitando classificarmos o conjunto de dados e até mesmo descartar variáveis que podem ser redundantes ou não importantes. Utiliza-se de fundamentações teóricas de Autovetores e Autovalores para que se encontre um novo sistema de coordenadas com novos pontos a partir das originais, pode-se dizer que rotacionamos para que se visualize num ``novo ângulo'', para descobrir e avaliar em ordem decrescente a variação (matriz de covariância do vetor aleatório) deste conjunto de dados. Os passos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Calcular a Matriz de Correlação amostral \(R_{mxn}\) ou Covariância amostral \(S_{mxn}\) do vetor aleatório de \(p\) variáveis.
\item
  Encontrar \(\lambda_i\) autovalores da matriz.
\item
  Encontrar seus respectivos \(e_i\) autovetores.
\item
  Aplicar outras análises caso necessite (como correlação da componente e a variável) , interpretar os dados e selecionar as novas variáveis.
\end{enumerate}

\hypertarget{exemplocp}{%
\subsection{Exemplos}\label{exemplocp}}

Tomando como base exemplos de \citet{mingoti2007analise}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Matriz de covariância amostral}

  A Tabela apresenta dados relativos as 12 empresas no que se refere a 3 variáveis (medidas em unidades monetárias): ganho bruto (\(X1\)), ganho líquido (\(X2\)) e o patrimônio acumulado (\(X_3\)):
\end{enumerate}

\begin{longtable}[]{@{}lccc@{}}
\toprule
\textbf{Empresas} & \textbf{Ganho Bruto(\(X_1\))} & \textbf{Ganho Líquido(\(X_2\))} & \textbf{Patrimônio Líquido(\(X_3\))}\tabularnewline
\midrule
\endhead
E1 & 9893 & 564 & 17689\tabularnewline
E2 & 8776 & 389 & 17359\tabularnewline
E3 & 13572 & 1103 & 18597\tabularnewline
E4 & 6455 & 743 & 8745\tabularnewline
E5 & 5129 & 203 & 14397\tabularnewline
E6 & 5432 & 215 & 3467\tabularnewline
E7 & 3807 & 385 & 4679\tabularnewline
E8 & 3423 & 187 & 6754\tabularnewline
E9 & 3708 & 127 & 2275\tabularnewline
E10 & 3294 & 297 & 6754\tabularnewline
E11 & 5433 & 432 & 5589\tabularnewline
E12 & 6287 & 451 & 8972\tabularnewline
\bottomrule
\end{longtable}

Após calcularmos suas covariâncias (recomendo o leitor calcular e verificar e atentar que por ser exemplificação, passível de ocorrência de arrendondamento dos valores), obtemos a matriz de covariância amostral:

\begin{longtable}[]{@{}cccc@{}}
\toprule
& \textbf{Ganho Bruto (\(X_1\))} & \textbf{Ganho Líquido (\(X_2\))} & \textbf{Patrimônio Líquido (\(X_3\))}\tabularnewline
\midrule
\endhead
\textbf{Ganho Bruto (\(X_1\))} & 9550608,6 & 706121,1 & 14978232,5\tabularnewline
\textbf{Ganho Líquido (\(X_2\))} & 706121,1 & 76269,5 & 933915,1\tabularnewline
\textbf{Patrimônio Líquido (\(X_3\))} & 14978232,5 & 933915,1 & 34408113,0\tabularnewline
\bottomrule
\end{longtable}

Para calcularmos os autovalores:

\[det(A_{mxn}-\lambda l)=0\]
\[\begin{bmatrix}
9550608,6 -\lambda &706121,1 &14978232,5\\ 
706121,1 &76269,5-\lambda & 933915,1 \\
14978232,5&933915,1&34408113,0-\lambda
\end{bmatrix}=0\]

Resolvendo o sistema, obtemos os seguintes autovalores das componentes principais:
\[\lambda_1=38018192,2 \ \ \lambda_2=2327881,5 \ \ \lambda_3=19334,8\]
Para encontrarmos a porcentagem da variância explicada por cada auto valor:
\[\%\lambda_1=\frac{38018192,2}{38018192,2+2327881,5+19334,8}.100\%=94,2\% \] \[\%\lambda_2=\frac{2327881,5}{38018192,2+2327881,5+19334,8}.100\%=5,77\% \] \[\%\lambda_3=\frac{19334,8}{38018192,2+2327881,5+19334,8}.100\%=0,048\%\]
Portanto, podemos descartar o segundo e o terceiro componente principal, pois o primeiro explica cerca de \(94,2\%\).

Por fim os autovetores podem sem calculados:

\[A_{mxn}\vec{u}=\lambda \vec{u}\]
Com \(A_{mxn}\) a matriz de covariância amostral, \(u\) o autovetor e \(\lambda\) os respectivos autovalores dos autovetores.

\[\begin{bmatrix}
\vec{u_1}\\ \vec{u_2} \\ \vec{u_3}
\end{bmatrix}
\begin{bmatrix}
9550608,6  &706121,1 &14978232,5\\ 
706121,1 &76269,5 & 933915,1 \\
14978232,5&933915,1&34408113,0
\end{bmatrix}  = \lambda_i \begin{bmatrix}
u_1\\ u_2 \\ u_3
\end{bmatrix} \]

\[\mbox{substituindo os autovalores:}\]
\[\begin{bmatrix}
u_1\\ u_2 \\ u_3
\end{bmatrix}
\begin{bmatrix}
9550608,6  &706121,1 &14978232,5\\ 
706121,1 &76269,5 & 933915,1 \\
14978232,5&933915,1&34408113,0
\end{bmatrix}  = \begin{bmatrix}0,942&0&0 \\ 0&0,0577&0 \\0&0& 0,0048 \end{bmatrix}\begin{bmatrix}
u_1\\ u_2 \\ u_3
\end{bmatrix}\]

Teremos os autovetores:

\begin{longtable}[]{@{}cccc@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\centering
\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
\textbf{Autovetor Ganho Bruto (\(u_1\))}\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
\textbf{Autovetor Ganho Líquido (\(u_2\))}\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
\textbf{Autovetor Patrimônio Líquido (\(u_3\))}\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\centering
\textbf{Autovetor Ganho Bruto (\(u_1\))}\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,425\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,900\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
-0,099\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\centering
\textbf{Autovetor Ganho Líquido (\(u_2\))}\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,028\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,096\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,995\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\centering
\textbf{Autovetor Patrimônio Líquido (\(u_3\))}\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,905\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
-0,426\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,016\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Com os autovetores, podemos elaborar as três componentes principais:

\[\hat{y_1}=0,425(Ganho Bruto)+0,028(GanhoLíquido)+0,905(PatrimônioLíquido)\]
\[\hat{y_2}=0,900(Ganho Bruto)+0,096(GanhoLíquido)-0,429(PatrimônioLíquido)\]
\[\hat{y_3}=-0,099(Ganho Bruto)+0,995(GanhoLíquido)+0,016(PatrimônioLíquido)\]

Determinada as componentes principais, podemos obter seus valores numéricos (\textbf{escores}) para cada elemento amostral. Basicamente substituímos os valores originais nas funções encontradas de componentes principais (\(\hat{y_1},\hat{y_2} \ \mbox{e}\  \hat{y_3}\)):

\begin{longtable}[]{@{}lccc@{}}
\toprule
\textbf{Empresas} & \textbf{\(CP_1\)} & \textbf{\(CP_2\)} & \textbf{\(CP_3\)}\tabularnewline
\midrule
\endhead
E1 & 8857,59 & -165,27 & -90,18\tabularnewline
E2 & 8079,36 & -1046,65 & -158,93\tabularnewline
E3 & 11257,93 & 2810,25 & 96,18\tabularnewline
E4 & -690,80 & 566,19 & 284,23\tabularnewline
E5 & 3844,09 & -3084,94 & -30,40\tabularnewline
E6 & -5915,42 & 1841,62 & -224,93\tabularnewline
E7 & -5504,97 & -119,93 & 124,81\tabularnewline
E8 & -3796,38 & -1367,83 & -0,64\tabularnewline
E9 & -7729,15 & 789,46 & -160,88\tabularnewline
E10 & -3848,18 & -1473,28 & 121,59\tabularnewline
E11 & -3989,16 & 960,15 & 25,13\tabularnewline
E12 & -564,92 & 290,23 & 14,02\tabularnewline
\bottomrule
\end{longtable}

Podemos observar que a empresa E9 possui o menor desempenho, e as E1, E2 e E3 os melhores. Entenda que não necessariamente o sinal de negativo é sempre ser um pior valor, isso depende da pesquisa e da interpretação do sinal ou como em caso de autovetores, indica a rotação. Para analisarmos por gráfico não é recomendável utilizar neste caso, devido que são valores bem grandes para serem inseridos. No caso de Matriz de correlação, que serão padronizados os dados, podemos visualizar melhor.

E a correlação entre as componentes principais e as variáives originais:

\begin{longtable}[]{@{}cccc@{}}
\toprule
& \textbf{CP 1} & \textbf{CP 2} & \textbf{CP 3}\tabularnewline
\midrule
\endhead
\textbf{Ganho Bruto (\(X_1\))} & 0,8859 & 0,4639 & -0,0047\tabularnewline
\textbf{Ganho Líquido (\(X_2\))} & 0,6450 & 0,5569 & 0,5232\tabularnewline
\textbf{Patrimônio Líquido (\(X_3)\))} & 0,9933 & -0,1156 & 0,0004\tabularnewline
\bottomrule
\end{longtable}

Por meio da observação de seus resultados podemos analisar que:

\begin{itemize}
\item
  A primeira componente possui alta correlação-positiva com todas as três variáveis, podemos analisar como um índice de desempenho global da empresa. Pelo autovetor, podemos ver que o patrimônio possui o maior peso e de menor o ganho líquido. Podemos verificar que quanto maior for os valores das variáveis, maior será dessa componente, ou melhor, maior será o desempenho global da empresa. Esta ocupa, observando pelos autovalores, 94,\textbackslash{}20\% de toda variação explicada, dependendo da pesquisa pode-se descartar as outras componentes.
\item
  A segunda componente que ocupa 5,77\% de toda variação explicada (autovalor), possui o ganho bruto e patrimônio de maior variância amostral (analisando o tabela de covariância amostra). Pelos autovetores, podemos verificar que o ganho bruto é a variável dominante com segunda maior variância amostral. Com a componente próximo a zero, entende-se que haverá um certo equilíbrio entre ganho bruto e patrimônio acumulado, o que na verdade o aumento do ganho bruto eleva-se esta componente e o patrimônio contrário. Note que há correlação bem menor entre elas.
\item
  A terceira componente com pouca variância total explicada, referente ao ganho líquido de menor variância amostral, possui pouca importância. Apena o ganho líquido possui alta correlação, visto que às outras duas são próximas de zero.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Matriz de correlação}
\end{enumerate}

No exemplo anterior, vimos que as componentes principais foram obtidas a partir de matriz de covariâncias e que são influenciadas pelas variáives com maior variância. Porém em casos onde existe muita discrepância entre essas variâncias por motivos de unidades de medidas distintas entre as variáveis. Podemos amenizar essa discrepância por meio de transformação dos dados originais de modo a equilibrar as variâncias ou colocar todos os dados em mesma escala de medida. Uma muito usual é a padronização que gera novas variáveis centradas em zero e com variâncias iguais a 1. Em caso de dúvida, reveja em \ref{normpadro}. Tomando como base o mesm conjunto de dados do exercício anterior, padronizando e elaborando a matriz de correlação amostral, obtemos:

\begin{longtable}[]{@{}cccc@{}}
\toprule
& \textbf{Ganho Bruto (\(X_1\))} & \textbf{Ganho Líquido (\(X_2\))} & \textbf{Patrimônio Líquido (\(X_3\))}\tabularnewline
\midrule
\endhead
\textbf{Ganho Bruto (\(X_1\))} & 1,00 & 0,827 & 0,826\tabularnewline
\textbf{Ganho Líquido (\(X_2\))} & 0,827 & 1,00 & 0,576\tabularnewline
\textbf{Patrimônio Líquido (\(X_3\))} & 0,826 & 0,576 & 1,00\tabularnewline
\bottomrule
\end{longtable}

Com o mesmo procedimento do exemplo anterior ao caso de matriz de covariância, obtemos os respectivos autovalores e autovetores:

\[\lambda_1=2,493 \ \ \lambda_2=0,423 \ \ \lambda_3=0,084 \]
\[\%\lambda_1=83,084\% \ \ \%\lambda_2=14,117\% \ \ \%\lambda_3=2,799\%\]

\begin{longtable}[]{@{}cccc@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\centering
\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
\textbf{Autovetor Ganho Bruto (\(u_1\))}\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
\textbf{Autovetor Ganho Líquido (\(u_2\))}\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
\textbf{Autovetor Patrimônio Líquido (\(u_3\))}\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\centering
\textbf{Autovetor Ganho Bruto (\(u_1\))}\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,617\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
-0,001\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
-0,787\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\centering
\textbf{Autovetor Ganho Líquido (\(u_2\))}\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,557\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
-0,706\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,437\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\centering
\textbf{Autovetor Patrimônio Líquido (\(u_3\))}\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,556\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,708\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
0,435\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Por meio dos autovalores, podemos verificar que a variância total explicada pela primeira componente é aproximadamente 83,1\%, pela segunda 14,1\% e pela terceira 2,8\%. As duas primeiras componentes explicam juntas 97,2\% aproximadamente da variância total do vetor original padronizado. Note que o processo de análise é da mesma forma que o exemplo anterior. A primeira componente é um índice de desempenho global padronizado da empresa. A segunda componente representa uma comparação entre ganho líquido e patrimônio padronizados (verifique pelo autovetor da segunda componente que o ganho bruto possui um valor de coeficiente muito pequeno em relação aos outros). Por fim, a terceira componente compara-se o ganho bruto com às outras duas variáveis.

Suas componentes principais são:

\[\hat{y_1}=0,617(Ganho Bruto)+0,557(GanhoLíquido)+0,556(PatrimônioLíquido)\]
\[\hat{y_2}=-0,001(Ganho Bruto)-0,706(GanhoLíquido)+0,708(PatrimônioLíquido)\]
\[\hat{y_3}=-0,787(Ganho Bruto)+0,437(GanhoLíquido)+0,435(PatrimônioLíquido)\]

Note que em relação ao exemplo anterior, seus coeficientes de ponderação estão numericamente mais equilibrados que no caso de matriz de covariâncias amostral. Todas as variâncias iguais a um, sem dominância direta de nenhuma variável.

Determinada as componentes principais, podemos obter seus valores numéricos (escores) para cada elemento amostral. Podendo ser obtidas com técnicas estatísticas usuais como análise de variância e análise de regressão, entre outras. Usando dados nas três componentes principais, obtemos:

\begin{longtable}[]{@{}lccc@{}}
\toprule
\textbf{Empresas} & \textbf{\(CP_1\)} & \textbf{\(CP_2\)} & \textbf{\(CP_3\)}\tabularnewline
\midrule
\endhead
E1 & 1,85 & 0,65 & -0,11\tabularnewline
E2 & 1,22 & 1,07 & -0,13\tabularnewline
E3 & 3,84 & -0,68 & -0,13\tabularnewline
E4 & 0,62 & -0,96 & 0,41\tabularnewline
E5 & -0,23 & 1,20 & 0,31\tabularnewline
E6 & -1,22 & -0,21 & -0,60\tabularnewline
E7 & -1,08 & -0,51 & 0,21\tabularnewline
E8 & -1,38 & 0,28 & 0,14\tabularnewline
E9 & -1,89 & -0,13 & -0,38\tabularnewline
E10 & -1,17 & -0,02 & 0,36\tabularnewline
E11 & -0,56 & -0,53 & 0,08\tabularnewline
E12 & 0,00 & 0,15 & -0.01\tabularnewline
\bottomrule
\end{longtable}

Da mesma forma que o exemplo anterior é importante reforçar novamente que pode haver troca de sinal de acordo com a formulação pelo software e a sua rotação em torno do eixo, visto que tratando de combinações lineares pode haver soluções com sinais diferentes. Pode resultar em valores numéricos diferentes e o pesquisador deve atentar em sua interpretação dos resultados obtidos. Pelos resultados nos leva a verificar que a empresa E9 possui o menor desempenho, e as E1, E2 e E3 os melhores.

Note que se compararmos os Escores do primeiro exemplo com matriz de covariância amostral e os Escores do exemplo com matriz de correlação amostral, foram concordantes a indicação das três empresas com melhor desempenho global e na de pior desempenho. Porém, algumas discordaram em algumas posições. Houve 5 concordância em 12 classificações (41,7\%). Como as componentes principais foram obtidas pela decomposição espectral de matrizes diferentes, houve esta diferença. E que a matriz de correlação amostral leva em consideração a média do conjunto de 12 empresas de cada variável original, a matriz de covariância amostral não. Importante notar que neste caso, as primeiras componentes obtidas possuem a mesma interpretação, verificando consistência nas análises de ambos os métodos.

Com valores padronizados, fica mais fácil a visualizaçãor e interpretação da ACP por um gráfico, que denominamos de biplot. Basicamente colocamos no eixo X a primeira componente e no eixo Y a segunda componente principal (as que mais explicam a variância total). No qual as observações em análise são os Escores das observações (no caso as empresas) e os respectivos vetores das variáveis (Ganho Bruto, Ganho Líquido e Patrimônio Líquido).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/biplotpadro} 

}

\caption{Gráfico de biplot, em X a primeira componente principal e Y a segunda componente.}\label{fig:biplotpadro}
\end{figure}



A primeira componente principal (Dim1), as variáveis que se referem ao patrimônio, ganho bruto e ganho líquido possuem cargas positivas (todas tendendo fortemente à direita), reafirmando a análise anterior de que a primeira componente refere-se ao desempenho global padronizado da empresa. Com E1, E2 e E3 os maiores em desempenho.
Para a segunda componente principal (Dim2), note que Patrimônio e Ganho Líquido estão em sentidos opostos, o que reafirma nossa análise anterior de ser uma comparação entre elas.

\hypertarget{anuxe1lise-de-agrupamentos---clusters}{%
\section{\texorpdfstring{Análise de Agrupamentos - \emph{Clusters}}{Análise de Agrupamentos - Clusters}}\label{anuxe1lise-de-agrupamentos---clusters}}

A Análise de Agrupamentos, também conhecido como Análise de Conglomerados, classificação ou \emph{Clusters}, tem como propósito dividir os elementos de uma amostra (ou população) em grupos de modo que os elementos pertencentes a estes grupos tenham características similares entre si e heterôgenos com os outros grupos \citep{mingoti2007analise}. Esta classificação vai de acordo com a medida e o método de classificação. Este tipo de análise é muito comum seu uso em diversas áreas como segmentação de clientes de acordo com perfis de consumo \citep{punj1983cluster}, perfis de personalidade em psicologia \citep{speece1985classification}, classificação de cidades, etc. Para o agrupamento de \emph{clusters}, tomaremos como base a literatura de \citet{mingoti2007analise}.

É muito importante o critério que o pesquisador utilizará para delimitar até que ponto os elementos podem ser considerados semelhantes em suas características ou não, por isso precisa-se de medidas apropriadas para classificar. Cada elemento amostral têm informações de \(p\) variáveis dentro de um vetor e por meio de medidas matemáticas, como as medidas de distância pode ser possível compararmos as observações dentro de seu banco de dados. Calculando a distância entre os vetores das observações da amostra e agrupando de acordo com suas distância (agrupar os de menores distâncias entre si). Aqui entramos com a aplicação de Medida de Distância, em \ref{meddist}. Quaquer medida de distância pode ser utilizada em variáveis quantitativas pode ser transformada num coeficiente de similaridade \citep{mingoti2007analise}.

A Análise de Clusters são frequentemente classificadas em \textbf{Hierárquicas (aglomerativas e divisivas)} que comumente utilizada para identificar possíveis agrupamentos e um provável valor da quantitade de grupos \(g\) e \textbf{Não hierárquicas} que necessita um número de grupos pré-estabelecido pelo pesquisados que a aplica.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/hierarq} 

}

\caption{Esquema geral de procedimentos hierárquicos aglomerativos e divisivos \citep{mingoti2007analise}.}\label{fig:hierarq}
\end{figure}



\hypertarget{tuxe9cnicas-hieruxe1rquicas-aglomerativas}{%
\subsection{Técnicas Hierárquicas Aglomerativas}\label{tuxe9cnicas-hieruxe1rquicas-aglomerativas}}

Nesta técnica, inicia-se com \(n\) conglomerados como se cada elemento do banco e dados fosse um conglomerado isolado. No algoritmo, a cada passo os elementos amostrais vão sendo agrupados, formando novos conglomerados até que todos os elementos considerados estejam num único grupo. No início, tratando-se de variabilidade, tem-se a partição de menor dispersão interna ja que todos os conglomerados possui amenas um único elemento (variância \(\sigma^2\) zero). Ao final dos estágios, encontra-se a maior dispersão interna possível, pois todos os elementos amostrais estão num único \emph{cluster} \citep{mingoti2007analise}. Conforme \citet{mingoti2007analise}, os passos fundamentais são:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Cada elemento possui um \emph{cluster} de tamanho 1, logo \(n\) \emph{clusters};
\item
  Em cada estágio do algoritmo de agrupamento, os pares de conglomerados mais ``similares'' vão combinando-se passando a constituir um único conglomerado. Apenas um novo conglomerado pode ser formada a cada passo, ou seja, a cada etapa o número de conglomerados irá diminuir;
\item
  Como mostra-se na Figura \ref{fig:hierarq}, em cada estágio do algoritmo, cada novo conglomerado formado é um agrupamento de conglomerados de estágios anteriores. Se dois elementos amostrais aparecem juntos num mesmo \emph{cluster} em alguma etapa, estarão juntos em todos os outros;
\item
  Por estarmos trabalhando com conglomerados em hierarquia, podemos construir um gráfico denominado Dendograma, ou Dendrograma, que representa a história do agrupamento. É um gráfico em forma de árvore tal que a escala vertical indica o nível de similaridade (ou dissimilaridade) e na horizontal os elementos amostrais em ordem relacionada à história do agrupamento. Sua altura representa ao nível em que os elementos foram considerados semelhantes entre si (distância do agrupamento ou nível de similaridade).
\end{enumerate}

Existe alguns métodos para que se escolha o número final dos grupos \(g\), mas em geral é subjetivo com base em fundamentações empíricas. Vamos agora para os métodos mais comuns e utilizados em muitos \emph{softwares} estatísticos.

\hypertarget{muxe9todo-de-ligauxe7ao-simples-simple-linkage}{%
\subsubsection{\texorpdfstring{Método de Ligaçao Simples (\emph{Simple Linkage})}{Método de Ligaçao Simples (Simple Linkage)}}\label{muxe9todo-de-ligauxe7ao-simples-simple-linkage}}

A similaridade entre dois conglomerados é definida pelos dois elementos mais parecidos entre si \citep{sneath1957application}. Por exemplo, num determinado momento do algoritmo, encontra-se dois grupos: \(C_1=\{X_1,X_3,X_7\}\) e \(C_2=\{X_2,X_6\}\). A distância entre esses dois grupos será definida por:

\begin{equation}
    d(C_1,C+2)=min\{d(X_l,X_k, l\neq k, l=1,3,7 \ \ \mbox{e} \ \ k=2,6\}
    \label{eq:ligsimples}
\end{equation}

é a distância entre os vizinhos mais próximos (elementos mais parecidos com os conglomerados. Em cada estágio, os dois conglomerados que são mais similares com relação à distância são combinados em um únicos \emph{cluster}. Como ilustrado abaixo, a distância entre 6 e 1 caracteriza a distância entre os grupos, pelo método de ligação simples.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/ligsimples} 

}

\caption{Método de ligação simples, adaptado de \citet{mingoti2007analise}.}\label{fig:ligsimples}
\end{figure}



Vamos aproveitar o exemplo que utilizamos de distância Euclidiana, em \ref{disteuclidana}. Com o seguinte banco de dados:

\begin{longtable}[]{@{}ccccccc@{}}
\caption{\label{tab:dadossrenda} Renda e Idade de 6 indíviduos, abordado em \ref{disteuclidana} sobre distância Euclidiana \citep{mingoti2007analise}}\tabularnewline
\toprule
\textbf{Renda} & 9,6 & 8,4 & 2,4 & 18,2 & 3,9 & 6,4\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Renda} & 9,6 & 8,4 & 2,4 & 18,2 & 3,9 & 6,4\tabularnewline
\midrule
\endhead
\textbf{Idade} & 28 & 31 & 42 & 38 & 25 & 41\tabularnewline
\bottomrule
\end{longtable}

A matriz de distância calculada entre os seis elementos amostrais é dada por:
\[D_{6x6}=\begin{bmatrix}\\
 &A&B&C&D&E&F \\
 A&0&&&&&\\
 B&3,23&0&&&&\\
 C & 15,74& 12,53&0&&&\\
 D& 13,19& 12,04& 16,29&0&&\\
 E& 6,44& 7,50& 17,06& 19,33&0&\\
 F& 13,39& 10,19& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

Sabemos que o menor valor observado na Matriz é 3,23 (distância entre os elementos A e B) nas duas variáveis medidas. Portanto este dois indivíduos são aglomerados fazendo com que a amostra de seis elementos passe a ser cinco. Lembrando que permanece as distâncias mínimas dos elementos com o novo conglomerado \(\{A,B\}\) pois queremos os mais próximos.
\[d(\{A,B\},\{C\})=min(d\{A,C\},\{B,C\})=min(\{15,74\},\{12,53\})=12,53\]
\[d(\{A,B\},\{D\})=min(d\{A,D\},\{B,D\})=min(\{13,19\},\{12,04\})=12,04\]
\[d(\{A,B\},\{E\})=min(d\{A,E\},\{B,E\})=min(\{6,44\},\{7,50\})=6,44\]
\[d(\{A,B\},\{F\})=min(d\{A,F\},\{B,F\})=min(\{13,39\},\{10,19\})=10,19\]

\[D_{5x5}=\begin{bmatrix}\\
 &\{A,B\}&C&D&E&F \\
 \{A,B\}&0&&&&\\
 C & 12,53&0&&&\\
 D& 12,04& 16,29&0&&\\
 E& 6,44& 17,06& 19,33&0&\\
 F& 10,19& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

Nesta nova matriz, será a distância entre C e F (4,12), da mesma forma que anteriormente, fazendo com que fique quatro grupos:

\[D_{4x4}=\begin{bmatrix}\\
 &\{A,B\}& \{C,F\}&\{D\}&\{E\} \\
 \{A,B\}&0&&\\
 \{C,F\} & 10,19&0&&\\
 \{D\}& 12,04& 12,18&0&\\
 \{E\}& 6,44& 16,19& 19,33&0\\
\end{bmatrix}\]

Agora a menor distância encontra-se entre \(\{A,B\}\) e \(\{E\}\) com 6,44:
\[D_{3x3}=\begin{bmatrix}\\
 &\{A,B,E\}& \{C,F\}&\{D\} \\
 \{A,B,E\}&0&\\
 \{C,F\} & 10,19&0&\\
 \{D\}& 12,04& 12,18&0\\
\end{bmatrix}\]
O próximo valor mínimo será 10,19 sobrando \(C_1=\{A,B,E,C,F\}\) e \(C_2=\{D\}\) e por fim reduz-se um único \emph{cluster} \(C_1=\{A,B,C,D,E,F\}\) com o nível de junção igual a 12,04.

Portanto, o o histórico do agrupamento e seu respectivo dendograma será:

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:ligsimple} Histórico do agrupamento por meio da Ligação Simples.}\tabularnewline
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endhead
1 & 5 & \{A\} e \{B\} & 3,23\tabularnewline
2 & 4 & \{C\} e \{F\} & 4,12\tabularnewline
3 & 3 & \{A,B\} e \{E\} & 6,44\tabularnewline
4 & 2 & \{A,B,E\} e \{C,F\} & 10,19\tabularnewline
5 & 1 & \{A,B,E,C,F\} e \{D\} & 12,04\tabularnewline
\bottomrule
\end{longtable}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/dendsimples} 

}

\caption{Dendograma do agrupamento. Método de ligação simples.}\label{fig:dendsimples}
\end{figure}



\hypertarget{muxe9todo-de-ligauxe7ao-completa-complete-linkage}{%
\subsubsection{\texorpdfstring{Método de Ligaçao Completa (\emph{Complete Linkage})}{Método de Ligaçao Completa (Complete Linkage)}}\label{muxe9todo-de-ligauxe7ao-completa-complete-linkage}}

A similaridade entre dois conglomerados é definida pelos elementos que são menos semelhantes entre si \citep{sneath1957application}. Por exemplo, vamos considerar os conjuntos \(C_1=\{X_1,X_3,X_7\}\) e \(C_2=\{X_2,X_6\}\). A distância entre eles então será:

\begin{equation}
d(C_1,C_2)=max \{d(X_l,X_k, l\neq k,l=1,3,7 \ \ \mbox{e} \ \ k=2,6\}
 \label{eq:ligcompleta}
\end{equation}

Em cada estágio calcula-se para os pares de grupos, combinando num único aqueles que estiverem com o menor valor da distância. Segue abaixo uma ilustração.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/ligcompleta} 

}

\caption{Método de ligação completa, adaptado de \citet{mingoti2007analise}.}\label{fig:ligcompleta}
\end{figure}



Aproveitando o mesmo exemplo que utilizamos no método anterior, sobre a distância Euclidiana, em \ref{disteuclidana}. A matriz de distância calculada entre os seis elementos amostrais é dada por:
\[D_{6x6}=\begin{bmatrix}\\
 &A&B&C&D&E&F \\
 A&0&&&&&\\
 B&3,23&0&&&&\\
 C & 15,74& 12,53&0&&&\\
 D& 13,19& 12,04& 16,29&0&&\\
 E& 6,44& 7,50& 17,06& 19,33&0&\\
 F& 13,39& 10,19& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

Sabemos que o menor valor observado na Matriz é 3,23 (distância entre os elementos A e B) nas duas variáveis medidas. Portanto este dois indivíduos são aglomerados fazendo com que a amostra de seis elementos passe a ser cinco. Lembrando que permanece as distâncias máximas dos elementos com o novo conglomerado \(\{A,B\}\) pois queremos os mais afastados.
\[d(\{A,B\},\{C\})=max(d\{A,C\},\{B,C\})=min(\{15,74\},\{12,53\})=15,74\]
\[d(\{A,B\},\{D\})=max(d\{A,D\},\{B,D\})=max(\{13,19\},\{12,04\})=13,19\]
\[d(\{A,B\},\{E\})=max(d\{A,E\},\{B,E\})=max(\{6,44\},\{7,50\})=7,50\]
\[d(\{A,B\},\{F\})=max(d\{A,F\},\{B,F\})=max(\{13,39\},\{10,19\})=13,39\]

\[D_{5x5}=\begin{bmatrix}\\
 &\{A,B\}&C&D&E&F \\
 \{A,B\}&0&&&&\\
 C & 15,74&0&&&\\
 D& 13,19& 16,29&0&&\\
 E& 7,50& 17,06& 19,33&0&\\
 F& 13,39& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

Nesta nova matriz, será a distância entre C e F (4,12), da mesma forma que anteriormente, fazendo com que fique quatro grupos e analisando pela máxima:

\[D_{4x4}=\begin{bmatrix}\\
 &\{A,B\}& \{C,F\}&\{D\}&\{E\} \\
 \{A,B\}&0&&\\
 \{C,F\} & 15,74&0&&\\
 \{D\}& 13,19& 16,29&0&\\
 \{E\}& 7,50& 17,06& 19,33&0\\
\end{bmatrix}\]

Agora a menor distância encontra-se entre \(\{A,B\}\) e \(\{E\}\) com 7,50:
\[D_{3x3}=\begin{bmatrix}\\
 &\{A,B,E\}& \{C,F\}&\{D\} \\
 \{A,B\}&0&\\
 \{C,F\} & 17,06&0&\\
 \{D\}& 19,33& 16,29&0\\
\end{bmatrix}\]

O próximo valor mínimo será 16,29, unindo os grupos \(\{C,F\}\) e \(\{D\}\), tornando os conglomerados \(C_1=\{A,B,E\}\) e \(C_2=\{C,F,D\}\) e por fim a distância máxima entre os dois grupos é 19,33.

Portanto, o o histórico do agrupamento por meio da Ligação Completa e seu respectivo dendograma será:

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:ligcomplet} Histórico do agrupamento por meio da Ligação Completa.}\tabularnewline
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endhead
1 & 5 & \{A\} e \{B\} & 3,23\tabularnewline
2 & 4 & \{C\} e \{F\} & 4,12\tabularnewline
3 & 3 & \{A,B\} e \{E\} & 7,5\tabularnewline
4 & 2 & \{C,F\} e \{D\} & 16,29\tabularnewline
5 & 1 & \{A,B,E\} e \{C,F\} & 19,33\tabularnewline
\bottomrule
\end{longtable}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/dendcomplete} 

}

\caption{Dendograma do agrupamento. Método de ligação completa.}\label{fig:dendcomplete}
\end{figure}



\hypertarget{muxe9todo-da-muxe9dia-das-distuxe2ncias-average-linkage}{%
\subsubsection{\texorpdfstring{Método da Média das Distâncias (\emph{Average Linkage})}{Método da Média das Distâncias (Average Linkage)}}\label{muxe9todo-da-muxe9dia-das-distuxe2ncias-average-linkage}}

Neste caso a distância entre os conglomerados é com base nas médias. Se \(C_1\) tem \(n_1\) elementos e \(C_2\) tem \(n_2\) elementos, a distância será expressa como:

\begin{equation}
d(C_1,C_2)=\displaystyle \sum_{l\epsilon C_1} \sum_{k\epsilon C_2} \frac{1}{n_1 n_2} d(X_l,X_k)
 \label{eq:ligmedia}
\end{equation}

Portanto, a distância entre \(C_1=\{X_1,X_3,X_7\}\) e \(C_2=\{X_2,X_6\}\) será:

\[d(C_1,C_2=\frac{1}{6}[d(X_1,X_2)+d(X_l,X_6)+d(X_3,X_2)+d(X_3,X_6)+d(X_7,X_2)+d(X_7,X_6)]\]
Vamo considerar novamente a matriz inicial como exemplificação:

\[D_{6x6}=\begin{bmatrix}\\
 &A&B&C&D&E&F \\
 A&0&&&&&\\
 B&3,23&0&&&&\\
 C & 15,74& 12,53&0&&&\\
 D& 13,19& 12,04& 16,29&0&&\\
 E& 6,44& 7,50& 17,06& 19,33&0&\\
 F& 13,39& 10,19& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

Sabemos que o menor valor observado na Matriz é 3,23 (distância entre os elementos A e B) nas duas variáveis medidas. Portanto este dois indivíduos são aglomerados fazendo com que a amostra de seis elementos passe a ser cinco. Dessa vez são calculados em relação às médias das distância dos conglomerados \(\{A,B\}\) com os outros.
\[d(\{A,B\},\{C\})=[d\{A,C\}+\{B,C\}]/2=[\{15,74\}+\{12,53\}]/2=14,13\]
\[d(\{A,B\},\{D\})=[d\{A,D\}+\{B,D\}]/2=[\{13,19\}+\{12,04\}]/2=12,62\]
\[d(\{A,B\},\{E\})=[d\{A,E\}+\{B,E\}]/2=[\{6,44\}+\{7,50\}]/2=6,97\]
\[d(\{A,B\},\{F\})=[d\{A,F\}+\{B,F\}]/2=[\{13,39\}+\{10,19\}]/2=11,79\]

\[D_{5x5}=\begin{bmatrix}\\
 &\{A,B\}&C&D&E&F \\
 \{A,B\}&0&&&&\\
 C & 14,13&0&&&\\
 D& 16,62& 16,29&0&&\\
 E& 6,97& 17,06& 19,33&0&\\
 F& 11,79& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

A próxima distância será entre C e F (4,12) novamente, fazendo com que fique quatro grupos. Repetindo o processo pela média.:

\[D_{4x4}=\begin{bmatrix}\\
 &\{A,B\}& \{C,F\}&\{D\}&\{E\} \\
 \{A,B\}&0&&\\
 \{C,F\} & 12,96&0&&\\
 \{D\}& 12,62& 14,24&0&\\
 \{E\}& 6,97& 16,62& 16,19&0\\
\end{bmatrix}\]

Atente-se ao cálculo das distâncias médias, como por exemplo \(\{A,B\}\) e \(\{C,F\}\) foram quatros valores: \(d(\{A,B\},\{C,F\})=[d(A,C)+d(A,F)+d(B,C)+d(B,F)]/4\).

Agora, teremos \(\{A,B\}\) e \(\{E\}\) com 6,97:

\[D_{3x3}=\begin{bmatrix}\\
 &\{A,B,E\}& \{D\}&\{C,F\} \\
 \{A,B\}&0&\\
 \{D\} & 14,85&0&\\
 \{E\}& 14,18& 14,24&0\\
\end{bmatrix}\]

O próximo valor mínimo será 14,18, unindo os grupos \(\{A,B,E\}\) e \(\{C,F\}\), tornando os conglomerados \(C_1=\{A,B,C,E,F\}\) e \(C_2=\{D\}\) e por final será 14,61 a distância entre eles.

Portanto, o o histórico do agrupamento e seu respectivo dendograma será:

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:ligmedia} Histórico do agrupamento por meio da Ligação Média.}\tabularnewline
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endhead
1 & 5 & \{A\} e \{B\} & 3,23\tabularnewline
2 & 4 & \{C\} e \{F\} & 4,12\tabularnewline
3 & 3 & \{A,B\} e \{E\} & 6,97\tabularnewline
4 & 2 & \{A,B,E\} e \{C,F\} & 14,19\tabularnewline
5 & 1 & \{A,B,E,C,F\} e \{D\} & 14,61\tabularnewline
\bottomrule
\end{longtable}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/dendaverage} 

}

\caption{Dendograma do agrupamento. Método da média das distâncias.}\label{fig:dendaverage}
\end{figure}



\hypertarget{muxe9todo-do-centruxf3ide-centroid-method}{%
\subsubsection{\texorpdfstring{Método do Centróide (\emph{Centroid Method})}{Método do Centróide (Centroid Method)}}\label{muxe9todo-do-centruxf3ide-centroid-method}}

A distância entre dois grupos é medida com a distância entre os vetores de médias, também denominado como centróides. Com \(C_1=\{X_1,X_3,X_7\}\) e \(C_2=\{X_2,X_6\}\), pode-se calcular:

\[\mbox{vetor de médias de} C_1=\overline{X_1}=\frac{1}{3}[X_1+X_3+X_7] \]
\[\mbox{vetor de médias de} C_2=\overline{X_2}=\frac{1}{2}[X_2+X_6]\]
E a distância entre \(C_1\) e \(C_2\), é a distância Euclidiana ao quadrado entre os vetores de médias amostral (também pode ser usado com a usual entre os vetores):

\begin{equation}
d(C_1,C_2)= (\overline{X_1}-\overline{X_2})'(\overline{X_1}-\overline{X_2})
 \label{eq:distcentroide}
\end{equation}

Para cada passo do algoritmo, os conglomerados que possuem o menor valor de distância são agrupados. Vamos manter a matriz euclidiana (podemos manter a usual ou utilizar calcular as distâncias euclidianas ao quadrado)

\[D_{6x6}=\begin{bmatrix}\\
 &A&B&C&D&E&F \\
 A&0&&&&&\\
 B&3,23&0&&&&\\
 C & 15,74& 12,53&0&&&\\
 D& 13,19& 12,04& 16,29&0&&\\
 E& 6,44& 7,50& 17,06& 19,33&0&\\
 F& 13,39& 10,19& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

Lembrando que os valores originais das variáveis são:

\begin{longtable}[]{@{}ccccccc@{}}
\caption{\label{tab:dadosrenda} Renda e Idade de 6 indíviduos, abordado em \ref{disteuclidana} sobre distância Euclidiana \citep{mingoti2007analise}.}\tabularnewline
\toprule
\textbf{Renda} & 9,6 & 8,4 & 2,4 & 18,2 & 3,9 & 6,4\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Renda} & 9,6 & 8,4 & 2,4 & 18,2 & 3,9 & 6,4\tabularnewline
\midrule
\endhead
\textbf{Idade} & 28 & 31 & 42 & 38 & 25 & 41\tabularnewline
\bottomrule
\end{longtable}

Temos o menor o valor de 3,23 (distância entre os elementos A e B) nas duas variáveis medidas. Portanto este dois indivíduos são aglomerados fazendo com que a amostra de seis elementos passe a ser cinco. Lembrando que agora calcula-se a média entre os vetores, já que queremos o centróide. Em \(\{A,B\}\) obtemos:

\[\{A,B\}=(\frac{9,6+8,4}{2});(\frac{28+31}{2})=(9;29,5)\]
Portanto calculando a distância com a nova coordenada \(\{A,B\}\):

\[d(\{A,B\},\{C\})=\sqrt{(9-2,4)^2+(29,5-42)^2}=14,135\]
\[d(\{A,B\},\{D\})=\sqrt{(9-18,2)^2+(29,5-38)^2}=12,525\]
\[d(\{A,B\},\{E\})=\sqrt{(9-3.9)^2+(29,5-25)^2}=6,800\]
\[d(\{A,B\},\{F\})=\sqrt{(9-6,4)^2+(29,5-41)^2}=11,700\]

\[D_{5x5}=\begin{bmatrix}\\
 &\{A,B\}&C&D&E&F \\
 \{A,B\}&0&&&&\\
 C & 14,13&0&&&\\
 D& 12,52& 16,29&0&&\\
 E& 6,80& 17,06& 19,33&0&\\
 F& 11,70& 4,12& 12,18& 16,19&0 \\
\end{bmatrix}\]

A próxima distância será entre C e F (4,12) novamente, fazendo com que fique quatro grupos. Repetindo o processo sucessivamente de retornar aos dados originais, recalcular identificar o novo menor valor (o que dependendo do banco de dados exige tempo computacional) chegaremos aos seguintes resultados:

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:ligcent} Histórico do agrupamento pelo Método de Centróide.}\tabularnewline
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endhead
1 & 5 & \{A\} e \{B\} & 3,2\tabularnewline
2 & 4 & \{C\} e \{F\} & 4,1\tabularnewline
3 & 3 & \{A,B\} e \{E\} & 6,8\tabularnewline
4 & 2 & \{A,B,E\} e \{C,F\} & 13,8\tabularnewline
5 & 1 & \{A,B,E,C,F\} e \{D\} & 12,9\tabularnewline
\bottomrule
\end{longtable}

Lembrando que dependendo do arredondamento, pode haver pequena variação e que é possível fazer com o quadrado da distância euclidiana. Note também que o nível de fusão no passo 5 foi menor que o do passo 4. É possível esta ocorrência no método de centróide pois em algum passo do algoritmo de agrupamento houver empates entre valores da matriz de distâncias, quanto maior for o número de elementos amostrais, menor será a chance dessa ocorrência \citep{mingoti2007analise}. A partição do dendograma será muito parecida com os anteriores, não será necessário apresentar.

\hypertarget{muxe9todo-de-ward-wards-method}{%
\subsubsection{\texorpdfstring{Método de Ward (\emph{Ward's Method})}{Método de Ward (Ward's Method)}}\label{muxe9todo-de-ward-wards-method}}

Vimos nos métodos anteriores que ao aumentarmos o estágio \(k\) para \(k+1\), a qualidade a partição decresce (com excessão de centróide) pois o nivel de fusão e portanto o nível de similaridade também. Então percebe-se que a variação entre grupos diminui e a variação dentro dos grupos aumenta. \citet{ward1963hierarchical} propôs um método fundamental na mudança de variação entre os grupos em formação e entre cada passo do processo de agrupamento. É também conhecido como ``mínima variância'' por ter como objetivo a minimização da soma de quadrados dentro dos grupos.

Inicialmente cada elemento é considerado como um único elemento conglomerado e em cada passo do algoritmo de agrupamento é calculada a soma de quadrados dentro de cada conglomerado. Portanto, o agrupamento é feito a partir das somas de quadrados dos desvios entre acessos ou do quadrado da distância Euclidiana.

\begin{equation}
 SS_i=\displaystyle \sum^{n_i}_{j=1} (X_{ij}-\overline{X_i})'(X_{ij}-\overline{X_i})
 \label{eq:sumquadraeuclid}
\end{equation}

em que \(n_i\) é o número de elementos no conglomerado \(C_i\), quando se está no passo \(k\); \(X_i\) é o vetor de observações do \(j\)-ésimo elemento amostral e pertence ao \(i\)-ésimo conglomerado; \(\overline{X_i}\), o centróide do conglomerado; e \(SS_i\), a soma de quadrados correspondente do conglomerado \(C_i\). No passo \(k\) então, a soma de quadrados total é expressa como:

\begin{equation}
 SS_i=\displaystyle \sum^{g_k}_{i=1}SS_i
 \label{eq:sumquadrak}
\end{equation}

onde \(g_k\) é o valor de grupos existentes quando se está no passo \(k\).
A Distância entre os conglomerados \(C_l\) e \(C_i\) é definida pela soma dos quadrados entre os \emph{clusters} \(C_l\) e \(C_i\):

\begin{equation}
 d(C_l,C_i)=[\frac{n_l n_i}{n_l+n_i}] (X_{l}-\overline{X_i})'(X_{l}-\overline{X_i})
 \label{eq:distward}
\end{equation}

em que cada passo do algoritmo de agrupamento, os dois conglomerados que minimizam a distância são combinados.

Note que é muito semelhante com o método de centróide, porém o método de Ward leva em consideração a diferença dos tamanhos dos conglomerados que estão sendo comparados, ele possui como fator de ponderação \([\frac{n_l n_i}{n_l+n_i}]\) que quanto maior forem os valores de \(n_l\) e \(n_i\) e a discrepância entre eles, maior será o fator e portanto, a distância entre os centróides dos conglomerados comparados \citep{mingoti2007analise}.

O processo de calcular é bem simples, semelhante ao método anterior, porém para as distâncias entre os conglomerados utiliza-se a equação \eqref{eq:distward} e acaba que sendo bem trabalhosa e consumindo muito tempo do pesquisador, por isso temos atualmente diversos \emph{softwares} que possam auxiliar neste processo. Com o mesmo conjunto de dados de Renda e Idade do exemplos anteriores podemos chegar no seguinte histórico de agrupamento:

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:ligward} Histórico do agrupamento pelo Método de Ward.}\tabularnewline
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Passo} & \textbf{Número de Grupos} & \textbf{Fusão} & \textbf{Distância}\tabularnewline
\midrule
\endhead
1 & 5 & \{A\} e \{B\} & 10,44\tabularnewline
2 & 4 & \{C\} e \{F\} & 17,00\tabularnewline
3 & 3 & \{A,B\} e \{E\} & 61,68\tabularnewline
4 & 2 & \{A,B,E\} e \{C,F\} & 270,25\tabularnewline
5 & 1 & \{A,B,E,C,F\} e \{D\} & 465,00\tabularnewline
\bottomrule
\end{longtable}

Importante lembrar que de mesmo modo em outras literaturas, os métodos descritos fazem o agrupamento de elementos amostrais com base em algum critério pré-estabelecido, então nem sempre segue a divisão dos dados amostrais de ordem ``natural'' entre os \(n\) elementos amostrais ou populacional. Pode variar um pouco dependente do \emph{Software} e sua simulação.

Atente-se pois com os exemplos utilizados, deram resultados bem próximos. Dependendo do tamanho do conjunto de dados pode nem sempre ocorrer assim, mas claro, esperamos uma consistência entre os diferentes métodos.

\hypertarget{nuxfamero-final-de-grupos}{%
\subsection{Número final de grupos}\label{nuxfamero-final-de-grupos}}

Como escolher o número final de grupos \(g\)? Em qual passo \(k\)? Isso varia muito com sua pesquisa, sua fundamentação teórica e até mesmo a experiência. Existe alguns critérios que pesquisadores utilizam para avaliar e tomar a decisão, as principais são:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Análise do comportamento do nível de fusão:} sabemos que a medida que o passo aumenta, a similaridade entre os conglomerados vai decrescendo. Portanto muitos elaboram um gráfico de passo pelo nível de distância. Se há ``pontos de salto'' grandes em relações aos outros pontos de distância, pode indicar parar. Ao caso do exemplo Método de Ligação Simples ficaria:
\end{enumerate}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/steps} 

}

\caption{Gráfico de Passo a partir do exemplo de Método de Ligação Simples. Passos \emph{versus} Distância.}\label{fig:steps}
\end{figure}



\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Análise do Comportamento do nível de similaridade:} em vez de observarmos o comportamento da distância em cada estágio, como no critério anterior. utiliza-se o seguinte cálculo para \(C_i\) e \(C_l\) unidos em certa etapa:
\end{enumerate}

\begin{equation}
S_{il}=(1-\frac{d_{il}}{max\{d_{jk},j,k-1,2,...,n\}}).100
 \label{eq:critsimi}
\end{equation}

sendo \(d_{il}\{max\{d_{jk},j,k-1,2,...,n\}\}\) a maior distância entre os \(n\) elementos amostrais na matriz do primeiro estágio. Tem como objetivo encontrar pontos onde há decrescimento acentuado na similaridade dos conglomerados unidos (ao encontrar, finaliza o algoritmo). Segundo \citet{felix2004}, geralmente valores acima de 90\% resulta em quantidade de grupos muito elevado.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Análise da soma de quadrados entre grupos, o coeficiente \(R^2\):} Em cada \(k\) passo, podemos calcular a soma de quadrados entre os grupos e dentro dos grupos.
\end{enumerate}

Para \(X_{ij}\) vetor de medidas observadas para o \(j\)-ésimo elemento amostral do \(i\)-ésimo grupo \(\overline{X}\) e partição dos dados amostrais em \(g\) grupos. A Soma de Quadrados Total corrigida para a média global em cada variável:

\begin{equation}
SST_c=\displaystyle \sum^{g}_{i=1} \sum^{n_i}_{i=1} (X_{ij}-\overline{X})'(X_{ij}-\overline{X})
 \label{eq:sstc}
\end{equation}

A Soma dos Quadrados Total dentro dos grupos da partição, que equivale ao residual:

\begin{equation}
SSR=\displaystyle \sum^{g}_{i=1} \sum^{n_i}_{i=1} = \sum^{g}_{i=1}SS_i
 \label{eq:ssrc}
\end{equation}

E a Soma de Quadrados Total entre os \(g\) grupos da partição:

\begin{equation}
SSB=\displaystyle \sum^{g}_{i=1} n_i (\overline{X_{i}}-\overline{X})'((\overline{X_{i}}-\overline{X})
 \label{eq:ssbc}
\end{equation}

Por fim, o coeficiente \(R^2\) é expresso por:

\begin{equation}
R^2=\frac{SSB}{SST_c}
 \label{eq:rsquarec}
\end{equation}

Quanto maior for seu valor, maior será a soma de quadrados SSB e menor o residual SSR. Elaborando um gráfico com os passos do agrupamento e o \(R^2\). E parar o algoritmo no ``ponto de salto'' grande em relação aos demais.

\textbf{Observação:} Há diversos critérios para o leitor se aprofundar, como \textbf{Estatística Pseudo F}, \textbf{Estatística Pseudo T}, \textbf{Correlação Semiparcial} que pode-se aplicar em método de Ward, \textbf{Estatísica \emph{Cubic Clustering Criterium}}, etc. Cabe o leitor interessado se aprofundar em seus estudos de acordo com sua pretensão. Os métodos hierárquicos são muito utilizados nas pesquisas atuais e ainda estão em constante desenvolvimento e combinações com outros modelos para aperfeiçoar suas pesquisas. Muitos usam o método hierárquico também, da mesma forma que Análise de Componentes Principais e pré-processamento, para selecionar variáveis que possar ser utilizadas em sua pesquisa.

\hypertarget{tuxe9cnicas-nuxe3o-hieruxe1rquicas}{%
\subsection{Técnicas Não Hierárquicas}\label{tuxe9cnicas-nuxe3o-hieruxe1rquicas}}

As Técnicas Não Hierárquicas são técnicas que têm como propósito identificar diretamente uma partição de \(n\) elementos em \(k\) \emph{clusters}, de modo que a partição satisfaça: coesão/semelhança interna e isolamento/separação dos \emph{clusters} formados. Há muitas partições possíveis de ordem \(k\) e não é plausível criar todas possíveis (provávelmente nem será possível). Portanto deve-se utilizar alguns meios que possam investigar algumas partições viáveis e próxima da ótima.

Diferentemente do Hierárquico, esta técnica necessita que o pesquisador específique previamente o número de \emph{clusters} desejado. Em cada passo do agrupamento, os novos grupos podem ser formados através da divisão ou junção de grupos formados em etapas anteriores, ou seja, não necessariamente os mesmos elementos num mesmo conglomerado estarão juntos no final. Então, não será possível o uso de dendogramas e geralmente são processos iterativos com maior capacidade de dados. Vamos observar alguns métodos utilizados.

\hypertarget{muxe9todo-da-k-muxe9dias-k-means}{%
\subsubsection{\texorpdfstring{Método da K-Médias (\emph{K-Means})}{Método da K-Médias (K-Means)}}\label{muxe9todo-da-k-muxe9dias-k-means}}

Por \citet{hartigan1979algorithm}, o método k-Médias é um dos mais conhecidos e utilizados em Ánalise de \emph{Clusters}. Nele, cada elemento amostral é alocado ao \emph{cluster} mp qual o centróide (vetor de médias amostral) é o mais próximo de valores observados para o respectivo elemento. É composto pelos passos \citep{mingoti2007analise}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Selecione \(k\) centróides (conhecido como sementes ou protótipos), para iniciar a etapa de partição. Para selecionar varia também pelo método aplicado: pode-se selecionar de forma aleatória simples sem reposição; utilizar técnicas hierárquicas aglomerativas para se obter os grupos iniciais e calcular o vetor de médias; escolher a partir de uma variável aleatória de maior variância; selecionar por análise estatística elementos discrepantes no conjunto de dados; escolhar prefixada ou os primeiros valores do \emph{dataset}, etc;
\item
  Cada elemento do conjunto de dados é comparado com cada centróide inicial, por meio de alguma medida de distância (geralmente Euclidiana). O de menor distância é alocado ao grupo;
\item
  Após aplicar em cada \(n\) elemento amostral, recalcula-se os valores dos centróides para cada novo grupo formado e repte-se a etapa 2, considerando os centróides desse novo grupo;
\item
  Os passos 2 e 3 serão repetidos até que nenhuma realocação de elementos seja necessária e o pesquisador verificar e analisar de acordo com sua demanda.
\end{enumerate}

Não é recomendável para o experimento quando \(k\) primeiros elementos amostrais são similares entre si.

Vamos a um exemplo:

\begin{longtable}[]{@{}ccccc@{}}
\caption{\label{tab:desenv} Valores dos índices de desenvolvimento de países.}\tabularnewline
\toprule
Países & Expectativa de Vida & Educação & PIB & Estabilidade Política\tabularnewline
\midrule
\endfirsthead
\toprule
Países & Expectativa de Vida & Educação & PIB & Estabilidade Política\tabularnewline
\midrule
\endhead
Reino Unido & 0,88 & 0,99 & 0,91 & 1,10\tabularnewline
Austrália & 0,90 & 0,99 & 0,93 & 1,26\tabularnewline
Canadá & 0,90 & 0,98 & 0,94 & 1,24\tabularnewline
Estados Unidos & 0,87 & 0,98 & 0,97 & 1,18\tabularnewline
Japão & 0,93 & 0,93 & 0,93 & 1,20\tabularnewline
França & 0,89 & 0,97 & 0,92 & 1,04\tabularnewline
Cingapura & 0,88 & 0,87 & 0,91 & 1,41\tabularnewline
Argentina & 0,81 & 0,92 & 0,80 & 0,55\tabularnewline
Uruguai & 0,82 & 0,92 & 0,75 & 1,05\tabularnewline
Cuba & 0,85 & 0,90 & 0,64 & 0,07\tabularnewline
Colômbia & 0,77 & 0,85 & 0,69 & -1,36\tabularnewline
Brasil & 0,71 & 0,83 & 0,72 & 0,47\tabularnewline
Paraguai & 0,75 & 0,83 & 0,63 & -0,87\tabularnewline
Egito & 0,70 & 0,62 & 0,60 & 0,21\tabularnewline
Nigéria & 0,44 & 0,58 & 0,37 & -1,36\tabularnewline
Senegal & 0,47 & 0,37 & 0,45 & -0,68\tabularnewline
Serra Leoa & 0,23 & 0,33 & 0,27 & -1,26\tabularnewline
Angola & 0,34 & 0,36 & 0,51 & -1,98\tabularnewline
Etiópia & 0,31 & 0,35 & 0,32 & -0,55\tabularnewline
Moçambique & 0,24 & 0,37 & 0,36 & 0,20\tabularnewline
China & 0,76 & 0,80 & 0,61 & 0,39\tabularnewline
\bottomrule
\end{longtable}

\textbf{Fonte:} ONU, 2002, site: www.undp.org/hdro. Relatório de Desenvolvimento Humano.

Como dito, este método é muito dispendioso ao pesquisador calcular manualmente, portanto recomendo-o utilizar algum \emph{software} estatístico para o seu cálculo e verificar o algoritmo do mesmo. Particularmente, utilizo para a escolha das sementes iniciais a seleção aleatória ou alguma técnica Hierárquica, pois ela evita com que há influências pessoais na seleção.

Após aplicarmos o método \emph{k-Médias} com a escolha aleatória das sementes iniciais obtemos:

\begin{longtable}[]{@{}lllclll@{}}
\caption{\label{tab:exkmeans} Resultado descritivo dos \emph{clusters} formados.}\tabularnewline
\toprule
\begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Grupos}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{SQ}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Países}\strut
\end{minipage} & \begin{minipage}[b]{0.27\columnwidth}\centering
\textbf{Média Expectativa de Vida}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Média Educação}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Média PIB}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Média Estabilidade Política}\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Grupos}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{SQ}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Países}\strut
\end{minipage} & \begin{minipage}[b]{0.27\columnwidth}\centering
\textbf{Média Expectativa de Vida}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Média Educação}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Média PIB}\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright
\textbf{Média Estabilidade Política}\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.09\columnwidth}\raggedright
\(n_1=3\)\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,0257\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
Reino Unido, França, Uruguai\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\centering
0,8633\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,960\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,860\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
1,063\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.09\columnwidth}\raggedright
\(n_2=7\)\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
2,187\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
Colômbia, Paraguai, Nigéria, Senegal, Serra Leoa, Angola, Etiópia\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\centering
0,473\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,524\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,463\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
-1,154\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.09\columnwidth}\raggedright
\(n_3=6\)\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,748\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
Argentina, Cuba, Brasil, Egito, Moçambique, China\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\centering
0,678\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,740\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,622\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,315\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.09\columnwidth}\raggedright
\(n_4=5\)\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,047\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
Austrália, Canadá, Estados Unidos, Japão, Cingapura\strut
\end{minipage} & \begin{minipage}[t]{0.27\columnwidth}\centering
0,896\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,950\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
0,936\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright
1,258\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}cc@{}}
\caption{\label{tab:exkmeans3} Análise da qualidade dos grupos formados.}\tabularnewline
\toprule
\textbf{SSR (Soma de Quadrados Residual, soma dos grupos)} & 3,008\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{SSR (Soma de Quadrados Residual, soma dos grupos)} & 3,008\tabularnewline
\midrule
\endhead
\textbf{SSB (Soma de Quadrados entre os \(g\) grupos)} & 22,757\tabularnewline
\textbf{SST (Soma de Quadrados Total)} & 25,765\tabularnewline
\textbf{\(R^2=SSB/SST\)} & 88,3\%\tabularnewline
\bottomrule
\end{longtable}

Podemos avaliar um bom modelo pelo seu \(R^2\), vale lembrar que o algoritmo foi aplicado para a escolha aleatória de centróides. O que pode variar o resultado de acordo com o processo. Por isso muitas vezes, os pesquisadores utilizam mais de um método para classificações para que se possa comparar e ter consistência em sua pesquisa. Caso o pesquisador verifique e valide estas classificações, pode-se aplicar novos estudos por exemplo, para cada conjunto de países, desde análise de regressão à diversos outros métodos.

\hypertarget{muxe9todo-de-fuzzy-c-muxe9dias-c-means}{%
\subsubsection{\texorpdfstring{Método de Fuzzy C-Médias (\emph{C-Means})}{Método de Fuzzy C-Médias (C-Means)}}\label{muxe9todo-de-fuzzy-c-muxe9dias-c-means}}

O método de Fuzzy \citep{bezdek1981objective} também é um método iterativo que requer do pesquisador pré-estabelecer do número de grupos, como \emph{K-means}. Este método procura a partição que minimiza a função objetivo, expressa por:

\begin{equation}
J=\displaystyle \sum^c_{i=l} \sum^n_{j=l} (u_{ij}^m d(X_j,V_i))
 \label{eq:cmeansobjetivo}
\end{equation}

em que \(V_i\) é a semente (protótipo ou centróide ponderado) do conglomerado \(i=1,2,...,c\), \(m>1\) é o parâmetro Fuzzy, quanto mais alto for, mais difuso será o cluster no final (geralmente usam-se \(m=2\)); \(u_{ij}\) é a probabilidade de que o elemento \(X_j\) pertença ao congomerado com a semente \(V_i\) e \(d\) é a distância (método escolhido pelo pesquisador, geralmente Euclidiana).

A função \(J\) \eqref{eq:cmeansobjetivo} é minimizada quando as probabilidades \(u_{ij}\) e a semente \(V_i\) são definidas como:

\begin{equation}
u_{ij}=\Big[\displaystyle \sum^c_{k=1}\Big(\frac{d(X_j,V_i)}{d(X_j,V_k)}\Big)^{2/(m-1)}\Big]^{-1}
 \label{eq:cmeansprob}
\end{equation}

\begin{equation}
V_{i}=\displaystyle \frac{\sum^n_{j=1}(u_{ij})^m X_j}{\sum^n_{j=1}(u_{ij})^m} 
\label{eq:cmeanssemente}
\end{equation}

em que \(i=1,2...,c\) e \(j=1,2,...n\). Com \(u_{ij}\) seguindo uma distribuição entre 0 e 1 e os protótipos vão se modificando a cada iteração. O algoritmo é interrompido quando a distância entre os protótipos de uma iteração em relação à anterior é menor ou igual a um erro \(\mu\) estabelicido pelo pesquisador, ou seja, os vetores \(V_t\) e \(V_{t+1}\) da iterações \(t\) e \(t+1\) que guardam as sementes precisam que: \(d(V_t,V_{t+1})<\mu\).

Para cada elemento amostral, este método estima uma probabilidade de que o este elemento pertença a cada um dos \emph{clusters} \(c\) da partição. Podemos então encontrar elementos amostrais que se assemelham a mais de um dos \(c\) grupos. Alguns pesquisadores utilizam como critério de seleção para qual \emph{cluster} irá pertencer de acordo com o que tenha a maior probabilidade.

Utilizando o mesmo conjunto de dados utilizado no método K-Médias e aplicarmos o método de Fuzzy C-Médias, supondo \(m=2\) e com \emph{cluster} pré-estabelecido, obtemos seus resultados e alocando-os com base no critério de maior probabildade.

\begin{longtable}[]{@{}llllll@{}}
\caption{\label{tab:excmeans} Resultado obtido pelo método de C-Médias. Utilizando como critério de alocar ao grupo pela maior probabilidade.}\tabularnewline
\toprule
Países & Prob. \(C_1\) & Prob. \(C_2\) & Prob. \(C_3\) & Prob. \(C_4\) & Prob. \(C_5\)\tabularnewline
\midrule
\endfirsthead
\toprule
Países & Prob. \(C_1\) & Prob. \(C_2\) & Prob. \(C_3\) & Prob. \(C_4\) & Prob. \(C_5\)\tabularnewline
\midrule
\endhead
Reino Unido & 0,864 & 0,026 & 0,063 & 0,027 & 0,020\tabularnewline
Austrália & 0,776 & 0,044 & 0,098 & 0,046 & 0,035\tabularnewline
Canadá & 0,802 & 0,039 & 0,087 & 0,041 & 0,031\tabularnewline
EstadosUnidos & 0,842 & 0,031 & 0,071 & 0,032 & 0,024\tabularnewline
Japão & 0,836 & 0,032 & 0,073 & 0,033 & 0,025\tabularnewline
França & 0,767 & 0,043 & 0,110 & 0,046 & 0,034\tabularnewline
Cingapura & 0,625 & 0,076 & 0,158 & 0,080 & 0,061\tabularnewline
Argentina & 0,228 & 0,098 & 0,500 & 0,103 & 0,071\tabularnewline
Uruguai & 0,636 & 0,066 & 0,177 & 0,070 & 0,051\tabularnewline
Cuba & 0,135 & 0,158 & 0,447 & 0,160 & 0,100\tabularnewline
Colômbia & 0,071 & 0,310 & 0,103 & 0,184 & 0,332\tabularnewline
Brasil & 0,123 & 0,068 & 0,685 & 0,075 & 0,049\tabularnewline
Paraguai & 0,048 & 0,557 & 0,080 & 0,162 & 0,152\tabularnewline
Egito & 0,120 & 0,121 & 0,533 & 0,144 & 0,082\tabularnewline
Nigéria & 0,024 & 0,103 & 0,035 & 0,081 & 0,757\tabularnewline
Senegal & 0,035 & 0,165 & 0,060 & 0,631 & 0,108\tabularnewline
Serra Leoa & 0,057 & 0,196 & 0,083 & 0,207 & 0,457\tabularnewline
Angola & 0,084 & 0,221 & 0,113 & 0,196 & 0,386\tabularnewline
Etiópia & 0,054 & 0,172 & 0,093 & 0,547 & 0,134\tabularnewline
Moçambique & 0,149 & 0,177 & 0,285 & 0,253 & 0,136\tabularnewline
China & 0,061 & 0,041 & 0,823 & 0,046 & 0,029\tabularnewline
\bottomrule
\end{longtable}

Portanto ficará:

\begin{longtable}[]{@{}lll@{}}
\caption{\label{tab:excmeans2} Quantidade de Países por grupo e Soma de Quadrados por grupo.}\tabularnewline
\toprule
\begin{minipage}[b]{0.30\columnwidth}\raggedright
\textbf{Grupos}\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\raggedright
\textbf{Países}\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\raggedright
\textbf{SQ}\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.30\columnwidth}\raggedright
\textbf{Grupos}\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\raggedright
\textbf{Países}\strut
\end{minipage} & \begin{minipage}[b]{0.30\columnwidth}\raggedright
\textbf{SQ}\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.30\columnwidth}\raggedright
\(n_1=8\)\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Reino Unido, Austrália, Canadá, Estados Unidos, Japão, França, Cingapura, Uruguai\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
0,157\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
\(n_2=1\)\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Paraguai\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
0,000\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
\(n_3=6\)\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Argentina,Cuba, Brasil, Egito, Moçambique, China\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
0,748\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
\(n_4=2\)\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Senegal, Etiópia\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
0,030\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.30\columnwidth}\raggedright
\(n_5=4\)\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
Colômbia, Nigéria, Serra Leoa, Angola\strut
\end{minipage} & \begin{minipage}[t]{0.30\columnwidth}\raggedright
0,763\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}cc@{}}
\caption{\label{tab:exkmeans2} Análise da qualidade dos grupos formados.}\tabularnewline
\toprule
\textbf{SSR (Soma de Quadrados Residual, soma dos grupos)} & 1,698\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{SSR (Soma de Quadrados Residual, soma dos grupos)} & 1,698\tabularnewline
\midrule
\endhead
\textbf{SSB (Soma de Quadrados entre os \(g\) grupos)} & 20,983\tabularnewline
\textbf{SST (Soma de Quadrados Total)} & 22,681\tabularnewline
\textbf{\(R^2=SSB/SST\)} & 0,925\%\tabularnewline
\bottomrule
\end{longtable}

Tivemos um resultado interessante com um bom valor de \(R^2\) e próximo ao do exemplo anterior, entretanto seria importante dar uma atenção maior em alguns países, visto que suas probabilidades para a seleção de \emph{cluster} são bem semelhantes para Colômbia em \(n_2 (0,310)\) e \(n_5 (0,332)\) e Moçambique \(n_3=0,285\) e \(n_4=0,253\). Poderíamos testar com novas estratégias, novas quantidades de \emph{clusters} ou alguns métodos de avaliação para que se avalie e torne mais consistente a análise. Em caso de variáveis com alta probabilidade não teremos dúvidas sobre sua alocação. O início da seleção de centróides foi formulado de forma aleatória para este exemplo. Recomendo-o o leitor retornar ao exemplo de K-médias e comparar a este ou até mesmo com Análise de Componentes Principais. Entenda que são metodologias diferentes com combinações de estratégias diferentes (desde medidas de distância como Euclidiana, método de análise multivariada, tipo de seleção de centróides, etc), podemos combinar e comparar todas estas técnicas para termos consistências em nossas pesquisas.

Em \ref{valid} serão apresentados outros métodos para medir o desempenho e validar seu modelo.

\hypertarget{knn-k-vizinhos-mais-pruxf3ximos-k-nearest-neighbors}{%
\section{\texorpdfstring{KNN: K-Vizinhos Mais Próximos (\emph{K-Nearest Neighbors})}{KNN: K-Vizinhos Mais Próximos (K-Nearest Neighbors)}}\label{knn-k-vizinhos-mais-pruxf3ximos-k-nearest-neighbors}}

Uma metodologia muito conhecida e utilizada, referida na literatura de \citep{bhattacharya1981application} e \citep{bhattacharya2005geometric}. O \textbf{K-Vizinhos Mais Próximos}, do inglês \textbf{\emph{K-Nearest Neighbors} (KNN)}, é um classificador simples. O conjunto de treinamento é formado por vetores com \(n\)-dimensões no qual cada elemento deste conjunto retrata um ponto no espaço \(n\)-dimensional.

Vamos supor que temos um conjunto de dados repartido em duas classes: doentes e não doentes. Com a entrada de mais um paciente para a análise, temos uma nova observação que ainda não está classificada. Dentro do conjunto de treinamento, o classificador KNN procura \(K\) elementos que estejam mais próximos deste elemento de classe desconhecida, ou seja, que tenham a menor distância. Após verificar quais são as classes desses \(K\) vizinhos e a classe mais frequente das observações próximas, será atribuída a classe deste elemento desconhecido. Por isso é denominado por K-Vizinhos Mais Próximos, onde \(K\) indica a quantidade de vizinhos próximos à observação nova no conjunto de dados.

Como já vimos, existe diversos métodos de calcular a distância entre as observações, algumas delas estão apresentadas em \ref{meddist}. Muitas vezes por ser um exaustivo processo computacional para calcular todas as distâncias entre as observações com a observação de classe desconhecida, é comum para que identifique vizinhos mais próximos, elaborar uma hiper-esfera de raio \(R\) que será decidido pelo pesquisador e selecionar os elementos que estão dentro desta hiper-esfera. Este processo torna muito mais rápido e barato para o pesquisador, porém como desvantagem de haver possibilidade de não ter pontos dentro da hiper-esfera.

Na figura \ref{fig:knn1} temos como exemplo uma situação onde queremos saber se o novo paciente de um hospital está doente ou não. De acordo com pacientes anteriores, podemos reprentar graficamente com características \(X_1\) E \(X_2\) e identificar em qual classe cada um pertence. Após calcularmos as distância entre as observações e este elemento de classificação desconhecida, podemos identificar os vizinhos mais próximos. Supondo que temos três vizinhos (\(k=3\)) mais próximo do elemento de classe desconhecida, note que das três observações (duas azuis e uma vermelha) próximas do elemento, duas são consideradas ``doentes'' (cor azul) e uma ``não doente'' (vermelho).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/knn1} 

}

\caption{Exemplo gráfico de KNN com \(k=3\).}\label{fig:knn1}
\end{figure}



Por voto de maioria, com duas azuis e uma vermelha (2x1), este elemento será classificado pelo algoritmo como ``doente''.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/knn2} 

}

\caption{Exemplo gráfico de KNN com \(k=3\). Como a maioria é classificada como ``doente'' entre os vizinhos próximos do elemento, o elemento desconhecido também será.}\label{fig:knn2}
\end{figure}



\hypertarget{exknn}{%
\subsection{Exemplo}\label{exknn}}

1 - A EmprestaX, uma empresa de empréstimos nova em uma cidade, possui apenas alguns dias de serviço. Com intuito de melhorar na identificação de seu público alvo, a empresa pretende utilizar o algoritmo de KNN com base no histórico de seus primeiros clientes: Renda mensal, a quantidade de Contas atrasadas e sua classificação de ser ou não um possível cliente.

\begin{longtable}[]{@{}lllll@{}}
\caption{\label{tab:dadossrendaaknn} Dados históricos de clientes da EmprestaX com as variáveis Renda Mensal (R\$), Contas Atrasadas e Possível Cliente.}\tabularnewline
\toprule
\textbf{Cliente} & \textbf{A} & \textbf{B} & \textbf{C} & \textbf{D}\tabularnewline
\midrule
\endfirsthead
\toprule
\textbf{Cliente} & \textbf{A} & \textbf{B} & \textbf{C} & \textbf{D}\tabularnewline
\midrule
\endhead
\textbf{Renda Mensal} & R\$ 4000,00 & R\$ 1000,00 & R\$ 2500,00 & R\$ 2800,00\tabularnewline
\textbf{Contas Atrasadas} & 1 & 3 & 2 & 2\tabularnewline
\textbf{Possível Cliente} & Não & Sim & Sim & Não\tabularnewline
\bottomrule
\end{longtable}

Supondo um indivíduo E com uma renda mensal de R\$ 3300,00 , duas contas atrasadas. Pelo método de KNN, com k=3 vizinhos, qual será sua classificação de ser ou não um possível cliente para a EmprestaX?

Primeiramente, vamos observar os pontos em um gráfico:

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/knnex1} 

}

\caption{Gráfico gerado com base na tabela \ref{tab:dadossrendaaknn} e classificação para Possível Cliente em: Sim, Não, Não Classificado.}\label{fig:knnex1}
\end{figure}



Agora que observamos o gráfico, lembrando que pode haver diversos métodos para calcular a distância ou considerando uma hiper-esfera, vamos calcular a Distância Euclidiana entre as observações:
\[\mbox{Distância entre E e A=}\sqrt{(4000-3300)^2+(1-2)^2}=700,0007\]
Repetindo o mesmo processo para todas observações, obtemos:

\[D_{5x5}=\begin{bmatrix}\\
 &A&B&C&D&E \\
 A&0&&&&\\
 B&3000,0007&0&&&\\
 C & 1500,0003& 1500,0003&0&&\\
 D& 1200,0004& 1800,0003& 300,0000&0&\\
 E& 700,0007& 2300,0002& 800,0000& 500,0000&0\\
\end{bmatrix}\]

Como queremos \(k=3\) vizinhos mais próximos do indivíduo E para que se possa classificá-lo, temos então:

\begin{longtable}[]{@{}llll@{}}
\toprule
& \textbf{A} & \textbf{C} & \textbf{D}\tabularnewline
\midrule
\endhead
\textbf{E} & 700,0007 & 800,0000 & 500,0000\tabularnewline
\textbf{Possível Cliente} & Não & Sim & Não\tabularnewline
\bottomrule
\end{longtable}

Portanto, pela maioria, temos que o indivído E não será considerado um possível cliente pelo algoritmo de KNN.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/knnex2} 

}

\caption{Gráfico gerado com base na tabela @tab:dadossrendaaknn e classificado conforme o algoritmo de KNN com \(k=3\) vizinhos próximos do elemento novo na amostra.}\label{fig:knnex2}
\end{figure}



Note que neste exemplo, caso fosse escolhido com \(k=4\) ou \(k=2\) vizinhos, haveria empate e necessitaria de alterarmos o valor de \(k\) ou utilizar algum outro método de classificação. Aumentar o número de observações para a amostra também é muito importante para que se treine seu modelo de Aprendizado de Máquina.

\hypertarget{ptIII}{%
\chapter{\texorpdfstring{Os métodos \emph{Ensemble}}{Os métodos Ensemble}}\label{ptIII}}

Os métodos \textbf{\emph{ensemble} (conjunto)} são algoritmos de aprendizado que constroem um conjunto de classificadores e combinam os resultados de cada modelo para classificar um novo modelo de exemplo \citep{dietterich2000ensemble}, obtendo um valor final único a fim de melhorar a precisão e estabilidade do modelo. Os mais conhecidos são as técnicas de \textbf{\emph{boosting}} \citep{freund1996experiments}, \textbf{\emph{bagging}} \citep{breiman1996bagging} e \textbf{\emph{Random Forest}} \citep{breiman2001random, liaw2002classification} e \textbf{\emph{Extra Trees}}.

Como é uma resposta agregada de outros modelos preditivos, tratamos de algoritmos mais complexos que necessitam de um custo computacional maior, mais tempo e com mais processos para que se tenha um desempenho melhor.

\hypertarget{bagging}{%
\section{\texorpdfstring{\emph{Bagging}}{Bagging}}\label{bagging}}

O método \emph{bagging} \citep{breiman1996bagging} é um dos métodos de algoritmos de aprendizado de máquinas mais antigos. Este método utiliza amostras \emph{bootstrap} - amostragem com reposição no qual por meio do conjunto de treinamento inicial, seleciona-se aleatoriamente exemplos para um novo subconjunto de treinamento \citep{oshiro2013abordagem}.

Na técnica \emph{bagging}, portanto, diferentes subconjuntos \(T_k\) são aleatóriamente elaborados, com reposição, a partir do original e tem como idéia básica criar classificadores a partir de um conjunto de dados de treinamento com distribuição uniforme de probabilidades. Cada amostra possui o mesmo tamanho da base de dados originais e por ser \emph{bootstrap} alguns elementos podem aparecer repetidamente, ao passo que alguns podem ser que não estejam presentes no conjunto de treinamento. Cada subconjunto \(T_k\) é utilizado para treinar um classificador diferente \(\{h_k(x)\}\) e a classificação é definida pelo voto majoritário sobre todos os classificadores.

Conforme \citep{oshiro2013abordagem},este método consiste então em combinar \(T\) classificadores de \(N\) amostras geradas a partir do conjunto de treinamento \(M\) com \(R\) elementos. Cada classificador possui \(m\) elementos do conjunto de treinamento original de \(M\). Em vez de utilizar todas as observações do conjunto original do treinamento, escolhe elementos uniformemente com repetição e gerando \(k\) exemplos, que representam aspectos originais da base de dados. Em cada exemplo o classificador é gerado independentemente e a classificação de um novo elemento será executada sobre cada um dos \(T\) classificadores.

A cada tentativa \(t=1,2,...,T\), um conjunto de treinamento de tamanho \(N\) é amostrado do conjunto de treinamento original com o mesmo tamanho. Também a cada tentativa, um classificador \(C_i\) será gerado e no final um classificador \(C^*\) será formado através da geração de \(T\) classificadores obtidos em cada tentativa. Para uma amostra desconhecida, cada classificador \(C_i\) retorna seu voto e por fim o classificador \(C^*\) retornará a classe com o maior número de votos.

Vamos pensar numa aplicação deste método em árvores de decisão: primeiramente, o \emph{bagging} faz um sorteio de todas as amostras - escolhe uma, sorteia e escolhe outra sucessivamente - com reposição com, por exemplo, 70\% do total. Por isso podem vir elementos repetidos ou até mesmo omitir alguns (\emph{bootstrap}). Temos agora um \emph{dataset} para construirmos uma árvore de decisão. Da mesma forma, faz este processo com uma segunda árvore, uma terceira e assim por diante com um novo \emph{dataset} aleatório com \emph{bootstrap}. Note que temos então uma estimação para cada árvore diferente com dados diferentes sorteados. Um mesmo modelo de Aprendizado de Máquina com conjuntos diferentes. Com o voto majoritário (situação de classificação) ou uma média (como um caso de regressão) de todas as estimações dos classificadores \(C_i\), obtemos um classificador \(C^*\) final. O método \emph{bagging} é muito útil para evitar \emph{overfitting} (ver @ref(\#fitt)) com essa repetição do mesmo modelo de Aprendizado de Máquina. Importante notar que ele é um método para ser aplicado em algum modelo de Aprendizado de Máquina, por exemplo, pode-se optar pelo algoritmo de Regressão Linear, KNN, árvore de decisão ou em alguma técnica de mineração de dados.

O método \emph{bagging} é muito útil para evitar \emph{overfitting} (ver @ref(\#fitt)) pois repetimos o modelo várias vezes com vários conjuntos aleatórios e situações com novos esimadores de treino. Ao entrar novos dados para o teste, ele terá um desempenho semelhante. Importante notar que ele é um método para ser aplicado em algum modelo de Aprendizado de Máquina, por exemplo, pode-se optar pelo algoritmo de Regressão Linear, KNN, árvore de decisão ou em alguma técnica de mineração de dados.

\hypertarget{boost}{%
\section{\texorpdfstring{\emph{Boosting}}{Boosting}}\label{boost}}

técnicas de \textbf{\emph{boosting}} \citep{freund1996experiments},

\hypertarget{rf}{%
\section{\texorpdfstring{Floresta Aleatória - \emph{Random Forest}}{Floresta Aleatória - Random Forest}}\label{rf}}

A \textbf{Floresta Aleatória}, do inglês \textbf{\emph{Random Forest}} \citep{breiman2001random, liaw2002classification}, é um classificador composto de classificadores projetados especialmente para árvores de decisão \(\{h_k(X),k=1,2,...,L.\}\) onde \(T_k\) são amostras aleatórias independentes e identicamente distribuídas e que cada árvore decide a classe mais popular para a entrada de \(X\) (baixa correlação entre as árvores) . Vetores aleatórios são gerados a partir de uma distribuição e probabilidade fixa sobre o vetor de entrada inicial. A precisão da Floresta Aleatória é medida probabilísticamente em termos de margem do classificador, dado um conjunto de classificadores \(h_1(x), h_2(x),...,h_k(x)\), e um conjunto de treinamento aleatório a partir do vetor \(Y\), \(X\) \citep{gomez2012random}.

Como mencionado em \ref{decisiontree}, as Árvores de Decisão tendem a serem sensíveis à amostra de treinamento (ruídos). As Florestas Aleatórias buscam sanar este tipo de problema. A Floresta Aleatória é uma variação de \emph{Bagging}, onde na construção da árvore, apenas um subconjunto aleatório das características participa da subdivisão de um nó. Pode-se melhorar a acurácia do modelo por meio da parametrização, que traz uma maior variação entre as árvores (mais estável que \emph{bagging}).

Durante as construções das árvores, utiliza-se para medirmos o erro, o \textbf{\emph{out of bag} (OOB)}. Diferentemente dos erros tradicionais estimados (como validação cruzada, por exemplo), cada árvore de decisão dessa floresta construída a partir de um subconjunto (aleatório) de treinamento, pode ser testada com os exemplos que sobram (de fora) da classificação (exemplos \emph{out of bag}). O próprio treinamento da Floresta Aleatória fornece uma estimativa de erro que denomina-se \textbf{erro \emph{out of bag} }.

Um ótimo exemplo, elaborado e apresentado pela Ariane Machado Lima em uma de suas aulas online na Universidade de São Paulo (USP) sobre Florestas Aleatórias e o \emph{out of bag} foi: imagine uma amostra de treinamento com duas classes e \(n=18\) observações, como um dos parâmetros a serem definidos a quantidade de árvores de de decisões \(n\_estim=4\) e amostras \emph{bootstrap} (reposição) com \(obs=10\) observações aleatórias em cada árvore que podem ou não serem repetidas.

Nesta amostra de treinamento será verificado quais elementos que situam-se fora de cada árvore composta por 10 observações (\emph{OOB}) e quantas vezes fora para selecionar as árvores. Por exemplo, nesta mesma situação vamos supor que das três árvores de decisão, a observação 1 encontra-se dentro de uma árvore e \emph{OOB} nas três restantes. Como a maioria das árvores não encontra-se esta observação específica, elas vão ditar a classificação desta observação (votação por maioria que pode acertar ou errar). Ao caso contrário da observação 2, por exemplo, encontra-se apenas em uma \emph{OOB} e em três árvores de decisão. Portanto a \emph{OOB} irá decidir a classificação desta observação. Assim sucessivamente até finalizar a contagem. Para as observações que não se encontram em nenhuma amostra, não serão contabilizadas no erro.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{G:/Hiro/Documents/Meus feitos/Livro ML/bookdown-demo-master/Figuras/outofbag} 

}

\caption{Exemplificação de \emph{out of bag} \citep{machadousprf}.}\label{fig:outofbag}
\end{figure}



Para cada momento que temos 0 e 1 para classificar (ou até por regressão) cada elemento que estavam \emph{OOB}, calcula-se a média das previsões como estimação de erro \emph{out of bag}. Lembrando que permanece a medida de impureza na elaboração das árvores, como o índice de gini por exemplo.

Podemos dizer então que o erro \emph{OOB} é o erro médio de predição em cada amostra de treinamento \(X_i\), no qual na construção de uma amostra-árvore haverá um conjunto de amostra de \emph{bootstrap} (\emph{in the bag}) e outro com dados não escolhidos no processo da amostragem (\emph{out of bag}). Na construção da floresta (\(n\) amostra-árvores) muitos exemplos de \emph{bootstrap} e \emph{OOB} elaborados. Estes conjuntos \emph{OOB} podem ser agrupados em um conjunto de dados. Ao considerar \(Y\) como a classe com a maioria dos votos, todas as vezes em que a observação foi considerada \emph{OOB}, a proporção de vezes que \(Y\) não for igual à verdadeira classe da observação, será a estimativa de erro \emph{OOB}. Para o caso de problema de regressão, utiliza-se o método erro quadrado médio (MSE).

O procedimento \emph{bootstrap} traz um melhor desempenho do modelo pois diminui a variância sem aumentar o viés, ou seja, embora as previsões de uma única árvore seja altamente sensível ao ruído em seu treinamento, a média de muitas árvores não será - desde que não sejam correlacionadas. Para estimarmos a incerteza das previsões de todas as árvores de regressão em \(x'\), seu desvio padrão, podemos por meio da equação:

\begin{equation}
\sigma = \sqrt{\frac{\sum^B_{b=1}(f_b(x')-\hat{f})^2}{B-1}}
\label{eq:desviorf}
\end{equation}

onde o \(B\) é o número de árvores, um parâmetro livre que pode variar dependendo do conjunto de treinamento e a decisão do pesquisador.

Para calcularmos a importância de um atributo (\emph{score}), para cada elemento \(e\) e para cada árvore \(t\), permuta-se os valores de \(e\) nos exemplos OOB de \(t\), ou seja: após permutarmos cada árvore terá uma nova votação em relação a cada elemento \(e\) \emph{OOB}, com novas classificações e novos erros \(OOB_p\). Podendo agora calcular a importância da variável \(e\) e analizá-la como uma taxa de acréscimo sobre o erro.

\begin{equation}
\mbox{Importância de} \ e = \frac{(OOB_p-OOB)}{OOB}
\label{eq:impc}
\end{equation}

O erro tradicional, geralmente utiliza-se todas as árvores como vantagem, porém é preciso dividir a amostra inicial em treinamento e teste. O \emph{out of bag} utiliza toda a amostra, mas muitas vezes superestima o erro. Com a monitoração adequada dos parâmetros, como profundidade de cada árvore, número de atributos sorteados para cada divisão (com reposição), número de árvores, de nós por exemplo, pode ser melhorada esta superstimação e trazendo um bom modelo para o pesquisador.

Para aumentar a aleatoriedade no modelo. É possível utilizar o \emph{bagging} em conjunto, onde cada novo conjunto de treinamento é criado por substituição a partir do novo vetor de entrada inicial. Uma nova árvore é induzida a partir de um novo conjunto de treinmaneto usando a seleção aleatória de atributos \citep{gomez2012random}. Conforme \citep{breiman2001random}, o uso do \emph{bagging} melhora o desempenho quando características aleatórias são utilizadas; este método também pode ser usado para fornecer estimativas contínuas do erro generalizado do conjunto combinado de árvores, bem como estimativas para força e correlação com o estimador \emph{OOB}. A força pode ser interpretada como medida de desempenho para cada árvore, uma árvore com uma baixa taxa de erro é um classificador forte. Aumentando a força das árvores individuais, reduz-se a taxa de erro de uma floresta, assim como a baixa correlação tende a diminuir \citep{oshiro2013abordagem}.

Um algoritmo que se tornou bem conhecido e bastante similar à Floresta Aleatória, é o \textbf{\emph{Extra-Trees}} \citep{geurts2006extremely}. Neste caso, é adicionado mais uma camada de aleatoriedade para montar as árvores. O algoritmo utiliza como estratégia aleatória, na montagem dos nós ao invés de utilizar métricas como ganho de informação. Este acréscimo de aleatoriedade faz com que tenha uma diminuição no viés com menor custo computacional e dispêndio de tempo \citep{machado2020avaliaccao}.

\hypertarget{redesneurais}{%
\chapter{Redes Neurais}\label{redesneurais}}

  \bibliography{book.bib,packages.bib}

\end{document}
