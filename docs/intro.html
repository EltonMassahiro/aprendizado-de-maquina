<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 1 Introdução | Machine Learning</title>
  <meta name="description" content="Tutorial de Machine Learning." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 1 Introdução | Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Tutorial de Machine Learning." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 1 Introdução | Machine Learning" />
  
  <meta name="twitter:description" content="Tutorial de Machine Learning." />
  

<meta name="author" content="Elton Massahiro Saito Loures" />


<meta name="date" content="2020-12-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="i-a.html"/>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefácio</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#por-que-ler-esse-livro"><i class="fa fa-check"></i><b>0.1</b> Por que ler esse livro?</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#estrutura"><i class="fa fa-check"></i><b>0.2</b> Estrutura</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#informações-a-respeito-do-conteúdo"><i class="fa fa-check"></i><b>0.3</b> Informações a respeito do conteúdo</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#agradecimentos"><i class="fa fa-check"></i><b>0.4</b> Agradecimentos</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introdução</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#dicas-de-estudo"><i class="fa fa-check"></i><b>1.1</b> Dicas de estudo</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#dicio"><i class="fa fa-check"></i><b>1.2</b> Dicionário</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="i-a.html"><a href="i-a.html"><i class="fa fa-check"></i><b>2</b> Inteligência Artificial (IA)</a><ul>
<li class="chapter" data-level="2.1" data-path="i-a.html"><a href="i-a.html#o-que-é-ia-de-onde-veio-esse-conceito"><i class="fa fa-check"></i><b>2.1</b> O que é IA? De onde veio esse conceito?</a></li>
<li class="chapter" data-level="2.2" data-path="i-a.html"><a href="i-a.html#a-arte-de-uma-ia"><i class="fa fa-check"></i><b>2.2</b> A arte de uma IA</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="vertentes-de-uma-ia-e-fundamentação-filosófica.html"><a href="vertentes-de-uma-ia-e-fundamentação-filosófica.html"><i class="fa fa-check"></i><b>3</b> Vertentes de uma IA e fundamentação filosófica</a></li>
<li class="chapter" data-level="4" data-path="machinelearning.html"><a href="machinelearning.html"><i class="fa fa-check"></i><b>4</b> O Aprendizado de Máquina</a><ul>
<li class="chapter" data-level="4.1" data-path="machinelearning.html"><a href="machinelearning.html#como-a-máquina-aprende"><i class="fa fa-check"></i><b>4.1</b> Como a máquina aprende?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fundamentamos.html"><a href="fundamentamos.html"><i class="fa fa-check"></i><b>5</b> Fundamentamos</a><ul>
<li class="chapter" data-level="5.1" data-path="fundamentamos.html"><a href="fundamentamos.html#medidasimport"><i class="fa fa-check"></i><b>5.1</b> Medidas de Importância</a><ul>
<li class="chapter" data-level="5.1.1" data-path="fundamentamos.html"><a href="fundamentamos.html#medinfo"><i class="fa fa-check"></i><b>5.1.1</b> Medidas de Informação</a></li>
<li class="chapter" data-level="5.1.2" data-path="fundamentamos.html"><a href="fundamentamos.html#meddist"><i class="fa fa-check"></i><b>5.1.2</b> Medidas de Similaridade e Dissimilaridade</a></li>
<li class="chapter" data-level="5.1.3" data-path="fundamentamos.html"><a href="fundamentamos.html#medidasdep"><i class="fa fa-check"></i><b>5.1.3</b> Medidas de Dependência</a></li>
<li class="chapter" data-level="5.1.4" data-path="fundamentamos.html"><a href="fundamentamos.html#medidas-de-precisão"><i class="fa fa-check"></i><b>5.1.4</b> Medidas de Precisão</a></li>
<li class="chapter" data-level="5.1.5" data-path="fundamentamos.html"><a href="fundamentamos.html#medidas-de-consistência"><i class="fa fa-check"></i><b>5.1.5</b> Medidas de consistência</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="fundamentamos.html"><a href="fundamentamos.html#testesanova"><i class="fa fa-check"></i><b>5.2</b> Teste de hipóteses e Análise de Variância</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="preprocesso.html"><a href="preprocesso.html"><i class="fa fa-check"></i><b>6</b> Pré-processamento</a><ul>
<li class="chapter" data-level="6.1" data-path="preprocesso.html"><a href="preprocesso.html#dados-faltantes-e-a-limpeza-de-dados"><i class="fa fa-check"></i><b>6.1</b> Dados faltantes e a Limpeza de dados</a><ul>
<li class="chapter" data-level="6.1.1" data-path="preprocesso.html"><a href="preprocesso.html#tratamento-de-dados-faltantes"><i class="fa fa-check"></i><b>6.1.1</b> Tratamento de dados faltantes</a></li>
<li class="chapter" data-level="6.1.2" data-path="preprocesso.html"><a href="preprocesso.html#outlier"><i class="fa fa-check"></i><b>6.1.2</b> <em>Outlier</em></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="preprocesso.html"><a href="preprocesso.html#transformação-de-dados"><i class="fa fa-check"></i><b>6.2</b> Transformação de dados</a><ul>
<li class="chapter" data-level="6.2.1" data-path="preprocesso.html"><a href="preprocesso.html#tipos-de-datasets"><i class="fa fa-check"></i><b>6.2.1</b> Tipos de <em>datasets</em></a></li>
<li class="chapter" data-level="6.2.2" data-path="preprocesso.html"><a href="preprocesso.html#normpadro"><i class="fa fa-check"></i><b>6.2.2</b> Normalização e padronização</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="preprocesso.html"><a href="preprocesso.html#features-selection---seleção-de-atributos-sa"><i class="fa fa-check"></i><b>6.3</b> Features Selection - Seleção de atributos (SA)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html"><i class="fa fa-check"></i><b>7</b> Algoritmos de Aprendizagem - Parte I</a><ul>
<li class="chapter" data-level="7.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#naive-bayes"><i class="fa fa-check"></i><b>7.1</b> Naive Bayes</a><ul>
<li class="chapter" data-level="7.1.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exbayes"><i class="fa fa-check"></i><b>7.1.1</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#reg"><i class="fa fa-check"></i><b>7.2</b> Regressão</a><ul>
<li class="chapter" data-level="7.2.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#reglin"><i class="fa fa-check"></i><b>7.2.1</b> Análise de Regressão Linear Simples</a></li>
<li class="chapter" data-level="7.2.2" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#regmult"><i class="fa fa-check"></i><b>7.2.2</b> Regressão Linear Múltipla</a></li>
<li class="chapter" data-level="7.2.3" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#mpl"><i class="fa fa-check"></i><b>7.2.3</b> Modelo de Probabilidade Linear (MPL)</a></li>
<li class="chapter" data-level="7.2.4" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exemplo1reg"><i class="fa fa-check"></i><b>7.2.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#GD"><i class="fa fa-check"></i><b>7.3</b> Gradiente Descendente (GD)</a><ul>
<li class="chapter" data-level="7.3.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exemplos"><i class="fa fa-check"></i><b>7.3.1</b> Exemplos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptII.html"><a href="ptII.html"><i class="fa fa-check"></i><b>8</b> Algoritmos de Aprendizagem - Parte II</a><ul>
<li class="chapter" data-level="8.1" data-path="ptII.html"><a href="ptII.html#svm"><i class="fa fa-check"></i><b>8.1</b> Máquina de Vetores Suporte - <em>Support Vectors Machine</em></a><ul>
<li class="chapter" data-level="8.1.1" data-path="ptII.html"><a href="ptII.html#classificação-de-padrões-linearmente-separáveis"><i class="fa fa-check"></i><b>8.1.1</b> Classificação de Padrões Linearmente Separáveis</a></li>
<li class="chapter" data-level="8.1.2" data-path="ptII.html"><a href="ptII.html#margmax"><i class="fa fa-check"></i><b>8.1.2</b> Hiperplano de Separação Ótima / Margem Máxima</a></li>
<li class="chapter" data-level="8.1.3" data-path="ptII.html"><a href="ptII.html#classificação-de-padrões-não-linearmente-separáveis"><i class="fa fa-check"></i><b>8.1.3</b> Classificação de Padrões Não-Linearmente Separáveis</a></li>
<li class="chapter" data-level="8.1.4" data-path="ptII.html"><a href="ptII.html#exemplosvm"><i class="fa fa-check"></i><b>8.1.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ptII.html"><a href="ptII.html#decisiontree"><i class="fa fa-check"></i><b>8.2</b> Árvore de Decisão (<em>Decision Tree</em>)</a><ul>
<li class="chapter" data-level="8.2.1" data-path="ptII.html"><a href="ptII.html#extree"><i class="fa fa-check"></i><b>8.2.1</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ptII.html"><a href="ptII.html#elastic-net"><i class="fa fa-check"></i><b>8.3</b> Elastic Net</a></li>
<li class="chapter" data-level="8.4" data-path="ptII.html"><a href="ptII.html#knn"><i class="fa fa-check"></i><b>8.4</b> KNN</a></li>
<li class="chapter" data-level="8.5" data-path="ptII.html"><a href="ptII.html#AC"><i class="fa fa-check"></i><b>8.5</b> Análise de Componentes Principais</a><ul>
<li class="chapter" data-level="8.5.1" data-path="ptII.html"><a href="ptII.html#autovalores-e-autovetores"><i class="fa fa-check"></i><b>8.5.1</b> Autovalores e Autovetores</a></li>
<li class="chapter" data-level="8.5.2" data-path="ptII.html"><a href="ptII.html#estatísticas"><i class="fa fa-check"></i><b>8.5.2</b> Estatísticas</a></li>
<li class="chapter" data-level="8.5.3" data-path="ptII.html"><a href="ptII.html#a-acp"><i class="fa fa-check"></i><b>8.5.3</b> A ACP</a></li>
<li class="chapter" data-level="8.5.4" data-path="ptII.html"><a href="ptII.html#exemplocp"><i class="fa fa-check"></i><b>8.5.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="ptII.html"><a href="ptII.html#análise-de-agrupamentos---clusters"><i class="fa fa-check"></i><b>8.6</b> Análise de Agrupamentos - Clusters</a><ul>
<li class="chapter" data-level="8.6.1" data-path="ptII.html"><a href="ptII.html#técnicas-hierárquicas-aglomerativas"><i class="fa fa-check"></i><b>8.6.1</b> Técnicas Hierárquicas Aglomerativas</a></li>
<li class="chapter" data-level="8.6.2" data-path="ptII.html"><a href="ptII.html#número-final-de-grupos"><i class="fa fa-check"></i><b>8.6.2</b> Número final de grupos</a></li>
<li class="chapter" data-level="8.6.3" data-path="ptII.html"><a href="ptII.html#técnicas-não-hierárquicas"><i class="fa fa-check"></i><b>8.6.3</b> Técnicas Não Hierárquicas</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="ptII.html"><a href="ptII.html#modelos-nivel-iii"><i class="fa fa-check"></i><b>8.7</b> modelos nivel III</a></li>
<li class="chapter" data-level="8.8" data-path="ptII.html"><a href="ptII.html#grad-boosting---estudar-boosting-e-bagging-dentro-de-emseamble"><i class="fa fa-check"></i><b>8.8</b> grad boosting -&gt; estudar boosting e bagging dentro de emseamble</a></li>
<li class="chapter" data-level="8.9" data-path="ptII.html"><a href="ptII.html#redes-neurais"><i class="fa fa-check"></i><b>8.9</b> Redes Neurais</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="valid.html"><a href="valid.html"><i class="fa fa-check"></i><b>9</b> Validação de um modelo</a><ul>
<li class="chapter" data-level="9.1" data-path="valid.html"><a href="valid.html#fitt"><i class="fa fa-check"></i><b>9.1</b> <em>Overfitting, Underfitting</em></a><ul>
<li class="chapter" data-level="9.1.1" data-path="valid.html"><a href="valid.html#underfitting-no-cenário-underfitting-o-desempenho-já-é-ruim-no-próprio-treinamento-de-seu-algoritmo."><i class="fa fa-check"></i><b>9.1.1</b> <strong>Underfitting</strong>: No cenário underfitting, o desempenho já é ruim no próprio treinamento de seu algoritmo.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="valid.html"><a href="valid.html#validação-cruzada"><i class="fa fa-check"></i><b>9.2</b> Validação Cruzada</a></li>
<li class="chapter" data-level="9.3" data-path="valid.html"><a href="valid.html#como-escolher-um-bom-modelo"><i class="fa fa-check"></i><b>9.3</b> Como escolher um bom modelo?</a></li>
<li class="chapter" data-level="9.4" data-path="valid.html"><a href="valid.html#aocroc"><i class="fa fa-check"></i><b>9.4</b> AOC e ROC</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado com bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1">
<h1><span class="header-section-number">Capítulo 1</span> Introdução</h1>
<p>Caro leitor, se você veio até esse livro é bem provável que passou e/ou ainda passa pelas mesmas dificuldades que todo estudante interessado nessa área.</p>
<p>Ao elevado número de pesquisas que fiz para aprender o que era a Inteligência Artificial, o que era o <em>Machine Learning</em> (Aprendizado de Máquina) e todos os outros temas similares, é nítido que ainda não está totalmente definido o conceito de cada um. É um ramo novo na área acadêmica, na indústria e em todo o mercado, com diversos temas, diversos modelos matemáticos, diversos modelos computacionais, diversos <em>softwares</em>, diversas aplicações e em diversas áreas. Diversos “diversos”… E o mais assustador é que esse campo une todos esses “diversos”, tornando o universo <strong>caótico</strong> ainda maior. Quando destaco o termo “caótico”, refiro exatamente pela ironia deste mote, todo esse universo confuso é aplicado em nosso cotidiano para organizar, analisar, diagnosticar e facilitar as coisas.</p>
<p>Poucos instruem como devemos enxergar todo esse cosmos que ao longo da história está passando por diversas construções para estruturar seu conceito. Com uma tentativa de trazer isso com base em artigos, livros, vídeos, podcasts e cursos, disponho este simples livro com o propósito de organizar a imagem que você, leitor, tem de Aprendizado de Máquina e entender os principais modelos utilizados tanto no meio acadêmico, quanto no mercado de trabalho.</p>
<div id="dicas-de-estudo" class="section level2">
<h2><span class="header-section-number">1.1</span> Dicas de estudo</h2>
<p>Não cabe a mim dizer como estudar, mas o que posso lhe aconselhar como principal ponto é a <strong>paciência</strong>. Temas como esse podem abranger qualquer campo, desde a filosofia até a área da saúde e portanto, do mesmo modo que se aplica a qualquer conteúdo, o mais importante é a base. Leia, releia, pesquise, veja vídeos, ouça um podcast, converse e discuta com colegas e professores a respeito. Não se cobre de que precisa aprender o mais rápido possível, mas preze a qualidade do estudo.</p>
<p>Com intuito de explicar sobre Aprendizado de Máquina. Na seção <strong>AQUI VOU COLOCAR A REFERENCIA DA SESSAO</strong>, para faciliar o leitor dependendo de sua demanda de conteúdo, busquei separar em subseções a lógica computacional e a matemática. Tornando mais prático para o público que não tem interesse no modelo matemático e que busca o conhecimento de determinado assunto quanto ao público que demanda esse conteúdo.</p>
</div>
<div id="dicio" class="section level2">
<h2><span class="header-section-number">1.2</span> Dicionário</h2>
<ul>
<li><p><strong>Escalares e Vetores:</strong></p></li>
<li><p><strong>Espaço Vetorial e Transformação Linear:</strong></p></li>
<li><p><strong>Assimetria e Curtose:</strong></p></li>
<li><p><strong>Variância e Desvio padrão (Erro padrão):</strong></p></li>
<li><p><strong>Covariância:</strong> A covariância mede a relação linear entre duas variáveis.
É possível utilizar a covariância para compreender a direção da relação entre as variáveis. Valores de covariância positivos indicam que valores acima da média de uma variável estão associados a valores médios acima da outra variável e abaixo dos valores médios são igualmente associado. Valores de covariância negativos indicam que valores acima da média de uma variável estão associados com valores médios abaixo da outra variável.</p></li>
<li><p><strong>Distribuição normal:</strong></p></li>
<li><p><strong>Distribuição binomial:</strong></p></li>
<li><p><strong>Disitrbuição de Poisson:</strong> <span class="citation">(Banzatto and Kronka <a href="#ref-banzatto1992experimentaccao">1992</a>)</span> Quando número de plantas daninhas por parcela, número de insetos capturados em armadilhas luminosas, número de pulgões ou ácaros por folhas, etc.</p></li>
<li><p><strong>Teorema de Bayes:</strong> quando tratamos de probabilidades, <span class="math inline">\(P(A|B)\)</span> e <span class="math inline">\(P(B|A)\)</span> podem ser parecidos, mas possuem grande diferença entre as probabilidades que representam. Por exemplo <span class="math inline">\(P(A|B)\)</span> pode se referir sobre a probabilidade de uma pessoa que cometeu um furto (B) ser condenada (A) e <span class="math inline">\(P(B|A)\)</span> seria a probabilidade de uma pessoa que foi condenada por furto ter efetivamente cometido um crime. A causa se torna o efeito e o efeito se torna a causa <span class="citation">(Freund <a href="#ref-freund2009estatistica">2009</a>)</span>.</p></li>
</ul>
<p>Pela regra geral de multiplicação que afirma que a probabilidade da ocorrência de dois eventos é o produto da probibilidade da ocorrência de um deles pela probabilidade condicional da ocorrência do outro evento, temos:</p>
<p><span class="math display" id="eq:multprob">\[\begin{equation} 
 P(A \bigcap B)= P(A). P(B|A) \  \mbox{ou} \ P(A \bigcap B)= P(B). P(A|B)
  \tag{1.1}
\end{equation}\]</span></p>
<p>Igualando ambas expressões, temos: $ P(A). P(B|A) = P(B). P(A|B)$ e portanto, divindo por <span class="math inline">\(P(B)\)</span>, obtém-se o Teorema de Bayes que descreve a probabilidade de um evento, baseado em um conhecimento a <em>priori</em> que pode estar relacionado ao evento:</p>
<p><span class="math display" id="eq:bayes">\[\begin{equation} 
 P(A|B) = \frac{P(A).P(B|A)}{P(B)}
  \tag{1.2}
\end{equation}\]</span></p>
<p>Para <span class="math inline">\(B_n\)</span> e <span class="math inline">\(A_k\)</span> atributos, podemos reescrever:</p>
<p><span class="math display" id="eq:bayesn">\[\begin{equation} 
 P(A_k|B_1,...,B_n) = \frac{P(A_k).P(B_1,...,B_n|A_k)}{P(B_1,...,B_n)}
  \tag{1.3}
\end{equation}\]</span></p>
<p><strong>Exemplo:</strong> este exemplo pode ser encontrado em <span class="citation">Freund (<a href="#ref-freund2009estatistica">2009</a>)</span>. Numa certa empresa, 4% dos homens e 1% das mulheres têm mais de 1,75m
de altura, respectivamente, sendo que 60% dos trabalhadores são mulheres. Um trabalhador é escolhido ao acaso.</p>
<ol style="list-style-type: upper-alpha">
<li>Qual a probabilidade de que tenha mais de 1,75m?</li>
</ol>
<p><em>Solução:</em> Temos de informação de que 60% dos trabalhadores são mulheres e que 1% delas possuem mais de 1,75m. Portanto 40% dos trabalhadores são homens, sendo 4% deles com mais de 1,75m. Logo temos que:
<span class="math display">\[P(&gt; 1, 75m) = (0, 04 . 0.4) + (0, 01 . 0.6) = 0, 022 \\ → 2, 2\% \ \mbox{ de probabilidade de que tenha mais de 1,75m.}\]</span></p>
<ol start="2" style="list-style-type: upper-alpha">
<li>E que seja homem dado que o trabalhador escolhido tenha mais de 1,75m?</li>
</ol>
<p><em>Solução:</em> pelo enunciado “que seja homem dado que o trabalhador escolhido tenha mais de 1,75m”, podemos perceber que já possuímos uma afirmação que já foi escolhido uma pessoa que tenha mais que 1,75m e queremos saber se é homem. Por meio da questão anterior sabemos a probabilidade P(&gt; 1,75m). Portanto:
<span class="math display">\[P(H| &gt; 1, 75m) = \frac{P(&gt; 1, 75m|H).P(H)}{P(&gt; 1, 75m)}=\frac{0,04.0,4}{0, 022} \]</span></p>
<p><span class="math display">\[→ 72,73\% \ \mbox{de probabilidade de ser homem dado que seja maior que 1,75m.}\]</span></p>
<ul>
<li><strong>Função de verossimilhança:</strong> a verossimilhança <span class="math inline">\(L\)</span> de um conjunto de parâmetros <span class="math inline">\(\theta\)</span>, com dada informação <span class="math inline">\(x\)</span>. É igual a probabilidade da mesma observação <span class="math inline">\(x\)</span> ter ocorrido dados os valores dos mesmos parâmetros <span class="math inline">\(\theta\)</span>. Conhecendo um parâmetro <span class="math inline">\(\theta\)</span>, a probabilidade condicional de <span class="math inline">\(x\)</span> é <span class="math inline">\(P(x|\theta)\)</span>, mas se o valor de <span class="math inline">\(x\)</span> é conhecido, pode-se realizar inferências sobre o valor de <span class="math inline">\(\theta\)</span> <span class="citation">(Bolfarine and Sandoval <a href="#ref-bolfarine2001introduccao">2001</a>)</span>.</li>
</ul>
<p><span class="math display" id="eq:fverossimilhanca">\[\begin{equation} 
 L(\theta |x)=P(x| \theta)
  \tag{1.4}
\end{equation}\]</span></p>
<p>Para “<span class="math inline">\(n\)</span>” valores:</p>
<p><span class="math display" id="eq:fsumverossimilhanca">\[\begin{equation} 
 L(\theta |x_1,..., x_n)=\prod_{i=1}^{n} P(x_i| \theta)
  \tag{1.5}
\end{equation}\]</span></p>
<p>Geralmente utiliza-se o logaritmo natural em verossimilhança <span class="math inline">\(L(\theta |x)=ln L(\theta|x)\)</span> como função suporte e facilitar em seu estudo.</p>
<p>Para facilitar a compreensão, considere a observação de que você esteja ouvindo barulho em sua sala de estar num dia de natal (observação <span class="math inline">\(x\)</span>), você parte da hipótese inicial que poderia ser o “Papai Noel” lhe entregando presentes (hipótese <span class="math inline">\(\theta\)</span>). A probabilidade de ser Noel lhe entregando presente apenas porque ouviu o barulho, isto é, <span class="math inline">\(P(\theta|x)\)</span> é baixa. No entanto o contrário, você com a afirmação de que é o Noel lhe entregando presentes, a probabilidade de haver barulho em sua sala de estar é bem alta, logo a verossimilhança <span class="math inline">\(L(\theta|x)=P(x|\theta)\)</span>.</p>
<ul>
<li><p><strong>Parâmetros:</strong> podem ser vistos como características númericas de um modelo ou população. Os valores não podem ser mensurados diretamente mas que podem ser estimados através dos dados de uma amostra.</p></li>
<li><p><strong>Paramétrico x Não Paramétrico:</strong></p></li>
<li><p><strong>Correlação:</strong></p></li>
<li><p><strong>Supervisionada x Não supervisionada:</strong></p></li>
<li><p><strong>Produto Interno:</strong></p></li>
<li><p><strong>Multiplicadores de Lagrange:</strong>*</p></li>
<li><p><strong>Karush-Kuhn-Tucker (KKT):</strong></p></li>
<li><p><strong>Bias:</strong>
<a href="https://iaexpert.academy/2020/09/28/importancia-do-bias-nas-redes-neurais/" class="uri">https://iaexpert.academy/2020/09/28/importancia-do-bias-nas-redes-neurais/</a></p></li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-banzatto1992experimentaccao">
<p>Banzatto, David Ariovaldo, and S do N Kronka. 1992. “Experimentação Agrı́cola.” <em>Jaboticabal: Funep</em> 2.</p>
</div>
<div id="ref-bolfarine2001introduccao">
<p>Bolfarine, Heleno, and Mônica Carneiro Sandoval. 2001. <em>Introdução à Inferência Estatı́stica</em>. Vol. 2. SBM.</p>
</div>
<div id="ref-freund2009estatistica">
<p>Freund, John E. 2009. <em>Estatı́stica Aplicada-: Economia, Administração E Contabilidade</em>. Bookman Editora.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="i-a.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
