<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 5 Validação de um modelo | Fundamentos de Machine Learning</title>
  <meta name="description" content="Entenda Machine Learning desde sua história até seus principais conceitos." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 5 Validação de um modelo | Fundamentos de Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Entenda Machine Learning desde sua história até seus principais conceitos." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 5 Validação de um modelo | Fundamentos de Machine Learning" />
  
  <meta name="twitter:description" content="Entenda Machine Learning desde sua história até seus principais conceitos." />
  

<meta name="author" content="Elton Massahiro Saito Loures" />


<meta name="date" content="2021-03-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="preprocesso.html"/>
<link rel="next" href="Algoritmosaprendizagem.html"/>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefácio</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#por-que-ler-esse-livro"><i class="fa fa-check"></i><b>0.1</b> Por que ler esse livro?</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#estrutura"><i class="fa fa-check"></i><b>0.2</b> Estrutura</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#informações-a-respeito-do-conteúdo"><i class="fa fa-check"></i><b>0.3</b> Informações a respeito do conteúdo</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#agradecimentos"><i class="fa fa-check"></i><b>0.4</b> Agradecimentos</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="i-a.html"><a href="i-a.html"><i class="fa fa-check"></i><b>1</b> Inteligência Artificial (IA)</a><ul>
<li class="chapter" data-level="1.1" data-path="i-a.html"><a href="i-a.html#o-que-é-ia-de-onde-veio-esse-conceito"><i class="fa fa-check"></i><b>1.1</b> O que é IA? De onde veio esse conceito?</a></li>
<li class="chapter" data-level="1.2" data-path="i-a.html"><a href="i-a.html#a-arte-de-uma-ia"><i class="fa fa-check"></i><b>1.2</b> A arte de uma IA</a></li>
<li class="chapter" data-level="1.3" data-path="i-a.html"><a href="i-a.html#vertentes-de-uma-ia-e-fundamentação-filosófica"><i class="fa fa-check"></i><b>1.3</b> Vertentes de uma IA e fundamentação filosófica</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="machinelearning.html"><a href="machinelearning.html"><i class="fa fa-check"></i><b>2</b> O Aprendizado de Máquina</a><ul>
<li class="chapter" data-level="2.1" data-path="machinelearning.html"><a href="machinelearning.html#como-a-máquina-aprende"><i class="fa fa-check"></i><b>2.1</b> Como a máquina aprende?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="dicio.html"><a href="dicio.html"><i class="fa fa-check"></i><b>3</b> Uma breve revisão</a><ul>
<li class="chapter" data-level="3.1" data-path="dicio.html"><a href="dicio.html#um-pouco-de-álgebra-linear"><i class="fa fa-check"></i><b>3.1</b> Um pouco de Álgebra Linear</a></li>
<li class="chapter" data-level="3.2" data-path="dicio.html"><a href="dicio.html#um-pouco-de-estatística"><i class="fa fa-check"></i><b>3.2</b> Um pouco de Estatística</a></li>
<li class="chapter" data-level="3.3" data-path="dicio.html"><a href="dicio.html#medidasimport"><i class="fa fa-check"></i><b>3.3</b> Medidas de Importância</a><ul>
<li class="chapter" data-level="3.3.1" data-path="dicio.html"><a href="dicio.html#medidasdep"><i class="fa fa-check"></i><b>3.3.1</b> Medidas de Dependência</a></li>
<li class="chapter" data-level="3.3.2" data-path="dicio.html"><a href="dicio.html#medinfo"><i class="fa fa-check"></i><b>3.3.2</b> Medidas de Informação</a></li>
<li class="chapter" data-level="3.3.3" data-path="dicio.html"><a href="dicio.html#meddist"><i class="fa fa-check"></i><b>3.3.3</b> Medidas de Similaridade e Dissimilaridade</a></li>
<li class="chapter" data-level="3.3.4" data-path="dicio.html"><a href="dicio.html#medidas-de-precisão"><i class="fa fa-check"></i><b>3.3.4</b> Medidas de Precisão</a></li>
<li class="chapter" data-level="3.3.5" data-path="dicio.html"><a href="dicio.html#medidas-de-consistência"><i class="fa fa-check"></i><b>3.3.5</b> Medidas de consistência</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="preprocesso.html"><a href="preprocesso.html"><i class="fa fa-check"></i><b>4</b> Pré-processamento</a><ul>
<li class="chapter" data-level="4.1" data-path="preprocesso.html"><a href="preprocesso.html#dados-faltantes-e-a-limpeza-de-dados"><i class="fa fa-check"></i><b>4.1</b> Dados faltantes e a Limpeza de dados</a><ul>
<li class="chapter" data-level="4.1.1" data-path="preprocesso.html"><a href="preprocesso.html#tratamento-de-dados-faltantes"><i class="fa fa-check"></i><b>4.1.1</b> Tratamento de dados faltantes</a></li>
<li class="chapter" data-level="4.1.2" data-path="preprocesso.html"><a href="preprocesso.html#outlier"><i class="fa fa-check"></i><b>4.1.2</b> <em>Outlier</em></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="preprocesso.html"><a href="preprocesso.html#transformação-de-dados"><i class="fa fa-check"></i><b>4.2</b> Transformação de dados</a><ul>
<li class="chapter" data-level="4.2.1" data-path="preprocesso.html"><a href="preprocesso.html#tipos-de-datasets"><i class="fa fa-check"></i><b>4.2.1</b> Tipos de <em>datasets</em></a></li>
<li class="chapter" data-level="4.2.2" data-path="preprocesso.html"><a href="preprocesso.html#normpadro"><i class="fa fa-check"></i><b>4.2.2</b> Normalização e padronização</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="preprocesso.html"><a href="preprocesso.html#features-selection---seleção-de-atributos-sa"><i class="fa fa-check"></i><b>4.3</b> Features Selection - Seleção de atributos (SA)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="valid.html"><a href="valid.html"><i class="fa fa-check"></i><b>5</b> Validação de um modelo</a><ul>
<li class="chapter" data-level="5.1" data-path="valid.html"><a href="valid.html#fitt"><i class="fa fa-check"></i><b>5.1</b> <em>Overfitting, Underfitting</em></a><ul>
<li class="chapter" data-level="5.1.1" data-path="valid.html"><a href="valid.html#overfitting"><i class="fa fa-check"></i><b>5.1.1</b> <strong>Overfitting</strong></a></li>
<li class="chapter" data-level="5.1.2" data-path="valid.html"><a href="valid.html#underfitting"><i class="fa fa-check"></i><b>5.1.2</b> <strong>Underfitting</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="valid.html"><a href="valid.html#holdout"><i class="fa fa-check"></i><b>5.2</b> Validação cruzada Hold-out</a></li>
<li class="chapter" data-level="5.3" data-path="valid.html"><a href="valid.html#kfold"><i class="fa fa-check"></i><b>5.3</b> Validação Cruzada <em>K-fold</em></a></li>
<li class="chapter" data-level="5.4" data-path="valid.html"><a href="valid.html#aocroc"><i class="fa fa-check"></i><b>5.4</b> ROC e AUC</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html"><i class="fa fa-check"></i><b>6</b> Modelos de Aprendizagem I</a><ul>
<li class="chapter" data-level="6.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#naive-bayes"><i class="fa fa-check"></i><b>6.1</b> Naive Bayes</a><ul>
<li class="chapter" data-level="6.1.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exbayes"><i class="fa fa-check"></i><b>6.1.1</b> Exemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#reg"><i class="fa fa-check"></i><b>6.2</b> Regressão</a><ul>
<li class="chapter" data-level="6.2.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#reglin"><i class="fa fa-check"></i><b>6.2.1</b> Análise de Regressão Linear Simples</a></li>
<li class="chapter" data-level="6.2.2" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#regmult"><i class="fa fa-check"></i><b>6.2.2</b> Regressão Linear Múltipla</a></li>
<li class="chapter" data-level="6.2.3" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#mpl"><i class="fa fa-check"></i><b>6.2.3</b> Modelo de Probabilidade Linear (MPL)</a></li>
<li class="chapter" data-level="6.2.4" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exemplo1reg"><i class="fa fa-check"></i><b>6.2.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#GD"><i class="fa fa-check"></i><b>6.3</b> Gradiente Descendente (GD)</a><ul>
<li class="chapter" data-level="6.3.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exemplos"><i class="fa fa-check"></i><b>6.3.1</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#regularizacao"><i class="fa fa-check"></i><b>6.4</b> Regularização</a><ul>
<li class="chapter" data-level="6.4.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#penalizacoes"><i class="fa fa-check"></i><b>6.4.1</b> Penalizações - Regressão <em>Lasso</em> e a Regressão <em>Ridge</em></a></li>
<li class="chapter" data-level="6.4.2" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#elasticnet"><i class="fa fa-check"></i><b>6.4.2</b> Elastic Net - <span class="math inline">\(L_1+L_2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#knn-k-vizinhos-mais-próximos-k-nearest-neighbors"><i class="fa fa-check"></i><b>6.5</b> KNN: K-Vizinhos Mais Próximos (<em>K-Nearest Neighbors</em>)</a><ul>
<li class="chapter" data-level="6.5.1" data-path="Algoritmosaprendizagem.html"><a href="Algoritmosaprendizagem.html#exknn"><i class="fa fa-check"></i><b>6.5.1</b> Exemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ptII.html"><a href="ptII.html"><i class="fa fa-check"></i><b>7</b> Modelos de Aprendizagem II</a><ul>
<li class="chapter" data-level="7.1" data-path="ptII.html"><a href="ptII.html#svm"><i class="fa fa-check"></i><b>7.1</b> Máquina de Vetores Suporte - <em>Support Vectors Machine</em></a><ul>
<li class="chapter" data-level="7.1.1" data-path="ptII.html"><a href="ptII.html#classificação-de-padrões-linearmente-separáveis"><i class="fa fa-check"></i><b>7.1.1</b> Classificação de Padrões Linearmente Separáveis</a></li>
<li class="chapter" data-level="7.1.2" data-path="ptII.html"><a href="ptII.html#margmax"><i class="fa fa-check"></i><b>7.1.2</b> Hiperplano de Separação Ótima / Margem Máxima</a></li>
<li class="chapter" data-level="7.1.3" data-path="ptII.html"><a href="ptII.html#classificação-de-padrões-não-linearmente-separáveis"><i class="fa fa-check"></i><b>7.1.3</b> Classificação de Padrões Não-Linearmente Separáveis</a></li>
<li class="chapter" data-level="7.1.4" data-path="ptII.html"><a href="ptII.html#exemplosvm"><i class="fa fa-check"></i><b>7.1.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ptII.html"><a href="ptII.html#decisiontree"><i class="fa fa-check"></i><b>7.2</b> Árvore de Decisão (<em>Decision Tree</em>)</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ptII.html"><a href="ptII.html#extree"><i class="fa fa-check"></i><b>7.2.1</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ptII.html"><a href="ptII.html#AC"><i class="fa fa-check"></i><b>7.3</b> Análise de Componentes Principais</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ptII.html"><a href="ptII.html#autovalores-e-autovetores"><i class="fa fa-check"></i><b>7.3.1</b> Autovalores e Autovetores</a></li>
<li class="chapter" data-level="7.3.2" data-path="ptII.html"><a href="ptII.html#estatísticas"><i class="fa fa-check"></i><b>7.3.2</b> Estatísticas</a></li>
<li class="chapter" data-level="7.3.3" data-path="ptII.html"><a href="ptII.html#a-acp"><i class="fa fa-check"></i><b>7.3.3</b> A ACP</a></li>
<li class="chapter" data-level="7.3.4" data-path="ptII.html"><a href="ptII.html#exemplocp"><i class="fa fa-check"></i><b>7.3.4</b> Exemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ptII.html"><a href="ptII.html#análise-de-agrupamentos---clusters"><i class="fa fa-check"></i><b>7.4</b> Análise de Agrupamentos - <em>Clusters</em></a><ul>
<li class="chapter" data-level="7.4.1" data-path="ptII.html"><a href="ptII.html#técnicas-hierárquicas-aglomerativas"><i class="fa fa-check"></i><b>7.4.1</b> Técnicas Hierárquicas Aglomerativas</a></li>
<li class="chapter" data-level="7.4.2" data-path="ptII.html"><a href="ptII.html#número-final-de-grupos"><i class="fa fa-check"></i><b>7.4.2</b> Número final de grupos</a></li>
<li class="chapter" data-level="7.4.3" data-path="ptII.html"><a href="ptII.html#técnicas-não-hierárquicas"><i class="fa fa-check"></i><b>7.4.3</b> Técnicas Não Hierárquicas</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ptII.html"><a href="ptII.html#redesneurais"><i class="fa fa-check"></i><b>7.5</b> Redes Neurais Artificiais (RNA)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ptIII.html"><a href="ptIII.html"><i class="fa fa-check"></i><b>8</b> Os métodos <em>Ensemble</em></a><ul>
<li class="chapter" data-level="8.1" data-path="ptIII.html"><a href="ptIII.html#bagging"><i class="fa fa-check"></i><b>8.1</b> <em>Bagging</em></a></li>
<li class="chapter" data-level="8.2" data-path="ptIII.html"><a href="ptIII.html#boost"><i class="fa fa-check"></i><b>8.2</b> <em>Boosting</em></a><ul>
<li class="chapter" data-level="8.2.1" data-path="ptIII.html"><a href="ptIII.html#adaboost"><i class="fa fa-check"></i><b>8.2.1</b> <em>AdaBoost</em></a></li>
<li class="chapter" data-level="8.2.2" data-path="ptIII.html"><a href="ptIII.html#gradientboost"><i class="fa fa-check"></i><b>8.2.2</b> <em>Gradient Boosting</em></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ptIII.html"><a href="ptIII.html#bagboost"><i class="fa fa-check"></i><b>8.3</b> <em>Bagging x Boosting</em></a></li>
<li class="chapter" data-level="8.4" data-path="ptIII.html"><a href="ptIII.html#stacking"><i class="fa fa-check"></i><b>8.4</b> <em>Stacking</em></a></li>
<li class="chapter" data-level="8.5" data-path="ptIII.html"><a href="ptIII.html#rf"><i class="fa fa-check"></i><b>8.5</b> Floresta Aleatória - <em>Random Forest</em></a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ptII.html"><a href="ptII.html#redesneurais"><i class="fa fa-check"></i><b>9</b> Redes Neurais</a></li>
<li class="chapter" data-level="10" data-path="deeplearning.html"><a href="deeplearning.html"><i class="fa fa-check"></i><b>10</b> <em>Deep Learning</em></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado com bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de <em>Machine Learning</em></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="valid" class="section level1">
<h1><span class="header-section-number">Capítulo 5</span> Validação de um modelo</h1>
<p>Com os dados totalmente preparados pela etapa de pré-processamento, estarão aptos para serem aplicados a um modelo de <em>Machine Learning</em> para que se consiga estimar e realizar previsões, ajustar parâmetros e repetindo o processo até que se consiga um bom modelo, ou seja, contendo o mínimo de erro possível. É importante antes de finalizar sua análise, que o pesquisador verifique se seu modelo está adequado ao conjunto de dados, aplicado corretamente e fazer uma validação.</p>
<div id="fitt" class="section level2">
<h2><span class="header-section-number">5.1</span> <em>Overfitting, Underfitting</em></h2>
<p>Sendo <strong>muito importantes</strong> nesta área, o <strong><em>Underfitting</em> (sub-ajustado)</strong> e <strong><em>Overfitting</em></strong> (sobre-ajustado)** são dois termos que temos que estar sempre atentos. Um bom modelo não deve sofrer de nenhum deles <span class="citation">(Silver <a href="#ref-silver2013sinal">2013</a>)</span>. Vamos entender melhor do que eles se tratam.</p>
<div id="overfitting" class="section level3">
<h3><span class="header-section-number">5.1.1</span> <strong>Overfitting</strong></h3>
<p>Um cenário de <em>overfitting</em> ocorre quando, nos dados de treino, o seu modelo ML tem um desempenho excelente, porém quando utilizamos os dados em novos bancos de dados, seu resultado é ruim. Nesta situação, seu modelo aprendeu tão bem as relações existentes dos conjuntos de dados para treino que acabou apenas decorando esses dados. Portanto ao receber as informações das variáveis preditoras aos novos dados, o modelo tenta aplicar as mesmas regras decoradas, porém com estes novos dados (diferentes do treino) esta regra não tem validade e seu desempenho é afetado.</p>
<p>As principais causas e soluções de um <em>overfitting</em> são:</p>
<ol style="list-style-type: decimal">
<li><p>Algoritmo muito complexo para os dados: caso for possível, pode-se simplificar o modelo utilizado por um algoritmo mais simples, com menos parâmetros. Permitindo reduzir as chances do modelo sofrer <em>overfitting</em>.</p></li>
<li><p>Poucos dados para treinar: dependendo da quantidade de dados utilizados para treinar, pode ser que seja uma amostra pequena, com isso recomenda-se aumentar seu tamanho coletando mais dados.</p></li>
<li><p>Ruídos nos dados de treinamento: é comum dentro do banco de dados existir algum tipo de ruído, isto é, <em>outlier</em> (valores extremos ou até mesmo valores incorretos nos dados). Esses ruídos podem fazer com que o modelo aprenda sobre ele, levando ao overfitting. Seria recomendado pré-processamento adequado para tratar essa interferência.</p></li>
</ol>
</div>
<div id="underfitting" class="section level3">
<h3><span class="header-section-number">5.1.2</span> <strong>Underfitting</strong></h3>
<p>No cenário <em>underfitting</em>, o desempenho já é ruim no próprio treinamento de seu algoritmo.</p>
<p>As principais causas e soluções de um <em>underfitting</em> são:</p>
<ol style="list-style-type: decimal">
<li><p>Algoritmo inadequado: bem provável que o modelo estatístico proposto pelo pesquisa pode não ter sido adequado ao comportamento dos dados. Por exemplo aplicar um algoritmo para funções de primeiro grau (linear) em um conjunto de dados com comportamento exponencial (função de segundo grau). Recomendável o pesquisador substituir o algoritmo escolhendo outro com outros parâmetros para solucionar o underfitting.</p></li>
<li><p>Características não representativas: há possibilidade de que as características que estamos utilizando para treinar o modelo não sejam representativas, ou seja, não possuem relação entre si ou não sejam importantes para o modelo aplicado.</p></li>
<li><p>Modelo com muitos parâmetros de restrição: o modelo torna-se inflexível, restrito, e não consegue se ajustar de forma adequada aos dados.</p></li>
</ol>
<p>Segue abaixo a Figura <a href="valid.html#fig:graficofit">5.1</a> demonstrando os dois casos anteriores e um modelo adequado.</p>
<div class="figure" style="text-align: center"><span id="fig:graficofit"></span>
<img src="Figuras/graficofit.png" alt="“Da esquerda para a direita, representações de um Underfitting, um Modelo bem ajustado e um Overfitting respectivamente.”" width="70%" />
<p class="caption">
Figura 5.1: “Da esquerda para a direita, representações de um <em>Underfitting</em>, um Modelo bem ajustado e um <em>Overfitting</em> respectivamente.”
</p>
</div>

</div>
</div>
<div id="holdout" class="section level2">
<h2><span class="header-section-number">5.2</span> Validação cruzada Hold-out</h2>
<p>Dependendo modelo que utilizarmos no conjunto de dados preparado, é possível trabalharmos com a totalidade dos dados históricos e obter um modelo de ML pronto para receber novos dados e realizar suas previsões de acordo com seu algoritmo, porém muitas vezes não teríamos como saber qual sua real performance em seu modelo. O algoritmo poderia estar com problemas de <strong>overfitting</strong> e ter decorado os dados, o que para suas futuras previsões é bem possível que haja graves problemas.</p>
<p>Para medirmos esta performance, é fundamental de que se faça testes com este modelo, portanto é necessário utilizar um conjunto de dados diferentes do quais foram utilizados em sua formulação. Após a etapa de tratar os dados (pré-processmento), é recomendável antes de elaborar seu modelo ML, separar este <em>dataset</em> total <span class="math inline">\(n\)</span> em grupos. O método validação cruzada, do inglês <em>cross-validation</em>, <strong>Hold-out</strong> <span class="citation">(Devroye and Wagner <a href="#ref-devroye1979distribution">1979</a>)</span> propõe que a amostra seja dividia em dois grupos: o primeiro grupo tem como propósito treinar o modelo, são os dados que serão apresentados ao algoritmo proposto pelo pesquisador para que se elabore um modelo (geralmente utilizam em torno dos 70% dos dados) e o segundo grupo tem como responsabilidade testar este modelo treinado pelo primeiro grupo. É composto pelo resto do <em>dataset</em> não utilizado no primeiro grupo e serve para ser apresesentado ao modelo elaborado, assim faz uma simulação de previsões com dados reais permitindo com que avalie o desempenho dele. É importante que o processo de separação dos dados seja de forma aleatória em seu <em>dataset</em>, para que se evite grandes problemas de viés.</p>
<p>Vamos imaginar a situação de avaliar bons pagadores e maus pagadores: você possui um enorme banco de dados com as características dos indivíduos e a classificação de quem é bom ou mau pagador e que está por ordem de idade - totalmente tratados pela etapa de pré-processamento. Primeiramente pegamos 70% do total do conjunto de dados aleatoriamente e separamos para treinarmos um modelo.</p>
<p>Após definirmos um modelo adequado ao conjunto de dados de treino, vamos treiná-lo com os dados apresentados para que ele aprenda a estimar valores futuros e classificar de acordo com as características do indivíduo, se será um bom ou mau pagador. Para verificarmos se este modelo é bom, utilizamos os outros 30% da amostra, aplicamos no modelo treinado pelo primeiro grupo de dados e por fim comparamos com a <strong>tabela de confusão</strong>, ou também conhecida como <strong>matriz de confusão</strong>. Esta tabela basicamente possui os dados dos 30% dos dados com suas classificações originais e a classificação que o próprio algoritmo que aprendeu com o primeiro grupo definiu, permitindo que possamos comparar seus acertos e erros. Note que caso não houvesse aleatoriedade na separação dos dados, possívelmente o modelo iria aprender apenas as pessoas com menor idade, os outros 30% seriam os mais velhos, isso faria com que o modelo não prevesse corretamente.</p>
<p>Supondo que 30% dos dados equivale a 100 indivíduos a serem classificados e com a seguinte tabela de confusão:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Bom Pagador</th>
<th>Mau Pagador</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bom Pagador</td>
<td>45</td>
<td>10</td>
</tr>
<tr class="even">
<td>Mau Pagador</td>
<td>13</td>
<td>32</td>
</tr>
</tbody>
</table>
<p>Podemos ver que como “Bom Pagador”, o algoritmo que aprendeu com o primeiro grupo composto pelos outros 70% dos dados, acertou 45 e errou 10 dizendo que era “Mau pagador”. Do caso de classificar como “Mau pagador”, o modelo acertou 32 e 13 eram na verdade “Bom Pagador”. Portanto podemos calcular sua taxa de acerto e de erro apenas somando e dividindo pelo total:</p>
<p><span class="math display">\[\mbox{Taxa de Acertos:}\ \frac{45+32}{100}=0,77 \ \ \ \mbox{Taxa de Erros:}\ \frac{10+13}{100}=0,23\]</span>
Podemos ver que o modelo, com os dados de teste, acertou 77% e errou 23%. Aparentemente o modelo não está tão bom. Neste caso o pesquisador precisaria verificar se está com um modelo adequado (pode ser que tenha outros melhores), se estão corretamente ajustados seus parâmetros ou se há necessidade de mais amostras em seu modelo para aprender.</p>
<p>Note que todas as predições corretas estão localizadas na diagonal principal da tabela, o que torna fácil inspecionar os erros de predição do modelo, localizados na diagonal da direita para a esquerda. Formalmente podemos expressá-la como:</p>
<table>
<caption><span id="tab:matrizconfu">Tabela 5.1: </span> Matriz de confusão.</caption>
<thead>
<tr class="header">
<th></th>
<th>Positivo</th>
<th>Negativo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Positivo</td>
<td>Verdadeiro Positivo (VP)</td>
<td>Falso Negativo (FN)</td>
</tr>
<tr class="even">
<td>Negativo</td>
<td>Falso Positivo (FP)</td>
<td>Verdadeiro Negativo (VN)</td>
</tr>
</tbody>
</table>
<p>onde a taxa de acerto é expressa como:</p>
<p><span class="math display" id="eq:TA">\[\begin{equation}
TA = \frac{VP+VN}{N}
\tag{5.1}
\end{equation}\]</span></p>
<p>em que <span class="math inline">\(N=VP+VN+FN+FP\)</span> equivale ao total de elementos. A taxa de erro TE é dada por:</p>
<p><span class="math display" id="eq:TE">\[\begin{equation}
TE=\frac{FN+FP}{N}
\tag{5.2}
\end{equation}\]</span></p>
<p>A métrica utilizada na matriz de confusão pode variar dependendo do objetivo da pesquisa, como por exemplo os modelos <strong><em>recall</em> (taxa de verdadeiro positivo)</strong>, precisão e <strong><span class="math inline">\(F_1\)</span> <em>score</em></strong>. Representando a proporção de positivos reais que foi identificada corretamente, a <em>recall</em> é representada pela seguinte equação:</p>
<p><span class="math display" id="eq:recall">\[\begin{equation}
Recall=\frac{VP}{VP+FN}
\tag{5.3}
\end{equation}\]</span></p>
<p>A precisão representa a proporção de identificações positivas corretas verdadeiramente:</p>
<p><span class="math display" id="eq:precision">\[\begin{equation}
Preciãi=\frac{VP}{VP+FP}
\tag{5.4}
\end{equation}\]</span></p>
<p>A <span class="math inline">\(F_1\)</span> <em>score</em>, por fim, é uma média harmônica das duas equações anteriores, visto que <em>recall</em> e precisão normalmente são inversas. Ela pode ser expressa pela equação:</p>
<p><span class="math display" id="eq:f1score">\[\begin{equation}
F_1=\frac{TP}{TP+\frac{1}{2}(FP+FN)}
\tag{5.5}
\end{equation}\]</span></p>
<p>em que <span class="math inline">\(F_1\)</span> <em>score</em> varia entre 0 (precisão ou <em>recall</em> nula) e 1 (perfeitos).</p>
<p>Alguns pesquisadores, como <span class="citation">Kohavi and others (<a href="#ref-kohavi1995study">1995</a>)</span>, acreditam ser pessimista por usar apenas uma parte dos dados como preditor do modelo e quanto mais observações deixarmos para a base teste, maior será o viés do modelo.</p>
</div>
<div id="kfold" class="section level2">
<h2><span class="header-section-number">5.3</span> Validação Cruzada <em>K-fold</em></h2>
<p>A validação cruzada <em>K-fold</em> <span class="citation">(Burman <a href="#ref-burman1989comparative">1989</a>)</span>, diferencia do método <em>Hold-out</em> pois em vez de dividir a amostra <span class="math inline">\(d\)</span> em duas partes, ela irá dividir em <span class="math inline">\(K\)</span> partes <span class="math inline">\((d_1,d_2,...,d_K)\)</span> de tamanhos semelhantes. De modo que haverá <span class="math inline">\(K\)</span> iterações em que cada iteração a amostra de validação será dada por <span class="math inline">\(d_k\)</span>, com <span class="math inline">\(k=1,2,...,K\)</span>, e a amostra de treino para a criação do preditor será o conjunto do resto <span class="math inline">\(K-1\)</span> partes <span class="citation">(Cunha <a href="#ref-cunha2019estudo">2019</a>)</span>. Portanto, sua vantagem é que será utilizados todos os dados na parte de treino e na parte de validação.</p>
<div class="figure" style="text-align: center"><span id="fig:kfold"></span>
<img src="Figuras/kfold.png" alt="“Método de validação cruzada K-fold em que K=3.”" width="70%" />
<p class="caption">
Figura 5.2: “Método de validação cruzada <em>K-fold</em> em que K=3.”
</p>
</div>

<p>Conforme <span class="citation">(Borra and Di Ciaccio <a href="#ref-borra2010measuring">2010</a>)</span>, o viés neste método diminui quanto maior for o valor de <span class="math inline">\(K\)</span>. O que é claro que também haverá um dispêndio de tempo e custo computacional maior. Inclusive que haverá uma amostra de teste pequena e consequentemente uma variância maior. <span class="citation">(Breiman and others <a href="#ref-breiman1996heuristics">1996</a>)</span> aponta que um dos problemas deste método é que as amostras de treino não são independentes entre si e portanto, implica numa variância grande. A respeito do tamanho de <span class="math inline">\(K\)</span> existe diversas discussões, pesquisadores como <span class="citation">(Borra and Di Ciaccio <a href="#ref-borra2010measuring">2010</a>; Kohavi and others <a href="#ref-kohavi1995study">1995</a>; Cunha <a href="#ref-cunha2019estudo">2019</a>)</span> utilizaram e verificaram um bom desempenho com <span class="math inline">\(K=10\)</span>, mas há pesquisadores que discordam e sugerem outros valores como por exemplo, 2 e 5.</p>
<p>Um caso específico do <em>K-fold</em> é o <strong><em>Leave-one-out</em></strong> que consiste em utilizar o valor de <span class="math inline">\(K=N\)</span>, ou seja, o número total de dados. Neste caso realiza-se <span class="math inline">\(N\)</span> estimativas de erro. <span class="citation">Borra and Di Ciaccio (<a href="#ref-borra2010measuring">2010</a>)</span> verifica que é um estimador não viesado do erro, visto que a amostra de treino é quase a base toda, porém possui alta variabilidade e um custo computacional muito elevado.</p>
</div>
<div id="aocroc" class="section level2">
<h2><span class="header-section-number">5.4</span> ROC e AUC</h2>
<p>Do inglês <strong><em>receiver operating characteristics</em></strong>, <strong>ROC</strong> é um método gráfico utilizado para visualizar, organizar e selecionar classificadores com base no desempenho do modelo de classificação. Foram originalmente utilizados em detecção de sinais para avaliar a qualidade de transmissão de um sinal em um canal com ruído <span class="citation">(Egan and Egan <a href="#ref-egan1975signal">1975</a>)</span> e atualmente é aplicado em áreas distintas como a avaliação da capacidade de indivíduos distinguirem entre estímulo e não estímulo <span class="citation">(Green, Swets, and others <a href="#ref-green1966signal">1966</a>)</span>, avaliar a desigualdade de renda <span class="citation">(Gastwirth <a href="#ref-gastwirth1971general">1971</a>)</span>, avaliar a qualidade das predições de tempo ao caso de eventos raros ou até mesmo a qualidade de um teste clínico <span class="citation">(Zhou, McClish, and Obuchowski <a href="#ref-zhou2009statistical">2009</a>; Mylne <a href="#ref-mylne2002decision">2002</a>)</span>.</p>
<p>Um dos primeiros a aplicar os gráficos ROC no Aprendizado de Máquina foi <span class="citation">(Spackman <a href="#ref-spackman1989signal">1989</a>)</span> na avaliação e comparação de algoritmos e atualmente anda crescendo seu uso entre a comunidade acadêmica devido que a precisão da classificação simples muitas vezes é uma métrica fraca para medir o desempenho <span class="citation">(Provost and Fawcett <a href="#ref-provost1997analysis">1997</a>)</span>, além de que possuem vantagens para domínios com com distribuição de classe distorcida e custos de erro de classificação desiguais. Embora mesmo sendo simples, existem algumas complexidades e equívocos que exige um cuidado do pesquisador.</p>
<p>Vimos em validação cruzada que a matriz de confusão em <a href="valid.html#tab:matrizconfu">5.1</a> é apresentada como:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Positivo</th>
<th>Negativo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Positivo</td>
<td>Verdadeiro Positivo (VP)</td>
<td>Falso Negativo (FN)</td>
</tr>
<tr class="even">
<td>Negativo</td>
<td>Falso Positivo (FP)</td>
<td>Verdadeiro Negativo (VN)</td>
</tr>
</tbody>
</table>
<p>A curva ROC é baseado na probabilidade de detecção e na probabilidade de falsos alarmes, ou seja, a <em>recall</em> <a href="valid.html#eq:recall">(5.3)</a> que é a taxa de verdadeiro positivo (TVP) e na taxa de falso positivo que pode ser expressa por:</p>
<p><span class="math display" id="eq:TFP">\[\begin{equation}
TFP=\frac{FP}{(FP+VN)}
\tag{5.6}
\end{equation}\]</span></p>
<p>Para se construir o gráfico ROC, plota-se TFP no eixo das ordenada (<span class="math inline">\(x\)</span>) e TVP (<em>recall</em>) no eixo das abscissas (<span class="math inline">\(y\)</span>). Conforme <span class="citation">(Prati et al. <a href="#ref-prati2008curvas">2008</a>)</span>, o ponto <span class="math inline">\((0,0)\)</span> representa a estratégia de nunca classificar um exemplo como positivo, modelos que correspondem a esse ponto não representam falso positivo, porém também não conseguem classificar nenhum ponto verdadeiro positivo. Do contrário em <span class="math inline">\((100\%,100\%)\)</span> representa de sempre classificar um novo exemplo como positivo. Ao ponto <span class="math inline">\((0,100\%)\)</span> representa o modelo perfeito e todos os exemplos são corretamente classificados e ao ponto <span class="math inline">\((100\%,0)\)</span> representa ao caso em que o modelo sempre erra em sua predição. Portanto, pode ser representado por duas linhas diagonais:</p>
<ul>
<li><p>Linha diagonal ascendente: representa um modelo de comportamento estocástico em que, os pontos pertencentes ao triângulo superior esquerdo a essa diagonal representam modelos que desempenham melhor que o aleatório e aos pontos que se encontram no triângulo inferior direito, representam modelos piores que o aleatório.</p></li>
<li><p>Linha diagonal descendente: os modelos de classificação que desempenham igualmente nas duas classes. À esquerda desta linha encontram-se os modelos que desempenham melhor para a classe negativa em detrimento da positiva e à direita melhor para a classe positiva.</p></li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:roc"></span>
<img src="Figuras/roc.PNG" alt="Espaço ROC (Prati et al. 2008)." width="70%" />
<p class="caption">
Figura 5.3: Espaço ROC <span class="citation">(Prati et al. <a href="#ref-prati2008curvas">2008</a>)</span>.
</p>
</div>

<p>Segue um exemplo, Figura <a href="valid.html#fig:roc2">5.4</a>, de ROC com 5 pontos arbitrários representando cinco modelos de classificações diferentes (<span class="math inline">\(A,B,C,D\)</span> e <span class="math inline">\(F\)</span>) <span class="citation">(Prati et al. <a href="#ref-prati2008curvas">2008</a>)</span>. Neste caso, para o modelo <span class="math inline">\(A\)</span>, dizemos “conservativo” pois ele faz uma classificação positiva somente se têm grande segurança na classificação. Ao modelo <span class="math inline">\(D\)</span>, pode-se considerar “liberal” pois prediz a classe positiva com mais frequência, porém com possibilidade de altas taxas de falsos positivos.</p>
<p>Um ponto no espaço ROC é melhor que outro se e somente se estiver acima e à esquerda de outro ponto com uma maior taxa de verdadeiros positivos e uma menor taxa de falsos positivos.</p>
<div class="figure" style="text-align: center"><span id="fig:roc2"></span>
<img src="Figuras/roc2.PNG" alt="Modelos de classificação no espaço ROC (Prati et al. 2008)." width="70%" />
<p class="caption">
Figura 5.4: Modelos de classificação no espaço ROC <span class="citation">(Prati et al. <a href="#ref-prati2008curvas">2008</a>)</span>.
</p>
</div>

<p>Para avaliarmos a ROC podemos utilizar a <strong>Área embaixo da curva ROC</strong>, do inglês <em>Area under the ROC Curve (AUC)</em>, que é feito por cálculo integral para medir a área embaixo da curva de ROC e fornecer uma medida agregada da performance de todos os limites de classificação disponíveis. Conforme <span class="citation">(MCCLISH <a href="#ref-mcclish1989">1989</a>)</span>, pode ser interpretada como a probabilidade de que o modelo classifique um exemplo positivo aleatório mais alto do que um exemplo negativo aleatório, variando em valores de 0 para previsões integralmente erradas e 1 (100%) de AUC para 100% corretas. O método AUC tem como vantagem medir o quão bem as previsões são classificadas por ser invariante de escala e mede a qualidade das previsões do modelo independente do limite de classificação escolhido. Na figura <a href="valid.html#fig:AUC">5.5</a> uma representação do gráifco da AUC para diferentes valores.</p>
<div class="figure" style="text-align: center"><span id="fig:AUC"></span>
<img src="Figuras/AUC.png" alt="AUC (Glen 2019)." width="110%" height="100%" />
<p class="caption">
Figura 5.5: AUC <span class="citation">(Glen <a href="#ref-stephanieauc">2019</a>)</span>.
</p>
</div>


</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-borra2010measuring">
<p>Borra, Simone, and Agostino Di Ciaccio. 2010. “Measuring the Prediction Error. A Comparison of Cross-Validation, Bootstrap and Covariance Penalty Methods.” <em>Computational Statistics &amp; Data Analysis</em> 54 (12): 2976–89.</p>
</div>
<div id="ref-breiman1996heuristics">
<p>Breiman, Leo, and others. 1996. “Heuristics of Instability and Stabilization in Model Selection.” <em>Annals of Statistics</em> 24 (6): 2350–83.</p>
</div>
<div id="ref-burman1989comparative">
<p>Burman, Prabir. 1989. “A Comparative Study of Ordinary Cross-Validation, V-Fold Cross-Validation and the Repeated Learning-Testing Methods.” <em>Biometrika</em> 76 (3): 503–14.</p>
</div>
<div id="ref-cunha2019estudo">
<p>Cunha, João Paulo Zanola. 2019. “Um Estudo Comparativo Das Técnicas de Validação Cruzada Aplicadas a Modelos Mistos.” PhD thesis, Universidade de São Paulo.</p>
</div>
<div id="ref-devroye1979distribution">
<p>Devroye, Luc, and Terry Wagner. 1979. “Distribution-Free Performance Bounds for Potential Function Rules.” <em>IEEE Transactions on Information Theory</em> 25 (5): 601–4.</p>
</div>
<div id="ref-egan1975signal">
<p>Egan, James P, and James Pendleton Egan. 1975. <em>Signal Detection Theory and Roc-Analysis</em>. Academic press.</p>
</div>
<div id="ref-gastwirth1971general">
<p>Gastwirth, Joseph L. 1971. “A General Definition of the Lorenz Curve.” <em>Econometrica: Journal of the Econometric Society</em>, 1037–9.</p>
</div>
<div id="ref-stephanieauc">
<p>Glen, Stephanie. 2019. “ROC Curve Explained in One Picture.” In. <a href="https://www.datasciencecentral.com/profiles/blogs/roc-curve-explained-in-one-picture">https://www.datasciencecentral.com/profiles/blogs/roc-curve-explained-in-one-picture</a>.</p>
</div>
<div id="ref-green1966signal">
<p>Green, David Marvin, John A Swets, and others. 1966. <em>Signal Detection Theory and Psychophysics</em>. Vol. 1. Wiley New York.</p>
</div>
<div id="ref-kohavi1995study">
<p>Kohavi, Ron, and others. 1995. “A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection.” In <em>Ijcai</em>, 14:1137–45. 2. Montreal, Canada.</p>
</div>
<div id="ref-mcclish1989">
<p>MCCLISH, D.K. 1989. “Analysing a Portion of the Roc Curve.” <em>Medical Decision Making</em> 9 (3): 190–96.</p>
</div>
<div id="ref-mylne2002decision">
<p>Mylne, Kenneth R. 2002. “Decision-Making from Probability Forecasts Based on Forecast Value.” <em>Meteorological Applications</em> 9 (3): 307–15.</p>
</div>
<div id="ref-prati2008curvas">
<p>Prati, RC, GEAPA Batista, MC Monard, and others. 2008. “Curvas Roc Para Avaliação de Classificadores.” <em>Revista IEEE América Latina</em> 6 (2): 215–22.</p>
</div>
<div id="ref-provost1997analysis">
<p>Provost, Foster, and Tom Fawcett. 1997. “Analysis and Visualization of Classifier Performance with Nonuniform Class and Cost Distributions.” In <em>Proceedings of Aaai-97 Workshop on Ai Approaches to Fraud Detection &amp; Risk Management</em>, 57–63.</p>
</div>
<div id="ref-silver2013sinal">
<p>Silver, Nate. 2013. <em>O Sinal E O Ruı́do</em>. Editora Intrinseca.</p>
</div>
<div id="ref-spackman1989signal">
<p>Spackman, Kent A. 1989. “Signal Detection Theory: Valuable Tools for Evaluating Inductive Learning.” In <em>Proceedings of the Sixth International Workshop on Machine Learning</em>, 160–63. Elsevier.</p>
</div>
<div id="ref-zhou2009statistical">
<p>Zhou, Xiao-Hua, Donna K McClish, and Nancy A Obuchowski. 2009. <em>Statistical Methods in Diagnostic Medicine</em>. Vol. 569. John Wiley &amp; Sons.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="preprocesso.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Algoritmosaprendizagem.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "github", "instagram"]
},
"fontsettings": ["white", "sepia", "night"],
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/06-Validacaodomodelo.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
