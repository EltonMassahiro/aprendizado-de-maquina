[
["algoritmos-de-aprendizagem-parte-i.html", "Capítulo 6 Algoritmos de Aprendizagem - Parte I 6.1 Medidas de Importância 6.2 Teste de hipóteses e Análise de Variância 6.3 Naive Bayes 6.4 Regressão 6.5 Gradiente Descendente (GD)", " Capítulo 6 Algoritmos de Aprendizagem - Parte I Existe uma infinidade de algoritmos utilizados em machine learning, cada um com uma finalidade específica. Há também características que podem inviabilizar a escolha do modelo mais preciso para determinado problema, como a utilização alto poder computacional. Aqui vai a Parte I de Algoritmos de Aprendizagem, neste capítulos irei apresentar: Medidas de Importância: Medidas de Informação Medidas de Distância Medidas de Dependência Medidas de Precisão Medidas de Consistência Teste de Hipóteses Naive Bayes Regressão Regressão Linear Simples Regressão Múltipla Modelo de Probabilidade Linear Gradiente Descendente 6.1 Medidas de Importância Um atributo é dito importante se quando removido a medida de importância considerada em relação aos atributos restantes é deteriorada , seja a precisão da medida, consistência, informação, distância ou dependência Tradução de Liu and Motoda (2012). É fundamental estimarmos a importância de um atributo, tanto uma avaliação individual quanto à avaliação de subconjuntos de atributos. É uma questão complexa e multidimensional (Liu and Motoda 2012). Podemos avaliar se os atributos selecionados pela etapa do pré-processamento auxiliam a melhorar a precisão do classificador ou a simplifcar algum modelo construído. A seguir, apresenta-se algumas medidas utilizadas (Lee 2005). 6.1.1 Medidas de Informação As medidas de informação determinam o ganho de informação a partir de um atributo. O ganho de informação é definido como a diferença entre a incerteza a priori e a incerteza a posteriori considerando-se o atributo \\(X_i\\). \\(X_i\\) é preferido ao atributo \\(X_j\\) se seu ganho de informação for maior que de \\(X_j\\). Uma das mais utilizadas é a entropia que normalmente é usada na teoria da informação para medir a pureza ou impureza de um determinado conjunto. Shannon (1948), tomou como “ponto de partida” encontrar uma forma matemática de medir o quanto de informação existe na transmissão de uma mensagem de um ponto a outro, denominando-a entropia. Sua proposta baseava-se na ideia de que o aumento da probabilidade do próximo símbolo diminuiria o tamanho da informação. Com isso, a entropia pode ser definida como a quantidade de incerteza que há em uma mensagem e que diminui à medida que os símbolos são transmitidos (vai se conhecendo a mensagem), tendo-se então a informação, que pode ser vista como redução da incerteza (Shannon 1948; Paviotti and Magossi 2019). Por exemplo: ao utilizarmos como idioma a nossa língua portuguesa e ao transmitir como símbolo a letra “q”, a probabilidade do próximo símbolo ser a letra “u” é maior que a de ser qualquer outro símbolo, enquanto que a probabilidade de ser novamente a letra “q” é praticamente nula (Paviotti and Magossi 2019). Shannon define que a entropia pode ser calculada por meio da soma das probabilidades de ocorrência de cada símbolo pela expressão \\(∑ p_i = 1 = 100\\%\\), em que \\(p_i\\) representa a probabilidade do i-ésimo símbolo que compõe a mensagem. Segundo ele, estes símbolos devem ser representados através de sequências binárias, utilizando das propostas de Nyquist (1924) e Hartley (1928). Sua proposta consistia em representar símbolos de um alfabeto através de um logaritmo de acordo com suas respectivas unidades de informação. A entropia proposta por ele é obtida pela média das medidas de Hartley (Moser and Chen 2012). Se A é discreto com distribuição de probabilidade \\(p(A)\\), a entropia será: \\[\\begin{equation} H(A)=- \\sum p(A)log_2(p(A)) \\tag{6.1} \\end{equation}\\] Para facilitar a compreensão, vamos supor um exemplo de um questionário com resposta binária entre “sim” e “não”: quanto mais distribuído as probabilidades das respostas, mais desorganizada é, logo maior suaa entropia, do contrário caso for uma probabilidade de ser zero “sim”/“não” ou de ser 1 (100%), ou seja, ter apenas uma opção de resposta, será menos distribuído e portanto menor usa entropia. Figura 6.1: Gráfico de Probabilidade x Entropia. O ganho de informação portanto mede a redução da entropia (nesse caso) causada pela partição dos exemplos de acordo com os valores do atributo. \\[\\begin{equation} \\mbox{Ganho de Informação}(D,T)=\\mbox{entropia}(D)-\\displaystyle \\sum_{i=1}^k \\frac{|D_i|}{|D|}. \\mbox{entropia}(D_i) \\tag{6.2} \\end{equation}\\] É muito utilizado em algoritmo de Árvore de decisão que será apresentado nesta mesma seção com um exemplo de seu uso. 6.1.2 Medidas de Distância Também conhecidas com medidas de separabilidade, discriminação e divergência. Em caso de duas classes, um atributo \\(X_i\\) é preferido ao atributo \\(X_j\\) se fornece uma diferença maior que \\(X_j\\) entre as probabilidades condicionais das duas classes. Uma das mais utilizadas é a distância Euclidiana. 6.1.3 Medidas de Dependência Figura 6.2: Padrões de correlação. Elaborado por Gujarati and Porter (2011) e adaptado Henri (1978). 6.1.4 Medidas de Precisão 6.1.5 Medidas de consistência 6.2 Teste de hipóteses e Análise de Variância 6.3 Naive Bayes Antes de falarmos sobre este algoritmo, vamos para o conceito matemático. Em (1.2) tratamos do Teorema de Bayes para \\(n\\) atributos. Colocando-o como probabilidade condicional: \\[\\begin{equation} p(A|B_{1},...,B_{n}) = \\\\ p(A)p(B_{1}|A)p(B_{2}|A,B_{1}),p(B_{3}|A,B_{1},B_{2})...p(B_{n}|A,B_{1},B_{2},...,B_{n−1}) \\tag{6.3} \\end{equation}\\] Assumindo que cada atributo \\(B_i\\) é condicionalmente independente de todos os outros \\(B_j\\) para \\(j\\neq i\\) e \\(p(B_i|A,B_j)=p(B_i|A)\\) o modelo poderá ser expresso como: \\[\\begin{equation} p(A_k|B_1,...,B_n)=p(A_k)p(B_1|A_k)p(B_2|A_k),...=p(A_k)\\prod_i^n p(B_i|A_k) \\ k ∈{1,...,k} \\tag{6.4} \\end{equation}\\] Por fim para podermos classificar, aplicamos argumento de máxima para otimizarmos a função, assim obtém-se o classificador de Naive Bayes: \\[\\begin{equation} \\mbox{classificador} \\ \\hat{y}=argmax \\ p(A_k)\\displaystyle \\prod_{i=1}^n p(B_i|A_k) \\ \\ k ∈{1,...,k} \\tag{6.5} \\end{equation}\\] Lembrando que para cada atributo, a sua distribuição de probabilidades é assumida como normal. O Naive Bayes é uma técnica de classificação baseado no teorema de Bayes com uma suposição de independência entre os preditores, ou seja, este classificador assume que a presença de uma característica particular em uma classe não está relacionada com a presença de qualquer outro fator. Por exemplo, uma fruta verde, redonda e com um tamanho de diâmetro X pode ser uma melancia, porém mesmo que estas variáveis dependam uns dos outros e de outras características, todas estas propriedades contribuem de forma independente para a probabilidade de que seja uma melancia. Este modelo é muito utilizado devido que é fácil de construir e particularmente útil para grandes volumes de dados. Porém a própria independência entre os preditores a torna desvantajosa na prática e caso haja variáveis categóricas num conjunto de dados de teste que não forem treinadas, o modelo não irá estimar estas novas variáveis. Exemplo: para facilitar, podemos supor que estamos trabalhando no diagnóstico de uma nova doença e que foi feito testes em 100 pessoas aleatórias (exemplo de Orgânica Digital (2019)). Após coletarmos a análise, descobrimos que das 100 pessoas, 20 possuíam a doença (20%) e 80 pessoas estavam saudáveis (80%), sendo que das pessoas que possuíam a doença, 90% receberam o resultado positivo no teste da doença, e 30% das pessoas que não possuíam a doença também receberam o teste positivo. Caso uma nova pessoa realizar o teste e receber um resultado positivo, qual a probabilidade de ela realmente possuir a doença? Figura 6.3: Dados coletados de uma amostra de 100 pessoas aleatórias. Com o algoritmo de Naive Bayes, buscamos encontrar uma probabilidade da pessoa possuir a doença dado que ela recebeu um resultado positivo, multiplicando a probabilidade de possuir a doença pela probabilidade de “receber um resultado positivo, dado que tem a doença”. De mesmo modo verificar a probabilidade de não possuir a doença dado que recebeu um resultado positivo. Ou seja, ao caso de ter a doença dado que o resultado deu positivo: \\[P(doença|positivo) = 20\\% . 90\\% \\] \\[P(doença|positivo) = 0,2 * 0,9 \\] \\[P(doença|positivo) = 0,18\\] Para o caso de não ter a doença, dado que deu positivo: \\[P(não \\ doença|positivo) = 80\\%.30\\%\\] \\[P(não \\ doença|positivo) = 0,8 * 0,3\\] \\[P(não\\ doença|positivo) = 0,24\\] Após isso precisamos normalizar os dados, para que a soma das duas probabilidades resulte 1 (100%). Como vimos em pré-processamento 5, a Normalização por reescala por meio de um valor mínimio e um máximo, gera um novo intervalo onde os valores de um atributo estão contidos. Um intervalo entre 0 e 1. Portanto, dividimos o resultado pela soma das duas probabilidades. \\[P(doença|positivo) = 0,18/(0,18+0,24) = 0,4285\\] \\[P(não doença|positivo) = 0,24/(0,18+0,24) = 0,5714\\] Logo, podemos concluir que se o resultado do teste da nova pessoa for positivo, ela possui aproximadamente 43% (0,4285) de chance de estar doente. Observação e resumo geral: Naive Bayes é uma técnica de classificação baseado no teorema de Bayes com uma suposição de independência entre os preditores diferentemente do caso em 1.2 (Teorema de Bayes), ou seja, O Naive Bayes assume que a presença de uma característica particular em uma classe não está relacionada com a presença de qualquer outro fator. Ao caso da melancia, uma fruta verde, redonda e com um tamanho de diâmetro X é possível ser ela, porém mesmo que estas variáveis dependam uma das outras e de outras características, elas contribuem de forma independente para a probabilidade de que seja uma melancia. É um modelo simples de construir e útil para grandes volumes de dados. Porém a própria independência entre os preditores a torna desvantajosa para apliação prática e que variáveis categóricas num conjunto de dados de teste que não foram treinadas, não irá estimar essa nova variável. Por isso Naive vem do significado “ingênuo”, pois como a Figura 6.4 demonstra, os atributos contribuem de forma independente para a probabilidade de A. Figura 6.4: Gráfico de Probabilidade x Entropia. 6.4 Regressão 6.4.1 Análise de Regressão Linear A análise de variância, pressupõe a independência dos efeitos dos diversos tratamentos utilizados no experimento. Quando a hipótese não é verificada, necessitamos refletir a dependência entre os efeitos dos tratamentos. No caso de experimentos quantitativos, frequentemente justifica a existência da equação de regressão, que une os valores dos tratamentos aos analisados. Em grande parte, trata de estimação e/ou previsão do valor médio (para população) da variável dependente com base nos valores conhecidos da variável explanatória, ela é supervisionada. Como na prática não conseguimos análisar uma população, trabalhamos em cima de amostras e estimamos para o todo, para que possamos fazer uma aproximação. Partimos da ideia de estimarmos uma função com dados amostrais com o menor erro possível. Portanto, o \\(Y_i\\) (população) observado pode ser expresso como: \\[\\begin{equation} Y_i=\\hat{Y_i}+\\hat{\\mu_i} \\tag{6.6} \\end{equation}\\] E o modelo para função de regressão amostral: \\[\\begin{equation} Y_i=\\hat{\\beta_0}+\\hat{\\beta_1}X_i+\\hat{\\mu_i} \\tag{6.7} \\end{equation}\\] em que: \\(\\hat{Y_i}\\) é o valor observado com \\(i\\) níveis de \\(X\\) (estimador da esperança \\(E(Y|Xi)\\)), \\(\\hat{\\beta_0}\\) a constante de regressão estimado e intercepto de \\(\\hat{Y}\\), \\(\\hat{\\beta_1}\\) o coeficiente de regressão estimado que seria a variação de \\(\\hat{Y}\\) em função da variação de cada unidade de \\(X\\), \\(X_i\\) com \\(i\\) níveis da variável independente e \\(\\hat{\\mu_i}\\) é o erro associado à distância entre o valor observado e o correspondente ponto na curva. Note que os “chapéis” em cima das variáveis é utilizado quando referimos a estimações, ou seja, são variáveis de dados amostrais e não a população. Mas como estimâmetros os parâmetros da função de forma que fique mais próxima possível e com o menor erro? Com o Método dos Mínimos Quadrados (MMQ) atribuído ao Carl Friedrich Gauss - matemático alemão - torna-se possível estimar os melhores \\(\\beta_0\\) e \\(\\beta_1\\) que minimizam os erros. Como não podemos observar a função de regressão populacional (FRP), precisamos estimálo por meio da função de regressão amostral: \\[Y_i=\\hat{\\beta_0}+\\hat{\\beta_1}X_i+\\hat{\\mu_i} \\\\ Y_i=\\hat{Y_i}+\\hat{\\mu_i} \\\\ \\mbox{Logo temos que} \\rightarrow \\ \\hat{\\mu_i}=Y_i-\\hat{\\beta_0}-\\hat{\\beta_1} X_i\\] Podemos ver que os erros \\(\\hat{\\mu_i}\\) (resíduos) são basicamente as diferenças entre os valores observados e estimados de \\(Y\\). Ao caso de dados com \\(n\\) pares de observações de \\(Y\\) e \\(X\\), queremos encontrar a FRA que se encontra o mais próximo possível do \\(Y\\) observado, ou seja, escolher a FRA de modo que a soma dos resíduos \\(\\sum \\hat{\\mu}_i=\\sum(Y_i-\\hat{Y_i})\\) seja a menor possível. Porém, como se pode ver pelo diagrama de dispersão na Figura 6.5, os erros possuem a mesma importância com variações entre sinais positivos e negativos e sua somatória será zero. Isso dificultari a possibilidade de minimizarmos. Figura 6.5: Critério do minímos quadrados Gujarati and Porter (2011). Para evitarmos isso, utilizamos o critério dos mínimos quadrados, de modo que elevamos os resíduos ao quadrado. Fazendo isso, o método dá mais peso aos resíduos (não irão mais se anular), podendo visualizar melhor o “tamanho” do erro total e obter propriedades estatísticas mais desejáveis. \\[\\begin{equation} \\sum \\hat{\\mu}^2_i=\\sum(Y_i-\\hat{Y_i})^2 \\\\ = \\sum (Y_i-\\hat{\\beta_0}-\\hat{\\beta_1})X_i^2 \\tag{6.8} \\end{equation}\\] O método dos mínimos quadrados nos oferece estimativas únicas de \\(\\beta_0\\) e \\(\\beta_1\\) que proporcionam o menor valor possível (encontrando \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\)) de \\(\\sum \\hat{\\mu}_i\\). Por meio de cálculo diferenciável (recomendo o leitor interessado em se aprofundar na definição matemática buscar literaturas em foco estatísticoler, como por exemplo a seção 3A de Gujarati and Porter (2011)) encontra-se: \\[\\begin{equation} \\sum Y_i=n\\hat{\\beta_0} + \\hat{\\beta_1} \\sum X_i \\tag{6.9} \\end{equation}\\] \\[\\begin{equation} \\sum Y_i X_i=\\hat{\\beta_0} \\sum X_i + \\hat{\\beta_1} \\sum X_i^2 \\tag{6.10} \\end{equation}\\] AQUI VOU COLOCAR DO JEITO Q FIZ EM ECONOMETRIA COM AS DEFINCOES E AS DERIVADAS Para que seja feito o modelo de regressão, ela depende das premissas: independência das variáveis erro, homogeneidade das variâncias, normalidade e relação linear entre as variáveis. Coeficiente de determinação \\(r^2\\): medir a qualidade de seu ajuste Estimamos os parâmetros e o erro da função, agora precisamos considerar a qualidade do ajuste da linha de regressão ajustada a um conjunto de dados, ou seja, vamos descobrir quão “bom” o ajuste dessa linha de regressão amostral é adequada aos dados. Se todas as observações estivessem exatamente em cima da linha de regressão, seria “perfeito”, o que raramente acontece e provávelmente seria um problema de Overfitting (será apresentado no próximo capítulo para verificarmos a validade do modelo). O coeficiente de terminação \\(r^2\\) é um medida que diz quanto a linha de regressão amostral ajusta-se aos dados. Para entendermos melhor, vamos visualizar por Diagrama de Venn (Kennedy 1981). O círculo \\(Y\\) representa a variação da variável dependente \\(Y\\) e o círculo \\(X\\), a variação da variável explanatória \\(X\\) como vimos em regressão linear. A área sombreada indica o quanto em que a variação de \\(Y\\) é explicada pela variação de \\(X\\). Quanto maior a área sobreposta, maior a parte da variação de \\(Y\\) é explicada por \\(X\\). O coefiente de determinação \\(r^2\\) é apenas a medida numérica dessa sobreposição. Na Figura 6.6, conforme move-se da esquerda para a direita, a sobreposição aumenta, ou seja, uma proporção cada vez maior da variação de \\(Y\\) é explicada por \\(X\\) (o \\(r^2\\) aumenta). Sem sobreposição, \\(r^2=0\\) e com total sobreposição, \\(r^2=1\\), pois 100% da variação de \\(Y\\) é explicada por \\(X\\). Portanto o coefienciente situa-se no intervalo entre 0 e 1. Figura 6.6: Critério do minímos quadrados Gujarati and Porter (2011). Podemos chegar ao coeficiente de determinação apenas por manipulação algébrica: \\[\\mbox{sabemos que:} \\ y_i=\\hat{y}_i+\\hat{\\mu}_i \\\\ \\mbox{elevando ao quadrado e somando a amostra:} \\ \\sum y^2_i=\\sum \\hat{y}^2_i+\\sum \\hat{\\mu}^2_i+2\\sum \\hat{y}_i \\hat{\\mu}_i \\\\ \\mbox{como} \\ \\sum \\hat{\\mu}_i=0, \\ \\mbox{temos que:}\\ \\sum y^2_i= \\hat{y}^2_i+\\sum \\hat{\\mu}^2_i \\\\ \\sum y^2_i=\\hat{\\beta}^2_1 \\sum x_i^2+\\sum \\hat{\\mu}^2_i \\] \\[\\begin{equation} \\mbox{podemos dizer} \\ SQT=SQE+SQR \\tag{6.11} \\end{equation}\\] sendo SQT a soma total dos quadrados, SQE a soma do quadrados explicados e SQR soma dos quadrados dos resíduos. \\[\\mbox{dividindo a equação anterior por SQT:}\\\\ 1=\\frac{SQE}{SQT}+\\frac{SQR}{SQT} \\\\ \\mbox{definindo}\\ r^2 \\ \\mbox{como:} \\ \\frac{SQE}{SQT} \\] \\[\\begin{equation} \\mbox{obtemos:} \\ r^2=1-\\frac{SQR}{SQT} \\rightarrow 1 - \\frac{\\sum \\hat{\\mu}_i}{\\sum (Y_i - \\overline{Y}_i)^2} \\tag{6.12} \\end{equation}\\] Por manipulação algébrica, podemos verificar também que \\(r^2=\\hat{\\beta}^2_1(\\frac{S^2_x}{S^2_y})\\), sendo \\(S^2_x\\ \\mbox{e} \\ S^2_y\\) as respectivas variâncias amostrais de \\(X\\) e \\(Y\\). Note que ao aplicarmos a raiz quadrada no coeficiente de determinação obtemos o coeficiente de correlação visto em 6.1.3, que mede o grau de associação entre duas variáveis. \\[r=\\pm \\sqrt{r^2}\\] AQUI VOU COLOCAR UM EXEMPLO DE REGRESSOA PARA ENTENDER E PARTE MATEMATICA e falar de ANOVA Não esqueça: dependendo das variáveis em estudo é possível que haja comportamento polinomial ao observarmos no gráfico, podendo ser quadrática, cúbica, etc. Os procedimentos são os mesmos de que linear, mas basicamente incluímos a variável e seu respectivo grau. Dependendo do comportamento muitas vezes é mais fácil ao invés e manter em exponencial (não linear), linearizarmos a função por meio dos logaritmos, semi-logaritmicos entre outros. Isso faz com que temos menos trabalho para tratarmos e estimarmos os parâmetros da função exponencial. Figura 6.7: Em (a) curva de função exponencial e (b) após aplicarmos o logaritmo (Gujarati and Porter 2011). Atualmente é bem comum utilizarmos o modelo log-log, pois seu coeficiente angular \\(\\beta_i\\) mede a elasticidade de \\(Y\\) em relação a \\(X\\), ou seja, a variação percentual de \\(Y\\) correspondente a uma variação percentual em \\(X\\). Por exemplo: na Figura 6.7 se \\(Y\\) representa a quantidade demandada de camisetas e \\(X\\) seu preço unitário. Em (a) temos a relação da quantidade de demanda por camisetas e o preço, mas com a transformação logaritmica teremos a estimação de \\(-\\beta_2\\) (pois é uma reta descendente) que indica a elasticidade preço (variação em \\(ln(Y)\\) por unidade de variação em \\(ln(X)\\)). Portanto teríamos a variação percentual da quantidade demandada de camisetas dada uma variação percentual do preço. Atente-se: porcentagem (Gujarati and Porter 2011). Resumo geral: Em palavras, r2 mede a proporção ou percentual da variação total de Y explicada pelo modelo de regressão. 6.4.2 Regressão Linear Múltipla Na prática deparamos com muitas outros fatores que podem influenciar em sua variável dependente \\(Y\\). Portanto são acrescentadas dentro de seu modelo de regressão mais variáveis, o que é conhecido como Regressão Linear Múltipla, nada mais do que uma ampliação da regressão linear simples. Num modelo, por exemplo, com três variáveis (caso mais simples) pode ser expressa para a amostra como: \\[\\begin{equation} Y_i=\\hat{\\beta_0}+\\hat{\\beta_{1}}X_{1i}+\\hat{\\beta_{2}}X_{2i}+\\mu_i \\tag{6.13} \\end{equation}\\] Da mesma forma, \\(Y_i\\) a variável dependente, \\(X_{2}\\) e \\(X_{3}\\) as independentes explanatórias (explicativa), \\(\\mu_i\\) o erro estocático e \\(i\\) para indicar \\(i\\)-ésima observação. Ao caso dos parâmetros, \\(\\beta_0\\) como intercepto, \\(\\beta_1\\) e \\(\\beta_2\\) os coeficientes parciais de regressão/angulares. \\(\\beta_2\\) mede a variação no valor médio de \\(Y\\) (esperança de \\(Y\\)), por unidade de variação em \\(X_2\\), mantendo \\(X_3\\) constante, ou seja, traz o efeito “direto” de uma unidade de variação em \\(X_2\\) sobre o valor médio de \\(Y\\), excluindo o efeito de \\(X_3\\) na média de \\(Y\\). De mesmo modo, \\(X_3\\) com \\(X_2\\) constante. A regressão múltipla pressupõe as mesma hipóteses de que a regressão linear simples, porém como acréscimo - e muito importante- que as variáveis independentes devem estar ausentes de multicolinearidade, ou seja, não devem haver relação linear entre si. Se essa relação linear existir entre \\(X_2\\) e \\(X_3\\) são colineares ou linearmente dependentes, do contrário linearmente independentes. Caso a multicolinearidade for perfeita, os coeficientes de regressão das variáveis \\(X\\) serão indeterminados e seus erros padrão, infinitos. Se a multicolinearidade for menos que perfeita, serão determinado mas com grandes erros padrão (em relação aos próprios coeficientes), o que trará um modelo ruim para sua estimação. Para medirmos a multicolinearidade é comum a análise de correlação de pearson entre todas as variáveis, como mencionada em Medidas de Dependência 6.1.3, ou analisar a ocorrência de intervalo de confiança mais amplo, verificação de razões “t” insignificantes mesmo que seu \\(R^2\\) esteja alto, parâmetros estimados muitos sensíveis a qualquer alteração de dados e comumente utilizado para verificar o fator de inflação de variância (FIV) (Montgomery, Peck, and Vining 2012), que pode ser expressa como: \\[\\begin{equation} VIF_j=\\frac{1}{1-r^2_j} \\ \\ j=1,2,...,p \\tag{6.14} \\end{equation}\\] sendo \\(r^2\\) o coeficiente de correlação ao quadrado e \\(j\\) para referir as variáveis. Por exemplo, se \\(r^2_{23}\\), refe-se ao coeficiente de correlação entre as variáveis \\(X_2\\) e \\(X_3\\). Segundo ,quando este indicador apresenta o valor acima de cinco, é possível a existência de multicolinearidade (Maroco 2014). De mesmo modo que em regressão linear simples, são estimados os MQO, Máxima verossimilhança e o coeficiente de determinação múltiplo \\(R^2\\) (mesma interpratação para regressão linear simples \\(r^2\\)) para que se obtenha a melhor aproximação possível. 6.4.3 Modelo de Probabilidade Linear (MPL) Considerando um modelo típico de regressão linear simples: \\[\\begin{equation} Y_i=\\beta_0+\\beta_1 X_i+\\mu_i \\tag{6.6} \\end{equation}\\] em que \\(X =\\)sua renda e \\(Y=1\\) de que você compre um celular e \\(0\\) não compre. Como o regressando é binário, ou dicotômico, chamamos de probabilidade linear (MPL). Pode ser interpretada como probabilidade condicional de que o evento ocorra dado \\(X_i\\), isto é, Pr \\((Yi = 1 | Xi)\\). Neste caso, é a probabilidade de você comprar um celular e cuja renda é dado por \\(X_i\\). Para entender este modelo, vamos supor \\(E(\\hat{\\mu}_i)=0\\) para evitarmos estimadores tendenciosos (erros). Portanto: \\[\\begin{equation} E(Y_i|X_i)=\\beta_0+\\beta_1 X_i \\tag{6.15} \\end{equation}\\] Com \\(P_i=\\)probabilidade de que \\(Y_i=1\\)(ocorrência do evento) e \\((1-P_i)\\)=probabilidade de \\(Y_i=0\\)(não ocorrência do evento). \\(Y_i\\) possui a seguinte distribuição de probabilidade de Bernoulli: \\(Y_i\\) Probabilidade \\(0\\) \\(1-P_i\\) \\(1\\) \\(P_i\\) Total \\(1\\) Aplicando a esperança, obtemos: \\[\\begin{equation} E(Y_i)=0(1-P_i)+1(P_i)=P_i \\tag{6.16} \\end{equation}\\] Igualando (6.16) com (6.15), obtemos: \\[\\begin{equation} E(Y_i|X_i)=\\beta_0+\\beta_1 X_i \\tag{6.17} \\end{equation}\\] Isso verifica que a esperança condicional do modelo de regressão (6.6) pode ser interpretada como a probabilidade condicional de \\(Yi\\). Note que, como explicado em 1.2 sobre Distribuição Bernoulli e Distribuição Binominal, caso haja \\(n\\) observações independentes, cada um com uma probabilidade \\(p\\) (sucesso) e probabilidade \\((1 - p)\\) (fracasso) e \\(X\\) dessas observações representarem o número de sucessos, \\(X\\) então segue a distribuição binomial (com médi \\(np\\) e variância \\(np(1-p)\\). Lembrando que a probabilidade \\(P_i\\) situa-se entre 0 e 1 \\(\\rightarrow 0 \\leq E(Y_i|X_i) \\leq 1\\). Alguns detalhes importantes: A hipótese de normalidade de \\(\\mu_i\\) não se verifica no caso dos modelos de probabilidade linear, pois os termos de erro assumem também apenas dois valores, seguindo a distribuição de Bernoulli. Se objetivo for a estimação pontual, a hipótese de normalidade deixa de ser necessária (Gujarati and Porter 2011) e que conforme aumentamos o tamanho da amostra indefinidamente, os estimadores de MQO tendem geralmente a distribuir-se normalmente. Como sabe-se, a média e variância de uma distribuição Bernoulli possuem respectivamente \\(p\\) e \\(p(1-p)\\). Logo a variância é heterocedástica \\(var(\\mu_i)=P_i(1-P_i)\\) e portanto os estimadores de MQO não são eficientes (não possuem variância mínima). Podemos fazer a transformação para que seja homocedástico: \\[\\sqrt{E(Y_i|X_i)-[1-E(Y_i|X_i)]}=\\sqrt{P_i(1-P_i)=\\sqrt{w_i}}\\] \\[\\begin{equation} \\frac{Y_i}{\\sqrt{w)i}} = \\frac{\\beta_0}{\\sqrt{w)i}}+\\frac{\\beta_1 X_i}{\\sqrt{w)i}}+\\frac{\\mu_i}{\\sqrt{w)i}} \\tag{6.18} \\end{equation}\\] Com a transformação, pode-se calcular por MQO (ponderados). 6.4.3.1 Alternativas para o MPL Como mencionado, a probabilidade condicional situa-se entre \\(0\\) e \\(1\\), porém por MQO não levarem em conta esta restrição. Pode-se verificar os valores que constam entre o intervalo, considerando os valores negativos como \\(0\\) e maiores que \\(1\\) como iguais a \\(1\\) ou aplicar algum outro modelo para garanti-los dentro dos intervalos. O \\(R^2\\) costuma-se situar muito abaixo de 1. Por ser limitado em caso de modelos binários, muitos pesquisadores buscam evitar seu uso. Os modelos mais comuns para ser utilizado como alternativa ao MPL são o logit e o probit para evitar estes problemas. 6.4.3.2 Logit A fim de fazer com que \\(P_i\\) varie entre 0 e 1 e relacione-se linearmente a \\(X_i\\), a função de distribuição logística pode ser expressa como: \\[\\begin{equation} P_i=\\frac{1}{1+e^{-Z_i}}=\\frac{e^Z_i}{1+e^Z_i} \\tag{6.19} \\end{equation}\\] e \\((1-P_i)\\) da probabilidade fracasso: \\[\\begin{equation} 1-P_i=\\frac{1}{1+e^{Z_i}}\\rightarrow e^{Z_i} \\tag{6.20} \\end{equation}\\] onde \\(Z_i=\\beta_0+\\beta_1X_i\\). Assim \\(Z_i\\) varia de \\(-\\infty\\) a \\(\\infty\\) e portanto \\(P_i\\) entre 0 e 1. Para estimarmos a MQO, precisamos linearizar a função: \\[\\begin{equation} L_i=ln(\\frac{P_i}{1-P_i})=Z_i=\\beta_0+\\beta_1 X_i \\tag{6.21} \\end{equation}\\] O modelo logit faz com que: A probabilidade varie entre 0 e 1, enquanto \\(Z\\) e \\(L\\) possam variar de \\(-\\infty\\) a \\(\\infty\\); Mesmo que as probabilides não sejam lineares, \\(L\\) é linear em \\(X\\); Pode-se aplicar com mais regressores e com mesma interpretação angular medindo a variação de \\(L\\) para uma unidade variação em \\(X\\) e para o intercepto; Se \\(L\\) torna-se maior e positivo quando as chances do evento de interesse ocorrer aumenta, do contrário (maior e negativo) de não ocorrer; Como em MPL, o modelo Logit é heterocedástico precisa-se ponderar (Gujarati and Porter 2011; Cox 1970): \\[\\begin{equation} \\sqrt{w_i}L_i=\\beta_0 \\sqrt{w_i}+\\beta_1\\sqrt{w_i}X_i+\\sqrt{w_i}\\mu_i \\tag{6.22} \\end{equation}\\] em que, com a variância \\(\\hat{\\sigma}^2=\\frac{1}{N_i\\hat{P_i}(1-\\hat{P_i})}\\), \\(W_i\\) é o peso \\(N_i\\hat{P_i}(1-\\hat{P_i})\\). Por fim, aplicar o mínimos quadrados ponderados (da mesma forma que MQO, porém com a nova transformação de dados) e estimarmos os parâmetros normalmente. Como o \\(R^2\\) não é significativa nos modelos binários. É comum utilizar as pseudo $R^2 [long1997regression] - existe uma variedade delas - ou o Count \\(R^2\\) que nada mais é que o número de previsões corretas com o número total de observações. Para a hiótese nula de que todos os coeficientes angulares são simultâneamente iguais a zero, utiliza-se a estatística da razão de verossimilhança que segue a distribuição \\(\\chi^2\\) que equivale ao teste F. 6.4.3.3 Probit 6.4.3.4 Tobit 6.4.4 Exemplos 6.5 Gradiente Descendente (GD) Para a obtenção dos parâmetros de forma analítica, como regressões, muitas vezes é difícil obter os parâmetros que minimizam determinada função de interesse. Dificuldades em obter a solução do sistema na forma fechada (ou não existir) ou quando \\(n\\) é muito grande, o cálculo da inversa (estimando os parâmetros matricialmente) pode ser muito caro computacionalmente. O Gradiente Descendente (GD) pode ser muito útil dependendo da situação, conhecido também como máximo declive, é um método númerico utilizado em otimização. Tem como finalidade identificar um mínimo local de uma função de modo iterativo, no qual a cada iteração toma-se a direção do gradiente. Muitas vezes serve como base para algoritmos de segunda ordem como Métodos de Newton, por exemplo. É uma função para casos gerais, por praticidade vamos supor que temos uma função denominada custo com apenas dois parâmetros \\(J(\\theta_0,\\theta_1)\\) e queremos estimar seus parâmetros que minimizam seus erros. Inicialmente atribuímos quaisquer estimativas iniciais para valores de \\(\\theta_0\\) e \\(\\theta_1\\), com o GD vamos alterandos os valores dos \\(\\theta&#39;s\\) para reduzirmos \\(J(\\theta_0,\\theta_1)\\) até que se chegue a um valor mínimo local. Um exemplo que gosto muito, por NG, Andrew Y. (2019): observe a Figura 6.8 e imagine que você está em um campo, com dois montes. Mantenha sua imaginação de que está situado na cruz preta - ponto 0 - no primeiro monte vermelho. Com o GD vamos olhar 360 graus ao redor do ponto em que você está situado apenas para descobrir a resposta de que “se você fosse dar um pequeno passo em alguma direção ao seu redor com o objetivo de ir para o ponto mais baixo do campo o mais rápido possível, para qual direção você deve andar?” Supondo que após olhar para todos os lados, com análise de GD você descobriu que seu primeiro passo será no ponto 1 da Figura 6.8. Após isso, você observa novamente para todos os lados e faz outra análise de GD para verificar aonde você vai se deslocar em seu segundo passo para chegar o mais rápido possível até concluir que será o ponto 2. Assim, sucessivamente, você vai se deslocando para os respectivos pontos 3, 4 e sucessivamente até convergir em seu objetivo Z, porém caso você iniciasse pelo ponto K, é bem possível que por meio do GD você descesse o monte por outro trajeto, encontrando outros pontos ótimos locais até chegar a outro ponto otimizado (descer por completo o monte). Esta é a ideia do Gradiente Descendente, por meio de iterações, o algoritmo vai identificando os pontos ótimos (estimadores mínimos) até convergir num ótimo local da função. Em caso de funções simples como regressão linear, não é necessário o uso de GD. Mas em casos com muitas variáveis e ordens, pode ser bem viável. Figura 6.8: Gráfico tridimensional a exemplo de Gradiente Descendente (NG, Andrew Y. 2019). O algoritmo pode ser expresso como: \\[\\begin{equation} \\theta_j := \\theta_j - \\alpha \\frac{d}{d \\theta_j}J(\\theta_0,\\theta_1) \\ \\mbox{com} \\ j=\\theta_0 \\ \\mbox{e} \\ j=\\theta_1 \\tag{6.23} \\end{equation}\\] com \\(j\\) referindo-se à quantidade de observações (parâmetros que pretendemos estimar) da amostra. O algoritmo é processado da seguinte forma: imagine na mesma Figura 6.8 que você irá dar seu primeiro passo, olhou os 360 graus e inseriu as variáveis em seu algoritmo de GD e seu destino é em \\(Z=10\\). Seu algoritmo calcula se você passou seu destino mais do que devia ou se você está atrás de \\(Z\\) ainda e também verifica se precisa dar passos grandes por estar bem longe de seu destino, ou passos menores. Supondo que seu \\(\\alpha\\) um pouquinho alto, podemos dar um passo grande para descer o monte (1) pela diferença da observação que você inseriu com \\(\\alpha \\frac{d}{d \\theta_j}J(\\theta_0,\\theta_1)\\). Caso fosse uma taxa pequena de \\(\\alpha\\), seu passo seria menor e sua derivada (taxa de variação) vai lhe dizer se você passou do ponto ótimo de \\(Z\\) (o quão a frente) ou está para trás (quão para trás) desse ponto ótimo. Com o primeiro passo dado (supor passo \\(1 = 40\\)), você precisa fazer o mesmo procedimento tomando agora o passo 1 como se fosse o inicial novamente, ou seja, atualizando sua função para cada \\(\\theta\\) simultâneamente (caso dois \\(\\theta\\)’s de entrada para a função, atualiza-se para ambos) até encontrar o novo valor ótimo do próximo passo no ponto \\(2=15\\). Conforme vai se aproximando de \\(Z\\), seus passos vão ficando cada vezes menores ( de 15 para 11; de 11 para 10,50; de 10,50 para 10,10; de 10,10 para 10,05; etc) até chegar na melhor aproximação de \\(Z=10\\) que é o ponto ótimo da função. Assim o algoritmo encontra os melhores parâmetros para buscar o ponto otimizado, com a estimatiza dos melhores parâmetros para a aproximação com os menores erros (sim! Podemos encontrar os parâmetros dos exemplos de regressão com este algoritmo também!) Desta forma, atribuímos (“\\(:=\\)”) para a própria observação de entrada da função receber ela mesma subtraída \\(\\alpha\\) que multiplica a derivada da função em relação a observação de entrada. Para que atualize a cada passo (iteração). \\(\\alpha\\)( learning rate - taxa de aprendizagem) é um valor fixo que controla o tamanho do passo em cada iteração: quando \\(\\alpha\\) for pequeno, o método fica lento, quando grande ele pode falhar na convergência e até mesmo divergir. Seu valor depende muito da pesquisa e de suas fundamentações teóricas, o que recomendo o leitor quando utilizar este método verificar um valor adequado, pode ser que dependendo do valor da taxa demore muito para finalizar o algoritmo pela quantidade de iterações (tamanhos de passos muito pequenos) ou divergir (tamanho de passos muito grandes). Rendle and Schmidt-Thieme (2008) divulgaram que a fatoração de matrizes para a predição de ratings nos dados do desafio Netflix precisou de 200 iterações, usando uma taxa de aprendizagem de 0,01. Para facilitar a compreensão do efeito da taxa de variação, observe a Figura ??. No primeiro gráfico você inicia seu algoritmo com o valor \\(\\theta\\) e com a derivada podemos observar que inclinação da reta tangente ao ponto é positiva (\\(\\frac{d}{d\\theta}j(\\theta)\\geq 0\\)), portanto em \\(\\theta=\\theta-\\alpha.\\mbox{um valor positivo}\\), faz que com que esse novo \\(\\theta\\) (segunda iteração) seja menor que o da primeira iteração, visto que terá que subtrair e deslocar-se para esquerda para tender ao ponto mínimo. Da mesma forma, ao segundo gráfico, podemos verificar que a inclinação é negativa (\\(\\frac{d}{d\\theta}j(\\theta)\\leq 0\\)), portanto \\(\\theta=\\theta-\\alpha.\\mbox{um valor negativo}\\), fará com que o novo \\(\\theta\\) seja maior do que da primeira iteração, pois irá somar e deslocar-se para direita tendendo ao ponto mínimo. Figura 6.9: Efeito da taxa de variação no Gradiente Descendente. Como pode-se perceber, a taxa de aprendizagem e a taxa de variação são fundamentais e complementares para o algoritmo de GD, pois elas dizem o tamanho do passo e em que posição estamos em relação ao ponto ótimo da função. 6.5.1 Exemplos Uma variável:Vamos supor a seguinte função custo: \\[j(\\theta)=\\theta^2\\] Queremos minimizá-la \\(min \\ j(\\theta)\\). Portanto precisamos inicialmente colocar um número aleatório para nosso parâmetro - não ótimo - para que o algoritmo atualize a cada iteração. Vamos supor a taxa de aprendizagem (learning rate) \\(\\alpha=0,1\\) e \\(\\theta=4\\) para facilitar. Ou seja, \\(j(\\theta)=4^2=16\\). Vamos atualizar os parâmetros: \\[\\theta := \\theta-\\alpha.\\frac{d}{d\\theta}j(\\theta) \\\\ \\mbox{derivando a função} \\ j(\\theta)=\\theta^2 \\ \\mbox{e substituindo:} \\\\ \\theta:= \\theta -\\alpha.2\\theta \\\\ \\mbox{substituindo os valores de}\\ \\alpha\\ \\mbox{e}\\ \\theta: \\\\ \\theta:=4-0,1 \\ .\\ 2\\ .\\ 4 \\\\ \\rightarrow \\theta:=3,2 \\] Na iteração obtemos \\(\\theta=3,2\\). Se subsituirmos em \\(j(\\theta)\\) novamente, iremos obter \\(j(\\theta)=(3,2)^2=10,24\\). Agora atualizando novamente para a próxima iteração: \\[\\theta:= \\theta -\\alpha.2\\theta \\\\ \\theta:=3,2-0,1\\ .\\ 2\\ .\\ 3,2 \\\\ \\theta:= 2,56\\] Portanto, \\(j(\\theta)=(2,56)^2=6,55\\). Sucessivamente, vamos fazendo as iterações até convergir: \\(\\theta\\) \\(j(\\theta)\\) 4 16 3,2 10,24 2,56 6,55 2,04 4,19 1,632 2,663 . . . . . . 0 0 Da mesma forma, se iniciarmos o algoritmo com -4: \\(\\theta\\) \\(j(\\theta)\\) -4 16 -3,2 10,24 -2,56 6,55 -2,04 4,19 -1,632 2,663 . . . . . . 0 0 Note que conforme \\(\\theta\\) diminui, o custo também. Conforme mais iterações são aplicadas, mais “ótimo” será. Graficamente: Duas variáveis: Vamos supor a seguinte função de custo com \\(\\alpha=0,1\\), \\(\\theta_1=1\\) e \\(\\theta_2=2\\): \\[j(\\theta_1,\\theta_2)=\\theta_1^2+\\theta_2^2 \\\\ j(\\theta_1,\\theta_2)=1^2+2^2=5\\] Queremos \\(min \\ j(\\theta_1,\\theta_2)\\)Como explicado, ao caso de haver mais de um parâmetro precisamos separar atualizar cada um simultâneamente e aplicar derivada parcial em sua função: \\[\\theta_1:=\\theta_1-\\alpha \\frac{d}{d\\theta_1}j(\\theta_1,\\theta_2) \\ \\ \\mbox{e}\\ \\ \\theta_2:=\\theta_2-\\alpha \\frac{d}{d\\theta_2}j(\\theta_1,\\theta_2) \\\\ \\mbox{calculando as derivadas parciais de}\\ j(\\theta_1,\\theta_2)=\\theta_1^2+\\theta_2^2\\ \\mbox{obtemos:}\\\\ \\frac{d}{d\\theta_1}j(\\theta_1,\\theta_2)=2\\theta_1 \\ \\ \\mbox{e}\\ \\ \\frac{d}{d\\theta_2}j(\\theta_1,\\theta_2)=2\\theta_2\\] \\[\\mbox{substituindo:} \\\\ \\theta_1:=\\theta_1-\\alpha.\\ 2\\theta_1 \\ \\ \\mbox{e}\\ \\ \\theta_2:=\\theta_2-\\alpha .\\ 2\\theta_2 \\\\ \\mbox{inserindo os valores:}\\\\ \\theta_1:=1-0,1.\\ 2.\\ 1 \\ \\ \\mbox{e}\\ \\ \\theta_2:=2-0,1.\\ 2.\\ 2 \\\\ \\theta_1:=0,8 \\ \\mbox{e} \\ \\theta_2=1,6\\] Portanto após a iteração, temos que \\(j(\\theta_1,\\theta_2)=0,8^2+1,6^2=3,2\\). Da mesma forma, para a próxima iteração temos: \\[\\theta_1:=0,8-0,1.\\ 2.\\ 0,8 \\ \\ \\mbox{e}\\ \\ \\theta_2:=1,6-0,1.\\ 2.\\ 1,6 \\\\ \\theta_1:=0,64 \\ \\mbox{e} \\ \\theta_2=1,28\\] Portanto teremos \\(j(\\theta_1,\\theta_2)=0,64^2+1,28^2=2,048\\). Assim sucessivamente: \\(\\theta_1\\) \\(\\theta_2\\) \\(j(\\theta_1,\\theta_2)\\) 1 2 5 0,8 1,6 3,2 0,64 1,28 2,48 . . . . . . . . . 0 0 Por fim, o gráfico: Erro quadrado médio (Regressão Linear Simples:) Observe a função de regressão linear: \\[f_\\theta(X)=\\theta_0+\\theta_1*X\\] A função de custo: \\[j(\\theta)=\\frac{1}{m}\\displaystyle \\sum^m_{i=1}(f_\\theta(x^i)-y^i)^2\\] Primeiramente vamos encontrar a derivada parcial de \\(j(\\theta_0,\\theta_1)\\): \\[\\frac{d}{d\\theta_0}j(\\theta_0,\\theta_1=\\frac{d}{d\\theta_0}(\\frac{1}{m}\\displaystyle \\sum^m_{i=1}(f_{\\theta}(x^i)-y^i)^2) \\rightarrow \\frac{2}{m}\\displaystyle \\sum^m_{i=1}(f_\\theta(x^i)-y^i) \\\\ \\frac{d}{d\\theta_1}j(\\theta_0,\\theta_1=\\frac{d}{d\\theta_1}(\\frac{1}{m}\\displaystyle \\sum^m_{i=1}(f_{\\theta}(x^i)-y^i)^2) \\rightarrow \\frac{2}{m}\\displaystyle \\sum^m_{i=1}(f_\\theta(x^i)-y^i)x^i\\] Com isso, basta aplicarmos o banco de dados de \\(X\\) e \\(Y\\) em seu modelo e de seus dois \\(\\theta&#39;s\\) de entrada. Repetindo as iterações e identificando os parâmetros que se aproximam References "]
]
