[
["algoritmos-de-aprendizagem.html", "Capítulo 6 Algoritmos de Aprendizagem 6.1 Medidas de importância 6.2 Teste de hipóteses e Análise de Variância 6.3 Naive Bayes 6.4 Regressão 6.5 Gradiente Descendente 6.6 SVM 6.7 Arvores de Decisão 6.8 Elastic Net 6.9 KNN 6.10 K-means 6.11 PCA 6.12 Clusters 6.13 AOC E ROC", " Capítulo 6 Algoritmos de Aprendizagem Existe uma infinidade de algoritmos utilizados em machine learning, cada um com uma finalidade específica. Há também características que podem inviabilizar a escolha do modelo mais preciso para determinado problema, como a utilização alto poder computacional. 6.1 Medidas de importância Um atributo é dito importante se quando removido a medida de importância considerada em relação aos atributos restantes é deteriorada , seja a precisão da medida, consistência, informação, distância ou dependência Tradução de Liu and Motoda (2012). É fundamental estimarmos a importância de um atributo, tanto uma avaliação individual quanto à avaliação de subconjuntos de atributos. É uma questão complexa e multidimensional (Liu and Motoda 2012). Podemos avaliar se os atributos selecionados pela etapa do pré-processamento auxiliam a melhorar a precisão do classificador ou a simplifcar algum modelo construído. A seguir, apresenta-se algumas medidas utilizadas (Lee 2005). 6.1.1 Medidas de Informação As medidas de informação determinam o ganho de informação a partir de um atributo. O ganho de informação é definido como a diferença entre a incerteza a priori e a incerteza a posteriori considerando-se o atributo \\(X_i\\). \\(X_i\\) é preferido ao atributo \\(X_j\\) se seu ganho de informação for maior que de \\(X_j\\). Uma das mais utilizadas é a entropia que normalmente é usada na teoria da informação para medir a pureza ou impureza de um determinado conjunto. Shannon (1948), tomou como “ponto de partida” encontrar uma forma matemática de medir o quanto de informação existe na transmissão de uma mensagem de um ponto a outro, denominando-a entropia. Sua proposta baseava-se na ideia de que o aumento da probabilidade do próximo símbolo diminuiria o tamanho da informação. Com isso, a entropia pode ser definida como a quantidade de incerteza que há em uma mensagem e que diminui à medida que os símbolos são transmitidos (vai se conhecendo a mensagem), tendo-se então a informação, que pode ser vista como redução da incerteza (Shannon 1948; Paviotti and Magossi 2019). Por exemplo: ao utilizarmos como idioma a nossa língua portuguesa e ao transmitir como símbolo a letra “q”, a probabilidade do próximo símbolo ser a letra “u” é maior que a de ser qualquer outro símbolo, enquanto que a probabilidade de ser novamente a letra “q” é praticamente nula (Paviotti and Magossi 2019). Shannon define que a entropia pode ser calculada por meio da soma das probabilidades de ocorrência de cada símbolo pela expressão \\(∑ p_i = 1 = 100\\%\\), em que \\(p_i\\) representa a probabilidade do i-ésimo símbolo que compõe a mensagem. Segundo ele, estes símbolos devem ser representados através de sequências binárias, utilizando das propostas de Nyquist (1924) e Hartley (1928). Sua proposta consistia em representar símbolos de um alfabeto através de um logaritmo de acordo com suas respectivas unidades de informação. A entropia proposta por ele é obtida pela média das medidas de Hartley (Moser and Chen 2012). Se A é discreto com distribuição de probabilidade \\(p(A)\\), a entropia será: \\[\\begin{equation} H(A)=- \\sum p(A)log_2(p(A)) \\tag{6.1} \\end{equation}\\] Para facilitar a compreensão, vamos supor um exemplo de um questionário com resposta binária entre “Sim” e “não”: quanto mais distribuído as probabilidades das respostas, mais desorganizada é, logo maior suaa entropia, do contrário caso for uma probabilidade de ser zero “sim”/“não” ou de ser 1 (100%), ou seja, ter apenas uma opção de resposta, será menos distribuído e portanto menor usa entropia. Figura 6.1: Gráfico de Probabilidade x Entropia. O ganho de informação portanto mede a redução da entropia (nesse caso) causada pela partição dos exemplos de acordo com os valores do atributo. \\[\\begin{equation} \\mbox{Ganho de Informação}(D,T)=\\mbox{entropia}(D)-\\displaystyle \\sum_{i=1}^k \\frac{|D_i|}{|D|}. \\mbox{entropia}(D_i) \\tag{6.2} \\end{equation}\\] É muito utilizado em algoritmo de Árvore de decisão que será apresentado nesta mesma seção com um exemplo de seu uso. 6.1.2 Medidas de Distância Também conhecidas com medidas de separabilidade, discriminação e divergência. Em caso de duas classes, um atributo \\(X_i\\) é preferido ao atributo \\(X_j\\) se fornece uma diferença maior que \\(X_j\\) entre as probabilidades condicionais das duas classes. Uma das mais utilizadas é a distância Euclidiana. 6.1.3 Medidas de Dependência Figura 6.2: Padrões de correlação. Elaborado por Gujarati and Porter (2011) e adaptado Henri (1978). 6.1.4 Medidas de Precisão 6.1.5 Medidas de consistência 6.2 Teste de hipóteses e Análise de Variância 6.3 Naive Bayes Antes de falarmos sobre este algoritmo, vamos para o conceito matemático. Em (1.2) tratamos do Teorema de Bayes para \\(n\\) atributos. Colocando-o como probabilidade condicional: \\[\\begin{equation} p(A|B_{1},...,B_{n}) = \\\\ p(A)p(B_{1}|A)p(B_{2}|A,B_{1}),p(B_{3}|A,B_{1},B_{2})...p(B_{n}|A,B_{1},B_{2},...,B_{n−1}) \\tag{6.3} \\end{equation}\\] Assumindo que cada atributo \\(B_i\\) é condicionalmente independente de todos os outros \\(B_j\\) para \\(j\\neq i\\) e \\(p(B_i|A,B_j)=p(B_i|A)\\) o modelo poderá ser expresso como: \\[\\begin{equation} p(A_k|B_1,...,B_n)=p(A_k)p(B_1|A_k)p(B_2|A_k),...=p(A_k)\\prod_i^n p(B_i|A_k) \\ k ∈{1,...,k} \\tag{6.4} \\end{equation}\\] Por fim para podermos classificarmos, aplicamos argumentos de máxima para otimizarmos a função, obtém-se o classificador de Naive Bayes: \\[\\begin{equation} \\mbox{classificador} \\ \\hat{y}=argmax \\ p(A_k)\\displaystyle \\prod_{i=1}^n p(B_i|A_k) \\ \\ k ∈{1,...,k} \\tag{6.5} \\end{equation}\\] Lembrando que para cada atributo, a sua distribuição de probabilidades é assumida como normal. O Naive Bayes é uma técnica de classificação baseado no teorema de Bayes com uma suposição de independência entre os preditores, ou seja, este classificador assume que a presença de uma característica particular em uma classe não está relacionada com a presença de qualquer outro fator. Por exemplo, uma fruta verde, redonda e com um tamanho de diâmetro X pode ser uma melancia, porém mesmo que estas variáveis dependam uns dos outros e de outras características, todas estas propriedades contribuem de forma independente para a probabilidade de que seja uma melancia. Este modelo é muito utilizado devido que é fácil de construir e particularmente útil para grandes volumes de dados. Porém a própria independência entre os preditores a torna desvantajosa para apliação prática e que variáveis categóricas num conjunto de dados de teste que não foram treinadas, não irá estimar essa nova variável. Exemplo: para facilitar, podemos supor que estamos trabalhando no diagnóstico de uma nova doença e que foi feito testes em 100 pessoas aleatórias (exemplo de Orgânica Digital (2019)). Após coletarmos a análise, descobrimos que das 100 pessoas, 20 possuíam a doença (20%) e 80 pessoas estavam saudáveis (80%), sendo que das pessoas que possuíam a doença, 90% receberam o resultado positivo no teste da doença, e 30% das pessoas que não possuíam a doença também receberam o teste positivo. Caso uma nova pessoa realizar o teste e receber um resultado positivo, qual a probabilidade de ela realmente possuir a doença? Figura 6.3: Dados coletados de uma amostra de 100 pessoas aleatórias. Com o algoritmo de Naive Bayes, buscamos encontrar uma probabilidade da pessoa possuir a doença, dado que recebeu um resultado positivo, multiplicando a probabilidade de possuir a doença pela probabilidade de “receber um resultado positivo, dado que tem a doença”. De mesmo modo verificar a probabilidade de não possuir a doença dado que recebeu um resultado positivo. Ou seja, ao caso de ter a doença dado que o resultado deu positivo: \\[P(doença|positivo) = 20% * 90% \\] \\[P(doença|positivo) = 0,2 * 0,9 \\] \\[P(doença|positivo) = 0,18\\] Para o caso de não ter a doença, dado que deu positivo: \\[P(não \\ doença|positivo) = 80% * 30%\\] \\[P(não \\ doença|positivo) = 0,8 * 0,3\\] \\[P(não\\ doença|positivo) = 0,24\\] Após isso precisamos normalizar os dados, para que a soma das duas probabilidades resulte 1 (100%). Como vimos em pré-processamento 5, a Normalização por reescala por meio de um valor mínimio e um máximo, gera um novo intervalo onde os valores de um atributo estão contidos. Um intervalo entre 0 e 1. Portanto, dividimos o resultado pela soma das duas probabilidades. \\[P(doença|positivo) = 0,18/(0,18+0,24) = 0,4285\\] \\[P(não doença|positivo) = 0,24/(0,18+0,24) = 0,5714\\] Logo, podemos concluir que se o resultado do teste da nova pessoa for positivo, ela possui aproximadamente 43% (0,4285) de chance de estar doente. Observação e resumo geral: Naive Bayes é uma técnica de classificação baseado no teorema de Bayes com uma suposição de independência entre os preditores diferentemente do caso em 1.2 (Teorema de Bayes), ou seja, O Naive Bayes assume que a presença de uma característica particular em uma classe não está relacionada com a presença de qualquer outro fator. Ao caso da melancia, uma fruta verde, redonda e com um tamanho de diâmetro X é possível ser ela, porém mesmo que estas variáveis dependam uma das outras e de outras características, elas contribuem de forma independente para a probabilidade de que seja uma melancia. É um modelo simples de construir e útil para grandes volumes de dados. Porém a própria independência entre os preditores a torna desvantajosa para apliação prática e que variáveis categóricas num conjunto de dados de teste que não foram treinadas, não irá estimar essa nova variável. Por isso Naive vem do significado “ingênuo”, pois como a Figura 6.4 demonstra, os atributos contribuem de forma independente para a probabilidade de A. Figura 6.4: Gráfico de Probabilidade x Entropia. 6.4 Regressão 6.4.1 Análise de Regressão Linear A análise de variância, pressupõe a independência dos efeitos dos diversos tratamentos utilizados no experimento. Quando a hipótese não é verificada, necessitamos refletir a dependência entre os efeitos dos tratamentos. No caso de experimentos quantitativos, frequentemente justifica a existência da equação de regressão, que une os valores dos tratamentos aos analisados. Em grande parte, trata de estimação e/ou previsão do valor médio (para população) da variável dependente com base nos valores conhecidos da variável explanatória, ela é supervisionada. Como na prática não conseguimos análisar uma população, trabalhamos em cima de amostras e estimamos para o todo, para que possamos fazer uma aproximação. Partimos da ideia de estimarmos uma função com dados amostrais com o menor erro possível. Portanto, o \\(Y_i\\) (população) observado pode ser expresso como: \\[\\begin{equation} Y_i=\\hat{Y_i}+\\hat{\\mu_i} \\tag{6.6} \\end{equation}\\] E o modelo para função de regressão amostral: \\[\\begin{equation} Y_i=\\hat{\\beta_0}+\\hat{\\beta_1 X_i}+\\hat{\\mu_i} \\tag{6.7} \\end{equation}\\] em que: \\(\\hat{Y_i}\\) é o valor observado com \\(i\\) níveis de \\(X\\) (estimador da esperança \\(E(Y|Xi)\\)), \\(\\hat{\\beta_0}\\) a constante de regressão estimado e intercepto de \\(\\hat{Y}\\), \\(\\hat{\\beta_1}\\) o coeficiente de regressão estimado que seria a variação de \\(\\hat{Y}\\) em função da variação de cada unidade de \\(X\\), \\(X_i\\) com \\(i\\) níveis da variável independente e \\(\\hat{\\mu_i}\\) é o erro associado à distância entre o valor observado e o correspondente ponto na curva. Note que os “chapéis” em cima das variáveis é utilizado quando referimos a estimações, ou seja, são variáveis de dados amostrais e não a população. Mas como estimâmetros os parâmetros da função de forma que fique mais próxima possível e com o menor erro? Com o Método dos Mínimos Quadrados (MMQ) atribuído ao Carl Friedrich Gauss - matemático alemão - torna-se possível estimar os melhores \\(\\beta_0\\) e \\(\\beta_1\\) que minimizam os erros. Como não podemos observar a função de regressão populacional (FRP), precisamos estimálo por meio da função de regressão amostral: \\[Y_i=\\hat{\\beta_0}+\\hat{\\beta_1}X_i+\\hat{\\mu_i} \\\\ Y_i=\\hat{Y_i}+\\hat{\\mu_i} \\\\ \\mbox{Logo temos que} \\rightarrow \\ \\hat{\\mu_i}=Y_i-\\hat{\\beta_0}-\\hat{\\beta_1 X_i}\\] Podemos ver que os erros \\(\\hat{\\mu_i}\\) (resíduos) são basicamente as diferenças entre os valores observados e estimados de \\(Y\\). Ao caso de dados com \\(n\\) pares de observações de \\(Y\\) e \\(X\\), queremos encontrar a FRA que se encontra o mais próximo possível do \\(Y\\) observado, ou seja, escolher a FRA de modo que a soma dos resíduos \\(\\sum \\hat{\\mu}_i=\\sum(Y_i-\\hat{Y_i})\\) seja a menor possível. Porém, como se pode ver pelo diagrama de dispersão na Figura 6.5, os erros possuem a mesma importância com variações entre sinais positivos e negativos e sua somatória será zero. Isso dificultari a possibilidade de minimizarmos. Figura 6.5: Critério do minímos quadrados Gujarati and Porter (2011). Para evitarmos isso, utilizamos o critério dos mínimos quadrados, de modo que elevamos os resíduos ao quadrado. Fazendo isso, o método dá mais peso aos resíduos (não irão mais se anular), podendo visualizar melhor o “tamanho” do erro total e obter propriedades estatísticas mais desejáveis. \\[\\begin{equation} \\sum \\hat{\\mu}^2_i=\\sum(Y_i-\\hat{Y_i})^2 \\\\ = \\sum (Y_i-\\hat{\\beta_0}-\\hat{\\beta_1 X_i})^2 \\tag{6.8} \\end{equation}\\] O método dos mínimos quadrados nos oferece estimativas únicas de \\(\\beta_0\\) e \\(\\beta_1\\) que proporcionam o menor valor possível (encontrando \\(\\hat{\\beta_0}\\) e \\(\\hat{\\beta_1}\\)) de \\(\\sum \\hat{\\mu}_i\\). Por meio de cálculo diferenciável (recomendo o leitor interessado em se aprofundar na definição matemática buscar literaturas em foco estatísticoler, como por exemplo a seção 3A de Gujarati and Porter (2011)) encontra-se: \\[\\begin{equation} \\sum Y_i=n\\hat{\\beta_0} + \\hat{\\beta_1} \\sum X_i \\tag{6.9} \\end{equation}\\] \\[\\begin{equation} \\sum Y_i X_i=\\hat{\\beta_0} \\sum X_i + \\hat{\\beta_1} \\sum X_i^2 \\tag{6.10} \\end{equation}\\] AQUI VOU COLOCAR DO JEITO Q FIZ EM ECONOMETRIA COM AS DEFINCOES E AS DERIVADAS Para que seja feito o modelo de regressão, ela depende das premissas: independência das variáveis erro, homogeneidade das variâncias, normalidade e relação linear entre as variáveis. Coeficiente de determinação \\(r^2\\): medir a qualidade de seu ajuste Estimamos os parâmetros e o erro da função, agora precisamos considerar a qualidade do ajuste da linha de regressão ajustada a um conjunto de dados, ou seja, vamos descobrir quão “bom” o ajuste dessa linha de regressão amostral é adequada aos dados. Se todas as observações estivessem exatamente em cima da linha de regressão, seria “perfeito”, o que raramente acontece e provávelmente seria um problema de Overfitting (será apresentado no próximo capítulo para verificarmos a validade do modelo). O coeficiente de terminação \\(r^2\\) é um medida que diz quanto a linha de regressão amostral ajusta-se aos dados. Para entendermos melhor, vamos visualizar por Diagrama de Venn (Kennedy 1981). O círculo \\(Y\\) representa a variação da variável dependente \\(Y\\) e o círculo \\(X\\), a variação da variável explanatória \\(X\\) como vimos em regressão linear. A área sombreada indica o quanto em que a variação de \\(Y\\) é explicada pela variação de \\(X\\). Quanto maior a área sobreposta, maior a parte da variação de \\(Y\\) é explicada por \\(X\\). O coefiente de determinação \\(r^2\\) é apenas a medida numérica dessa sobreposição. Na Figura 6.6, conforme move-se da esquerda para a direita, a sobreposição aumenta, ou seja, uma proporção cada vez maior da variação de \\(Y\\) é explicada por \\(X\\) (o \\(r^2\\) aumenta). Sem sobreposição, \\(r^2=0\\) e com total sobreposição, \\(r^2=1\\), pois 100% da variação de \\(Y\\) é explicada por \\(X\\). Portanto o coefienciente situa-se no intervalo entre 0 e 1. Figura 6.6: Critério do minímos quadrados Gujarati and Porter (2011). Podemos chegar ao coeficiente de determinação apenas por manipulação algébrica: \\[\\mbox{sabemos que:} \\ y_i=\\hat{y}_i+\\hat{\\mu}_i \\\\ \\mbox{elevando ao quadrado e somando a amostra:} \\ \\sum y^2_i=\\sum \\hat{y}^2_i+\\sum \\hat{\\mu}^2_i+2\\sum \\hat{y}_i \\hat{\\mu}_i \\\\ \\mbox{como} \\ \\sum \\hat{\\mu}_i=0, \\ \\mbox{temos que:}\\ \\sum y^2_i= \\hat{y}^2_i+\\sum \\hat{\\mu}^2_i \\\\ \\sum y^2_i=\\hat{\\beta}^2_1 \\sum x_i^2+\\sum \\hat{\\mu}^2_i \\] \\[\\begin{equation} \\mbox{podemos dizer} \\ SQT=SQE+SQR \\tag{6.11} \\end{equation}\\] sendo SQT a soma total dos quadrados, SQE a soma do quadrados explicados e SQR soma dos quadrados dos resíduos. \\[\\mbox{dividindo a equação anterior por SQT:}\\\\ 1=\\frac{SQE}{SQT}+\\frac{SQR}{SQT} \\\\ \\mbox{definindo}\\ r^2 \\ \\mbox{como:} \\ \\frac{SQE}{SQT} \\] \\[\\begin{equation} \\mbox{obtemos:} \\ r^2=1-\\frac{SQR}{SQT} \\rightarrow 1 - \\frac{\\sum \\hat{\\mu}_i}{\\sum (Y_i - \\overline{Y}_i)^2} \\tag{6.12} \\end{equation}\\] Por manipulação algébrica, podemos verificar também que \\(r^2=\\hat{\\beta}^2_1(\\frac{S^2_x}{S^2_y})\\), sendo \\(S^2_x\\ \\mbox{e} \\ S^2_y\\) as respectivas variâncias amostrais de \\(X\\) e \\(Y\\). Note que ao aplicarmos a raiz quadrada no coeficiente de determinação obtemos o coeficiente de correlação visto em 6.1.3, que mede o grau de associação entre duas variáveis. \\[r=\\pm \\sqrt{r^2}\\] AQUI VOU COLOCAR UM EXEMPLO DE REGRESSOA PARA ENTENDER E PARTE MATEMATICA Resumo geral: Em palavras, r2 mede a proporção ou percentual da variação total de Y explicada pelo modelo de regressão. 6.4.2 Regressão Linear Múltipla 6.5 Gradiente Descendente 6.6 SVM 6.7 Arvores de Decisão 6.8 Elastic Net 6.9 KNN 6.10 K-means 6.11 PCA 6.12 Clusters 6.13 AOC E ROC References "],
["modelos-nível-ii.html", "Capítulo 7 Modelos nível II 7.1 Gradiente Boosting -&gt; estudar boosting e bagging dentro de Emsemnble 7.2 Random Forest 7.3 Redes Neurais", " Capítulo 7 Modelos nível II 7.1 Gradiente Boosting -&gt; estudar boosting e bagging dentro de Emsemnble 7.2 Random Forest 7.3 Redes Neurais "]
]
